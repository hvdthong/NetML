Iteration: 1 trainLoss:0.5083807137919376 testLoss:0.38005855682885514
Iteration: 2 trainLoss:0.4948524365165741 testLoss:0.35173900477235504 trainLossDiff:-0.013528277275363487 testLossDiff:-0.028319552056500108
Iteration: 3 trainLoss:0.4855335509424139 testLoss:0.3308591852008092 trainLossDiff:-0.009318885574160218 testLossDiff:-0.020879819571545832
Iteration: 4 trainLoss:0.4785930187098941 testLoss:0.3153401173592859 trainLossDiff:-0.0069405322325197805 testLossDiff:-0.015519067841523293
Iteration: 5 trainLoss:0.47325644409342804 testLoss:0.3045006435321841 trainLossDiff:-0.005336574616466083 testLossDiff:-0.01083947382710182
Iteration: 6 trainLoss:0.4688431712164509 testLoss:0.295634692835721 trainLossDiff:-0.004413272876977126 testLossDiff:-0.008865950696463065
Iteration: 7 trainLoss:0.4651895438740696 testLoss:0.2888005086875892 trainLossDiff:-0.003653627342381338 testLossDiff:-0.0068341841481318055
Iteration: 8 trainLoss:0.4621183030009445 testLoss:0.28425855965710295 trainLossDiff:-0.003071240873125103 testLossDiff:-0.00454194903048627
Iteration: 9 trainLoss:0.4594282482156996 testLoss:0.2801408292334746 trainLossDiff:-0.0026900547852448664 testLossDiff:-0.004117730423628341
Iteration: 10 trainLoss:0.4570900162071444 testLoss:0.27695097058620416 trainLossDiff:-0.0023382320085552077 testLossDiff:-0.0031898586472704493
Iteration: 11 trainLoss:0.4549425149743869 testLoss:0.2731945239507227 trainLossDiff:-0.002147501232757476 testLossDiff:-0.0037564466354814696
Iteration: 12 trainLoss:0.45311223862770045 testLoss:0.27149727575641064 trainLossDiff:-0.0018302763466864769 testLossDiff:-0.001697248194312051
Iteration: 13 trainLoss:0.4513703319192447 testLoss:0.2680537372743495 trainLossDiff:-0.0017419067084557538 testLossDiff:-0.003443538482061137
Iteration: 14 trainLoss:0.4498572306616118 testLoss:0.2669733562538072 trainLossDiff:-0.0015131012576328762 testLossDiff:-0.0010803810205423092
Iteration: 15 trainLoss:0.4484458116803839 testLoss:0.2650394089862992 trainLossDiff:-0.0014114189812279299 testLossDiff:-0.0019339472675080072
Iteration: 16 trainLoss:0.4471841190554917 testLoss:0.26379676213342 trainLossDiff:-0.0012616926248921745 testLossDiff:-0.00124264685287917
Iteration: 17 trainLoss:0.44608904725556237 testLoss:0.26336679243439254 trainLossDiff:-0.001095071799929348 testLossDiff:-4.2996969902747706E-4
Iteration: 18 trainLoss:0.44496305788579404 testLoss:0.2612882915470707 trainLossDiff:-0.001125989369768321 testLossDiff:-0.0020785008873218658
Iteration: 19 trainLoss:0.44396369653528733 testLoss:0.259735922661103 trainLossDiff:-9.993613505067112E-4 testLossDiff:-0.0015523688859676588
Iteration: 20 trainLoss:0.443058275546096 testLoss:0.25872411705493586 trainLossDiff:-9.054209891913301E-4 testLossDiff:-0.0010118056061671488
Iteration: 21 trainLoss:0.44224810438431894 testLoss:0.25854280559183895 trainLossDiff:-8.101711617770624E-4 testLossDiff:-1.8131146309691148E-4
Iteration: 22 trainLoss:0.44148886033348594 testLoss:0.25786788070796834 trainLossDiff:-7.592440508329967E-4 testLossDiff:-6.74924883870609E-4
Iteration: 23 trainLoss:0.4407697270752846 testLoss:0.25711979599485274 trainLossDiff:-7.191332582013321E-4 testLossDiff:-7.480847131156043E-4
Iteration: 24 trainLoss:0.44010391379437597 testLoss:0.2564859507376057 trainLossDiff:-6.658132809086448E-4 testLossDiff:-6.338452572470232E-4
Iteration: 25 trainLoss:0.4394659454178075 testLoss:0.2556863805258346 trainLossDiff:-6.379683765684874E-4 testLossDiff:-7.995702117711279E-4
Iteration: 26 trainLoss:0.43885845851309935 testLoss:0.25469282910549224 trainLossDiff:-6.074869047081322E-4 testLossDiff:-9.935514203423534E-4
Iteration: 27 trainLoss:0.43831170406296105 testLoss:0.25387148707950313 trainLossDiff:-5.467544501382982E-4 testLossDiff:-8.213420259891024E-4
Iteration: 28 trainLoss:0.43783523425851456 testLoss:0.25375230010103494 trainLossDiff:-4.764698044464888E-4 testLossDiff:-1.1918697846818871E-4
Iteration: 29 trainLoss:0.4373587135054777 testLoss:0.2529400216554419 trainLossDiff:-4.765207530368354E-4 testLossDiff:-8.122784455930621E-4
Iteration: 30 trainLoss:0.43696927085505566 testLoss:0.253285541751185 trainLossDiff:-3.8944265042206716E-4 testLossDiff:3.455200957431237E-4
Learned weights: -37.82294773609269 47.67350441120657 2.584078102094115
