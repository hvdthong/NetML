Iteration: 1 trainLoss:0.46517225909571525 testLoss:0.4097713607050557
Iteration: 2 trainLoss:0.4516085327210993 testLoss:0.38794116921804167 trainLossDiff:-0.013563726374615948 testLossDiff:-0.02183019148701404
Iteration: 3 trainLoss:0.44113122625852685 testLoss:0.37028112606630276 trainLossDiff:-0.010477306462572444 testLossDiff:-0.017660043151738913
Iteration: 4 trainLoss:0.4329925157230938 testLoss:0.35594977402954553 trainLossDiff:-0.00813871053543308 testLossDiff:-0.014331352036757228
Iteration: 5 trainLoss:0.4264411463500505 testLoss:0.3440895666110284 trainLossDiff:-0.006551369373043292 testLossDiff:-0.011860207418517121
Iteration: 6 trainLoss:0.42107660767976396 testLoss:0.33412551131347956 trainLossDiff:-0.005364538670286523 testLossDiff:-0.009964055297548846
Iteration: 7 trainLoss:0.4166332528081348 testLoss:0.3257153539277779 trainLossDiff:-0.004443354871629168 testLossDiff:-0.008410157385701666
Iteration: 8 trainLoss:0.4129505800655447 testLoss:0.31870655210345283 trainLossDiff:-0.0036826727425900985 testLossDiff:-0.007008801824325062
Iteration: 9 trainLoss:0.4097445419672545 testLoss:0.31243786447735505 trainLossDiff:-0.003206038098290176 testLossDiff:-0.00626868762609778
Iteration: 10 trainLoss:0.40704473192684726 testLoss:0.30722175879468516 trainLossDiff:-0.002699810040407258 testLossDiff:-0.0052161056826698915
Iteration: 11 trainLoss:0.40469314507226745 testLoss:0.302664179353563 trainLossDiff:-0.0023515868545798124 testLossDiff:-0.004557579441122173
Iteration: 12 trainLoss:0.4026648595131381 testLoss:0.29881082698260936 trainLossDiff:-0.0020282855591293725 testLossDiff:-0.0038533523709536333
Iteration: 13 trainLoss:0.40070890239488033 testLoss:0.2946354282299544 trainLossDiff:-0.001955957118257745 testLossDiff:-0.004175398752654935
Iteration: 14 trainLoss:0.3991701477642596 testLoss:0.29198443387672396 trainLossDiff:-0.0015387546306207533 testLossDiff:-0.0026509943532304625
Iteration: 15 trainLoss:0.39765312625839816 testLoss:0.28891653853580146 trainLossDiff:-0.0015170215058614156 testLossDiff:-0.0030678953409224996
Iteration: 16 trainLoss:0.3963349382752998 testLoss:0.28640594193331825 trainLossDiff:-0.0013181879830983512 testLossDiff:-0.002510596602483206
Iteration: 17 trainLoss:0.3951161637295943 testLoss:0.2839578671257057 trainLossDiff:-0.0012187745457055144 testLossDiff:-0.0024480748076125547
Iteration: 18 trainLoss:0.3940759949150096 testLoss:0.2821577119255637 trainLossDiff:-0.0010401688145846855 testLossDiff:-0.001800155200141984
Iteration: 19 trainLoss:0.39307655075325176 testLoss:0.28023653019531897 trainLossDiff:-9.994441617578453E-4 testLossDiff:-0.0019211817302447476
Iteration: 20 trainLoss:0.39223090946642536 testLoss:0.278831004107055 trainLossDiff:-8.45641286826404E-4 testLossDiff:-0.001405526088263942
Iteration: 21 trainLoss:0.3913754196145688 testLoss:0.27717385118943166 trainLossDiff:-8.554898518565723E-4 testLossDiff:-0.0016571529176233613
Iteration: 22 trainLoss:0.3905456152528256 testLoss:0.27531057791481317 trainLossDiff:-8.298043617431805E-4 testLossDiff:-0.0018632732746184932
Iteration: 23 trainLoss:0.38985899377277694 testLoss:0.27411738735978 trainLossDiff:-6.866214800486659E-4 testLossDiff:-0.0011931905550331967
Iteration: 24 trainLoss:0.389226232000507 testLoss:0.27304552963061185 trainLossDiff:-6.327617722699519E-4 testLossDiff:-0.0010718577291681242
Iteration: 25 trainLoss:0.388630586067756 testLoss:0.2719817990214677 trainLossDiff:-5.956459327509656E-4 testLossDiff:-0.0010637306091441645
Iteration: 26 trainLoss:0.3880930409240618 testLoss:0.2710991029387661 trainLossDiff:-5.375451436941958E-4 testLossDiff:-8.82696082701584E-4
Iteration: 27 trainLoss:0.38753976154373804 testLoss:0.2698873557214438 trainLossDiff:-5.532793803237901E-4 testLossDiff:-0.001211747217322312
Iteration: 28 trainLoss:0.3870954204942791 testLoss:0.26928958119518004 trainLossDiff:-4.443410494589517E-4 testLossDiff:-5.977745262637502E-4
Iteration: 29 trainLoss:0.38664057798674245 testLoss:0.2684190315239259 trainLossDiff:-4.548425075366347E-4 testLossDiff:-8.705496712541616E-4
Iteration: 30 trainLoss:0.3862218979457517 testLoss:0.2676661420405797 trainLossDiff:-4.1868004099077094E-4 testLossDiff:-7.528894833461752E-4
Learned weights: -39.61127740843032 47.99059906316744 2.1859673709913574
