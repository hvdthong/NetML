Iteration: 1 trainLoss:0.48885508050968984 testLoss:0.4649736270273556
Iteration: 2 trainLoss:0.47648190524342043 testLoss:0.45609043298104546 trainLossDiff:-0.01237317526626941 testLossDiff:-0.008883194046310161
Iteration: 3 trainLoss:0.46747502005363895 testLoss:0.44915655265056403 trainLossDiff:-0.009006885189781488 testLossDiff:-0.006933880330481423
Iteration: 4 trainLoss:0.46062381913556083 testLoss:0.4429596321023068 trainLossDiff:-0.006851200918078115 testLossDiff:-0.006196920548257212
Iteration: 5 trainLoss:0.4551802812214849 testLoss:0.4374370560569836 trainLossDiff:-0.005443537914075924 testLossDiff:-0.005522576045323246
Iteration: 6 trainLoss:0.4506959736253985 testLoss:0.432773151648681 trainLossDiff:-0.004484307596086423 testLossDiff:-0.004663904408302555
Iteration: 7 trainLoss:0.44689193878766315 testLoss:0.42911319837975415 trainLossDiff:-0.0038040348377353372 testLossDiff:-0.0036599532689268743
Iteration: 8 trainLoss:0.4436216731478089 testLoss:0.42620178012651977 trainLossDiff:-0.0032702656398542196 testLossDiff:-0.002911418253234377
Iteration: 9 trainLoss:0.4409226999712753 testLoss:0.4218308106228642 trainLossDiff:-0.0026989731765336145 testLossDiff:-0.004370969503655564
Iteration: 10 trainLoss:0.43849752180863594 testLoss:0.4188048344387431 trainLossDiff:-0.0024251781626393742 testLossDiff:-0.003025976184121093
Iteration: 11 trainLoss:0.4363728437279556 testLoss:0.4158399560010408 trainLossDiff:-0.0021246780806803423 testLossDiff:-0.002964878437702323
Iteration: 12 trainLoss:0.4343731403204797 testLoss:0.4144146814834493 trainLossDiff:-0.0019997034074759057 testLossDiff:-0.0014252745175915016
Iteration: 13 trainLoss:0.43277081211511614 testLoss:0.4108254244851302 trainLossDiff:-0.0016023282053635457 testLossDiff:-0.003589256998319079
Iteration: 14 trainLoss:0.4311135894327595 testLoss:0.41023106835925427 trainLossDiff:-0.0016572226823566294 testLossDiff:-5.943561258759389E-4
Iteration: 15 trainLoss:0.42991104455952883 testLoss:0.40600307546175485 trainLossDiff:-0.001202544873230682 testLossDiff:-0.004227992897499422
Iteration: 16 trainLoss:0.4285134560013913 testLoss:0.40542330319685327 trainLossDiff:-0.0013975885581375413 testLossDiff:-5.797722649015791E-4
Iteration: 17 trainLoss:0.4273695001864524 testLoss:0.40340875546911314 trainLossDiff:-0.0011439558149388684 testLossDiff:-0.0020145477277401236
Iteration: 18 trainLoss:0.42626040579610486 testLoss:0.4022450630879779 trainLossDiff:-0.0011090943903475647 testLossDiff:-0.0011636923811352284
Iteration: 19 trainLoss:0.4252293905019296 testLoss:0.40126248114893653 trainLossDiff:-0.0010310152941752637 testLossDiff:-9.825819390413826E-4
Iteration: 20 trainLoss:0.42425865699594967 testLoss:0.40075299617687504 trainLossDiff:-9.70733505979926E-4 testLossDiff:-5.094849720614913E-4
Iteration: 21 trainLoss:0.42350070836366743 testLoss:0.3980892505466124 trainLossDiff:-7.579486322822349E-4 testLossDiff:-0.002663745630262615
Iteration: 22 trainLoss:0.42271062361405465 testLoss:0.3969343925282145 trainLossDiff:-7.90084749612785E-4 testLossDiff:-0.0011548580183979307
Iteration: 23 trainLoss:0.42203932603950756 testLoss:0.3950362195621373 trainLossDiff:-6.712975745470917E-4 testLossDiff:-0.001898172966077194
Iteration: 24 trainLoss:0.42134029940726103 testLoss:0.3940976474661059 trainLossDiff:-6.990266322465244E-4 testLossDiff:-9.385720960313759E-4
Iteration: 25 trainLoss:0.4207541970589621 testLoss:0.3925344601164478 trainLossDiff:-5.861023482989225E-4 testLossDiff:-0.0015631873496581017
Iteration: 26 trainLoss:0.4200578575146689 testLoss:0.3926241784789347 trainLossDiff:-6.963395442932119E-4 testLossDiff:8.971836248689025E-5
Iteration: 27 trainLoss:0.41955246725522743 testLoss:0.3910541146374592 trainLossDiff:-5.053902594414628E-4 testLossDiff:-0.0015700638414755108
Iteration: 28 trainLoss:0.4188934283694983 testLoss:0.3918178554320931 trainLossDiff:-6.590388857291574E-4 testLossDiff:7.637407946338715E-4
Iteration: 29 trainLoss:0.41835279318114776 testLoss:0.39181632010469486 trainLossDiff:-5.406351883505134E-4 testLossDiff:-1.5353273982166016E-6
Iteration: 30 trainLoss:0.41794889790020506 testLoss:0.3899520901762611 trainLossDiff:-4.03895280942701E-4 testLossDiff:-0.0018642299284337693
Learned weights: -41.72231441855357 41.04516934830045 3.1473439039612834
