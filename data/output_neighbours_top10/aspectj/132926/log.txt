Iteration: 1 trainLoss:0.5052966275562788 testLoss:0.42916273179733416
Iteration: 2 trainLoss:0.48962501302502404 testLoss:0.4161106415487783 trainLossDiff:-0.015671614531254763 testLossDiff:-0.013052090248555859
Iteration: 3 trainLoss:0.47926984943139933 testLoss:0.406062260054238 trainLossDiff:-0.010355163593624706 testLossDiff:-0.010048381494540293
Iteration: 4 trainLoss:0.47185568981809456 testLoss:0.3985462953028374 trainLossDiff:-0.007414159613304772 testLossDiff:-0.0075159647514005945
Iteration: 5 trainLoss:0.4663699555086527 testLoss:0.39174044137619857 trainLossDiff:-0.005485734309441881 testLossDiff:-0.00680585392663885
Iteration: 6 trainLoss:0.4620241457940202 testLoss:0.3865362366835986 trainLossDiff:-0.004345809714632498 testLossDiff:-0.005204204692599967
Iteration: 7 trainLoss:0.4585089555963274 testLoss:0.3822053207378435 trainLossDiff:-0.0035151901976927524 testLossDiff:-0.004330915945755076
Iteration: 8 trainLoss:0.45562290742451544 testLoss:0.37805662419111546 trainLossDiff:-0.0028860481718119835 testLossDiff:-0.004148696546728059
Iteration: 9 trainLoss:0.4531571908341244 testLoss:0.3746523915708255 trainLossDiff:-0.0024657165903910205 testLossDiff:-0.0034042326202899376
Iteration: 10 trainLoss:0.4510475840032655 testLoss:0.3715397996915981 trainLossDiff:-0.0021096068308589233 testLossDiff:-0.003112591879227411
Iteration: 11 trainLoss:0.44918142426267527 testLoss:0.36856412804122207 trainLossDiff:-0.0018661597405902342 testLossDiff:-0.002975671650376044
Iteration: 12 trainLoss:0.4475854952205549 testLoss:0.36536313718200136 trainLossDiff:-0.0015959290421203587 testLossDiff:-0.0032009908592207093
Iteration: 13 trainLoss:0.44605710469522475 testLoss:0.3644738713180374 trainLossDiff:-0.0015283905253301588 testLossDiff:-8.892658639639839E-4
Iteration: 14 trainLoss:0.4447260223368469 testLoss:0.3619139595489855 trainLossDiff:-0.0013310823583778664 testLossDiff:-0.0025599117690519035
Iteration: 15 trainLoss:0.44357683734781617 testLoss:0.3589926296643128 trainLossDiff:-0.001149184989030716 testLossDiff:-0.0029213298846726965
Iteration: 16 trainLoss:0.4424687618130404 testLoss:0.3573631578804842 trainLossDiff:-0.0011080755347757654 testLossDiff:-0.0016294717838286066
Iteration: 17 trainLoss:0.44149249660273915 testLoss:0.35557558525269467 trainLossDiff:-9.762652103012526E-4 testLossDiff:-0.001787572627789502
Iteration: 18 trainLoss:0.44055401720158643 testLoss:0.35465849801273075 trainLossDiff:-9.384794011527142E-4 testLossDiff:-9.170872399639207E-4
Iteration: 19 trainLoss:0.43972893369757104 testLoss:0.3530575773678236 trainLossDiff:-8.250835040153892E-4 testLossDiff:-0.0016009206449071334
Iteration: 20 trainLoss:0.43896602812926927 testLoss:0.35172361806913643 trainLossDiff:-7.629055683017749E-4 testLossDiff:-0.0013339592986871818
Iteration: 21 trainLoss:0.43828003920622094 testLoss:0.3501711516470657 trainLossDiff:-6.859889230483307E-4 testLossDiff:-0.0015524664220707418
Iteration: 22 trainLoss:0.43760405235685607 testLoss:0.3497281786524581 trainLossDiff:-6.759868493648735E-4 testLossDiff:-4.429729946076044E-4
Iteration: 23 trainLoss:0.43703719567675453 testLoss:0.3481280254116555 trainLossDiff:-5.668566801015351E-4 testLossDiff:-0.0016001532408025931
Iteration: 24 trainLoss:0.43647260007724065 testLoss:0.3472029422528555 trainLossDiff:-5.64595599513884E-4 testLossDiff:-9.250831588000219E-4
Iteration: 25 trainLoss:0.43592558234154966 testLoss:0.34699614697733794 trainLossDiff:-5.470177356909911E-4 testLossDiff:-2.0679527551753507E-4
Iteration: 26 trainLoss:0.43543798515929855 testLoss:0.34691494467674566 trainLossDiff:-4.875971822511094E-4 testLossDiff:-8.120230059227573E-5
Iteration: 27 trainLoss:0.43502727908335026 testLoss:0.34474611634574664 trainLossDiff:-4.107060759482861E-4 testLossDiff:-0.0021688283309990175
Iteration: 28 trainLoss:0.43458809661354364 testLoss:0.3446516890766262 trainLossDiff:-4.3918246980662046E-4 testLossDiff:-9.442726912045618E-5
Iteration: 29 trainLoss:0.434216270097743 testLoss:0.34347112118606243 trainLossDiff:-3.7182651580064396E-4 testLossDiff:-0.001180567890563755
Iteration: 30 trainLoss:0.4338436994746385 testLoss:0.34329529330767034 trainLossDiff:-3.725706231044734E-4 testLossDiff:-1.7582787839209857E-4
Learned weights: -39.098871302992144 45.34447256776324 2.8079537420370024
