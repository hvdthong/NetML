Iteration: 1 trainLoss:0.5054784900437229 testLoss:0.6735245270478434
Iteration: 2 trainLoss:0.4920834399356441 testLoss:0.7591849681499447 trainLossDiff:-0.013395050108078843 testLossDiff:0.08566044110210136
Iteration: 3 trainLoss:0.48274265234879704 testLoss:0.8320848683850577 trainLossDiff:-0.009340787586847032 testLossDiff:0.07289990023511295
Iteration: 4 trainLoss:0.4758005042395957 testLoss:0.8934968262008651 trainLossDiff:-0.0069421481092013515 testLossDiff:0.06141195781580744
Iteration: 5 trainLoss:0.4704082257104498 testLoss:0.9440822191133489 trainLossDiff:-0.005392278529145866 testLossDiff:0.05058539291248376
Iteration: 6 trainLoss:0.4660010612017561 testLoss:0.9878324470004503 trainLossDiff:-0.004407164508693717 testLossDiff:0.04375022788710137
Iteration: 7 trainLoss:0.46238153743949584 testLoss:1.0230966176647143 trainLossDiff:-0.0036195237622602683 testLossDiff:0.035264170664264016
Iteration: 8 trainLoss:0.4593045549749457 testLoss:1.0535470473381743 trainLossDiff:-0.0030769824645501265 testLossDiff:0.03045042967346001
Iteration: 9 trainLoss:0.4566450588222961 testLoss:1.0792252756128216 trainLossDiff:-0.0026594961526495986 testLossDiff:0.025678228274647275
Iteration: 10 trainLoss:0.4543256375237409 testLoss:1.100592206417722 trainLossDiff:-0.0023194212985552243 testLossDiff:0.021366930804900486
Iteration: 11 trainLoss:0.4522860928277623 testLoss:1.1194281485797017 trainLossDiff:-0.0020395446959786123 testLossDiff:0.018835942161979702
Iteration: 12 trainLoss:0.45044343701914846 testLoss:1.137641900428626 trainLossDiff:-0.0018426558086138134 testLossDiff:0.018213751848924264
Iteration: 13 trainLoss:0.4488159188246075 testLoss:1.1514676845416454 trainLossDiff:-0.001627518194540989 testLossDiff:0.01382578411301938
Iteration: 14 trainLoss:0.44736273883682665 testLoss:1.1647884276520806 trainLossDiff:-0.0014531799877808282 testLossDiff:0.013320743110435185
Iteration: 15 trainLoss:0.4460325743605115 testLoss:1.1765218617338302 trainLossDiff:-0.001330164476315121 testLossDiff:0.01173343408174965
Iteration: 16 trainLoss:0.4448021091775132 testLoss:1.1876324793073665 trainLossDiff:-0.001230465182998297 testLossDiff:0.011110617573536263
Iteration: 17 trainLoss:0.4436762203177464 testLoss:1.1983244100716512 trainLossDiff:-0.0011258888597668326 testLossDiff:0.010691930764284763
Iteration: 18 trainLoss:0.44269594435557946 testLoss:1.2070364637973219 trainLossDiff:-9.802759621669321E-4 testLossDiff:0.008712053725670632
Iteration: 19 trainLoss:0.4417381289276496 testLoss:1.21528676627177 trainLossDiff:-9.578154279298867E-4 testLossDiff:0.008250302474448024
Iteration: 20 trainLoss:0.44088956763739684 testLoss:1.2229763482590676 trainLossDiff:-8.485612902527362E-4 testLossDiff:0.0076895819872977444
Iteration: 21 trainLoss:0.44008616533098555 testLoss:1.230086912631952 trainLossDiff:-8.034023064112938E-4 testLossDiff:0.007110564372884376
Iteration: 22 trainLoss:0.4393617655634615 testLoss:1.236694149329376 trainLossDiff:-7.24399767524031E-4 testLossDiff:0.006607236697423913
Iteration: 23 trainLoss:0.4386980887399028 testLoss:1.243262793713729 trainLossDiff:-6.636768235587232E-4 testLossDiff:0.006568644384353117
Iteration: 24 trainLoss:0.43805891765204463 testLoss:1.2498536591956984 trainLossDiff:-6.391710878581591E-4 testLossDiff:0.006590865481969299
Iteration: 25 trainLoss:0.43747584082493995 testLoss:1.2559119333753168 trainLossDiff:-5.830768271046782E-4 testLossDiff:0.006058274179618461
Iteration: 26 trainLoss:0.4369324185745149 testLoss:1.2616159795951756 trainLossDiff:-5.434222504250297E-4 testLossDiff:0.0057040462198587605
Iteration: 27 trainLoss:0.4364326392020629 testLoss:1.266340735275082 trainLossDiff:-4.997793724520472E-4 testLossDiff:0.004724755679906378
Iteration: 28 trainLoss:0.43599682542466167 testLoss:1.2697973076628786 trainLossDiff:-4.358137774012061E-4 testLossDiff:0.0034565723877966192
Iteration: 29 trainLoss:0.4355462103659874 testLoss:1.2743488846456756 trainLossDiff:-4.506150586742752E-4 testLossDiff:0.004551576982797068
Iteration: 30 trainLoss:0.43515843693797895 testLoss:1.2780121655127354 trainLossDiff:-3.8777342800844217E-4 testLossDiff:0.003663280867059804
Learned weights: -35.31967855432006 48.742754279378964 2.523896274365841
