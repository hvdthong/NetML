Iteration: 1 trainLoss:0.5272961135872303 testLoss:0.5059694594932665
Iteration: 2 trainLoss:0.5196264367766797 testLoss:0.5022721884396449 trainLossDiff:-0.00766967681055053 testLossDiff:-0.003697271053621609
Iteration: 3 trainLoss:0.5133944760051399 testLoss:0.49807252112014117 trainLossDiff:-0.006231960771539868 testLossDiff:-0.004199667319503775
Iteration: 4 trainLoss:0.5082446740672646 testLoss:0.4948943280294895 trainLossDiff:-0.005149801937875287 testLossDiff:-0.0031781930906516487
Iteration: 5 trainLoss:0.5038970545004688 testLoss:0.49177859086431186 trainLossDiff:-0.004347619566795746 testLossDiff:-0.0031157371651776566
Iteration: 6 trainLoss:0.5001909533318203 testLoss:0.4892006719351645 trainLossDiff:-0.0037061011686485568 testLossDiff:-0.0025779189291473825
Iteration: 7 trainLoss:0.49699745270361595 testLoss:0.4872204263025508 trainLossDiff:-0.0031935006282043377 testLossDiff:-0.0019802456326136753
Iteration: 8 trainLoss:0.49422983959464883 testLoss:0.48543208065822185 trainLossDiff:-0.002767613108967115 testLossDiff:-0.001788345644328948
Iteration: 9 trainLoss:0.49181247822405305 testLoss:0.4833238176637047 trainLossDiff:-0.002417361370595783 testLossDiff:-0.0021082629945171627
Iteration: 10 trainLoss:0.48972308601202086 testLoss:0.48362053899158214 trainLossDiff:-0.002089392212032193 testLossDiff:2.967213278774472E-4
Iteration: 11 trainLoss:0.48781167821058957 testLoss:0.48112631656331317 trainLossDiff:-0.0019114078014312863 testLossDiff:-0.0024942224282689662
Iteration: 12 trainLoss:0.4861483940660702 testLoss:0.48071374747703965 trainLossDiff:-0.0016632841445193836 testLossDiff:-4.125690862735176E-4
Iteration: 13 trainLoss:0.4846498168861131 testLoss:0.4795880781257113 trainLossDiff:-0.0014985771799571057 testLossDiff:-0.0011256693513283511
Iteration: 14 trainLoss:0.4833095135545188 testLoss:0.4781564687356573 trainLossDiff:-0.0013403033315942947 testLossDiff:-0.0014316093900539895
Iteration: 15 trainLoss:0.4821055979528743 testLoss:0.4774165451915832 trainLossDiff:-0.0012039156016445118 testLossDiff:-7.399235440740948E-4
Iteration: 16 trainLoss:0.48101383682964205 testLoss:0.4768301289029086 trainLossDiff:-0.0010917611232322266 testLossDiff:-5.864162886746183E-4
Iteration: 17 trainLoss:0.4800353335186942 testLoss:0.47694952804762686 trainLossDiff:-9.785033109478425E-4 testLossDiff:1.1939914471825741E-4
Iteration: 18 trainLoss:0.47914073549997327 testLoss:0.4766159147771074 trainLossDiff:-8.945980187209379E-4 testLossDiff:-3.3361327051945056E-4
Iteration: 19 trainLoss:0.47830190478917434 testLoss:0.4753954434289533 trainLossDiff:-8.388307107989323E-4 testLossDiff:-0.0012204713481541174
Iteration: 20 trainLoss:0.4775464310723675 testLoss:0.47388558686816207 trainLossDiff:-7.554737168068426E-4 testLossDiff:-0.0015098565607912229
Iteration: 21 trainLoss:0.47684927980815284 testLoss:0.4742928030759582 trainLossDiff:-6.971512642146571E-4 testLossDiff:4.072162077961572E-4
Iteration: 22 trainLoss:0.47621394523225763 testLoss:0.4735808000537304 trainLossDiff:-6.353345758952078E-4 testLossDiff:-7.120030222278473E-4
Iteration: 23 trainLoss:0.4756246567357206 testLoss:0.4736195212792232 trainLossDiff:-5.892884965370548E-4 testLossDiff:3.872122549281043E-5
Iteration: 24 trainLoss:0.47509289937852406 testLoss:0.474107606975276 trainLossDiff:-5.317573571965162E-4 testLossDiff:4.8808569605279795E-4
Iteration: 25 trainLoss:0.4745765016084911 testLoss:0.47303628591451263 trainLossDiff:-5.163977700329836E-4 testLossDiff:-0.0010713210607633528
Iteration: 26 trainLoss:0.4741099941732615 testLoss:0.4725194429877513 trainLossDiff:-4.665074352295795E-4 testLossDiff:-5.168429267613517E-4
Iteration: 27 trainLoss:0.47367668502227955 testLoss:0.4727253913846965 trainLossDiff:-4.33309150981942E-4 testLossDiff:2.0594839694521028E-4
Iteration: 28 trainLoss:0.4732730193381771 testLoss:0.47263131349213733 trainLossDiff:-4.0366568410243886E-4 testLossDiff:-9.407789255916343E-5
Iteration: 29 trainLoss:0.47291462550660435 testLoss:0.4732780176049772 trainLossDiff:-3.583938315727675E-4 testLossDiff:6.467041128398465E-4
Iteration: 30 trainLoss:0.4725461017399734 testLoss:0.4718360056980924 trainLossDiff:-3.685237666309349E-4 testLossDiff:-0.0014420119068847548
Learned weights: -28.928889158449064 43.46089075920008 2.190270073100498
