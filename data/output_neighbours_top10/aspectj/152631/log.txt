Iteration: 1 trainLoss:0.4349722265701441 testLoss:0.4665874607605373
Iteration: 2 trainLoss:0.41876170954618885 testLoss:0.4498294444603017 trainLossDiff:-0.016210517023955262 testLossDiff:-0.0167580163002356
Iteration: 3 trainLoss:0.40773554165934456 testLoss:0.4366600556299559 trainLossDiff:-0.011026167886844296 testLossDiff:-0.013169388830345796
Iteration: 4 trainLoss:0.3997135607589422 testLoss:0.4264970630431847 trainLossDiff:-0.008021980900402348 testLossDiff:-0.010162992586771225
Iteration: 5 trainLoss:0.3936399133328736 testLoss:0.4185054534142684 trainLossDiff:-0.006073647426068585 testLossDiff:-0.007991609628916263
Iteration: 6 trainLoss:0.3888202898093919 testLoss:0.411518997723134 trainLossDiff:-0.004819623523481753 testLossDiff:-0.00698645569113443
Iteration: 7 trainLoss:0.38492710765063853 testLoss:0.4066851051984391 trainLossDiff:-0.003893182158753339 testLossDiff:-0.004833892524694905
Iteration: 8 trainLoss:0.38165942818518706 testLoss:0.40133027271495264 trainLossDiff:-0.0032676794654514785 testLossDiff:-0.005354832483486449
Iteration: 9 trainLoss:0.37888154055667367 testLoss:0.39657081674170847 trainLossDiff:-0.002777887628513387 testLossDiff:-0.0047594559732441755
Iteration: 10 trainLoss:0.3764933218142142 testLoss:0.39255340521749166 trainLossDiff:-0.0023882187424594803 testLossDiff:-0.004017411524216807
Iteration: 11 trainLoss:0.3743967634771247 testLoss:0.38953296785846914 trainLossDiff:-0.0020965583370894936 testLossDiff:-0.003020437359022521
Iteration: 12 trainLoss:0.37256344551179515 testLoss:0.3862016600436303 trainLossDiff:-0.0018333179653295395 testLossDiff:-0.003331307814838813
Iteration: 13 trainLoss:0.3709056118060653 testLoss:0.3852363132696582 trainLossDiff:-0.0016578337057298609 testLossDiff:-9.653467739721422E-4
Iteration: 14 trainLoss:0.3694263399720933 testLoss:0.3827479408316475 trainLossDiff:-0.0014792718339720068 testLossDiff:-0.0024883724380106997
Iteration: 15 trainLoss:0.3681095446953285 testLoss:0.3791293458536645 trainLossDiff:-0.0013167952767647595 testLossDiff:-0.003618594977983003
Iteration: 16 trainLoss:0.3668914516382489 testLoss:0.3774009801109319 trainLossDiff:-0.00121809305707965 testLossDiff:-0.0017283657427325516
Iteration: 17 trainLoss:0.365803065775876 testLoss:0.375928923398176 trainLossDiff:-0.0010883858623728648 testLossDiff:-0.0014720567127559092
Iteration: 18 trainLoss:0.36481491645541664 testLoss:0.37490569198042667 trainLossDiff:-9.88149320459375E-4 testLossDiff:-0.0010232314177493484
Iteration: 19 trainLoss:0.3639231730502174 testLoss:0.3716805668363972 trainLossDiff:-8.917434051992634E-4 testLossDiff:-0.0032251251440294504
Iteration: 20 trainLoss:0.3630707572202868 testLoss:0.3729509406944779 trainLossDiff:-8.52415829930564E-4 testLossDiff:0.0012703738580806534
Iteration: 21 trainLoss:0.36230405444007746 testLoss:0.3709729053593718 trainLossDiff:-7.667027802093496E-4 testLossDiff:-0.0019780353351060986
Iteration: 22 trainLoss:0.36160463535695786 testLoss:0.36999285912270974 trainLossDiff:-6.994190831196012E-4 testLossDiff:-9.800462366620355E-4
Iteration: 23 trainLoss:0.3609614275406836 testLoss:0.3687729635929187 trainLossDiff:-6.432078162742494E-4 testLossDiff:-0.0012198955297910152
Iteration: 24 trainLoss:0.36037238820252054 testLoss:0.36801519574627606 trainLossDiff:-5.890393381630665E-4 testLossDiff:-7.577678466426652E-4
Iteration: 25 trainLoss:0.35983003349791204 testLoss:0.36610314750796535 trainLossDiff:-5.423547046085053E-4 testLossDiff:-0.001912048238310704
Iteration: 26 trainLoss:0.35932936433482365 testLoss:0.364874209855513 trainLossDiff:-5.006691630883853E-4 testLossDiff:-0.0012289376524523554
Iteration: 27 trainLoss:0.3588517413127306 testLoss:0.36545372265006115 trainLossDiff:-4.776230220930322E-4 testLossDiff:5.795127945481537E-4
Iteration: 28 trainLoss:0.35842515443409917 testLoss:0.3633247971349383 trainLossDiff:-4.2658687863145195E-4 testLossDiff:-0.002128925515122837
Iteration: 29 trainLoss:0.35802678722238507 testLoss:0.3624537712360726 trainLossDiff:-3.983672117141013E-4 testLossDiff:-8.710258988657293E-4
Iteration: 30 trainLoss:0.35764336868185737 testLoss:0.36353873909875517 trainLossDiff:-3.834185405277024E-4 testLossDiff:0.0010849678626825843
Learned weights: -37.08800620096405 51.001666761976686 2.363781185255749
