Iteration: 1 trainLoss:0.4459710328381944 testLoss:0.4457081237274154
Iteration: 2 trainLoss:0.4299087415343721 testLoss:0.43066513527548334 trainLossDiff:-0.016062291303822307 testLossDiff:-0.015042988451932082
Iteration: 3 trainLoss:0.41853002502772474 testLoss:0.41919476245484316 trainLossDiff:-0.011378716506647346 testLossDiff:-0.011470372820640173
Iteration: 4 trainLoss:0.410141289270854 testLoss:0.41008844870825545 trainLossDiff:-0.008388735756870713 testLossDiff:-0.009106313746587713
Iteration: 5 trainLoss:0.4037625892593175 testLoss:0.40302881484731384 trainLossDiff:-0.006378700011536509 testLossDiff:-0.007059633860941605
Iteration: 6 trainLoss:0.3987692470671607 testLoss:0.39713369278107485 trainLossDiff:-0.004993342192156802 testLossDiff:-0.005895122066238989
Iteration: 7 trainLoss:0.3947489923859425 testLoss:0.39272410815072967 trainLossDiff:-0.004020254681218194 testLossDiff:-0.004409584630345187
Iteration: 8 trainLoss:0.3914560894380186 testLoss:0.3881030104118839 trainLossDiff:-0.003292902947923948 testLossDiff:-0.004621097738845781
Iteration: 9 trainLoss:0.3887318308340053 testLoss:0.38530592447319756 trainLossDiff:-0.0027242586040132633 testLossDiff:-0.002797085938686328
Iteration: 10 trainLoss:0.3864050070640843 testLoss:0.38224221445672124 trainLossDiff:-0.0023268237699209937 testLossDiff:-0.0030637100164763176
Iteration: 11 trainLoss:0.3843996100567286 testLoss:0.3791337586330726 trainLossDiff:-0.0020053970073556915 testLossDiff:-0.0031084558236486592
Iteration: 12 trainLoss:0.3826469709794059 testLoss:0.3770957977648835 trainLossDiff:-0.001752639077322704 testLossDiff:-0.0020379608681890815
Iteration: 13 trainLoss:0.38111549605697387 testLoss:0.37546909222745284 trainLossDiff:-0.0015314749224320523 testLossDiff:-0.0016267055374306616
Iteration: 14 trainLoss:0.3797657000045161 testLoss:0.373822533719138 trainLossDiff:-0.0013497960524577746 testLossDiff:-0.0016465585083148548
Iteration: 15 trainLoss:0.37857200634135646 testLoss:0.37199303341143675 trainLossDiff:-0.001193693663159634 testLossDiff:-0.0018295003077012373
Iteration: 16 trainLoss:0.37747541026393594 testLoss:0.37089976832901356 trainLossDiff:-0.0010965960774205197 testLossDiff:-0.0010932650824231893
Iteration: 17 trainLoss:0.37649713923066475 testLoss:0.36984428316974727 trainLossDiff:-9.782710332711941E-4 testLossDiff:-0.0010554851592662895
Iteration: 18 trainLoss:0.3756231299347209 testLoss:0.3685150106074607 trainLossDiff:-8.740092959438339E-4 testLossDiff:-0.0013292725622865431
Iteration: 19 trainLoss:0.37479475925325934 testLoss:0.3681194500088295 trainLossDiff:-8.283706814615766E-4 testLossDiff:-3.955605986312172E-4
Iteration: 20 trainLoss:0.37407016348499866 testLoss:0.3663870146317577 trainLossDiff:-7.245957682606718E-4 testLossDiff:-0.0017324353770717948
Iteration: 21 trainLoss:0.3733770384065703 testLoss:0.3657123746334287 trainLossDiff:-6.93125078428336E-4 testLossDiff:-6.746399983290075E-4
Iteration: 22 trainLoss:0.3727294272632512 testLoss:0.3657903529479156 trainLossDiff:-6.476111433191267E-4 testLossDiff:7.797831448691506E-5
Iteration: 23 trainLoss:0.37215177138403416 testLoss:0.36487614955818115 trainLossDiff:-5.776558792170428E-4 testLossDiff:-9.142033897344692E-4
Iteration: 24 trainLoss:0.37161560957474565 testLoss:0.3643342978069889 trainLossDiff:-5.361618092885045E-4 testLossDiff:-5.418517511922571E-4
Iteration: 25 trainLoss:0.3711280657500494 testLoss:0.3637776485407144 trainLossDiff:-4.875438246962349E-4 testLossDiff:-5.566492662744671E-4
Iteration: 26 trainLoss:0.370662853327433 testLoss:0.36317595082812015 trainLossDiff:-4.652124226164345E-4 testLossDiff:-6.016977125942735E-4
Iteration: 27 trainLoss:0.37023945166505784 testLoss:0.362835893305143 trainLossDiff:-4.2340166237514465E-4 testLossDiff:-3.400575229771663E-4
Iteration: 28 trainLoss:0.36984854229592534 testLoss:0.36189352174379 trainLossDiff:-3.909093691324972E-4 testLossDiff:-9.423715613529615E-4
Iteration: 29 trainLoss:0.36946417964887135 testLoss:0.3617610058652651 trainLossDiff:-3.843626470539929E-4 testLossDiff:-1.325158785249192E-4
Iteration: 30 trainLoss:0.3691145635900395 testLoss:0.3615046854833562 trainLossDiff:-3.4961605883182534E-4 testLossDiff:-2.563203819089255E-4
Learned weights: -38.777117580170135 45.86303727093986 2.4798463940402935
