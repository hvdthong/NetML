Iteration: 1 trainLoss:0.49330657239470344 testLoss:0.42523717455168275
Iteration: 2 trainLoss:0.47973843389821663 testLoss:0.4086516153362327 trainLossDiff:-0.013568138496486803 testLossDiff:-0.016585559215450074
Iteration: 3 trainLoss:0.47013177605035655 testLoss:0.3964727707692358 trainLossDiff:-0.009606657847860078 testLossDiff:-0.01217884456699686
Iteration: 4 trainLoss:0.4628447051935413 testLoss:0.3875576030290591 trainLossDiff:-0.0072870708568152365 testLossDiff:-0.0089151677401767
Iteration: 5 trainLoss:0.4572615026366121 testLoss:0.38061463957230957 trainLossDiff:-0.005583202556929234 testLossDiff:-0.006942963456749551
Iteration: 6 trainLoss:0.4527390082074444 testLoss:0.3750755096209918 trainLossDiff:-0.004522494429167689 testLossDiff:-0.005539129951317778
Iteration: 7 trainLoss:0.44897696501516365 testLoss:0.37070128209046294 trainLossDiff:-0.0037620431922807396 testLossDiff:-0.004374227530528851
Iteration: 8 trainLoss:0.44585245477377006 testLoss:0.36721932006729785 trainLossDiff:-0.0031245102413935966 testLossDiff:-0.003481962023165086
Iteration: 9 trainLoss:0.4432808552668424 testLoss:0.36458374346607214 trainLossDiff:-0.0025715995069276465 testLossDiff:-0.0026355766012257087
Iteration: 10 trainLoss:0.44087736770843106 testLoss:0.362063171017579 trainLossDiff:-0.0024034875584113546 testLossDiff:-0.0025205724484931302
Iteration: 11 trainLoss:0.43884223157807156 testLoss:0.3600999418737619 trainLossDiff:-0.002035136130359494 testLossDiff:-0.0019632291438171356
Iteration: 12 trainLoss:0.4369965937472743 testLoss:0.35830161553060164 trainLossDiff:-0.0018456378307972754 testLossDiff:-0.0017983263431602392
Iteration: 13 trainLoss:0.4353807705729228 testLoss:0.3570152702953435 trainLossDiff:-0.001615823174351494 testLossDiff:-0.0012863452352581128
Iteration: 14 trainLoss:0.43395426050701064 testLoss:0.35610637424076785 trainLossDiff:-0.0014265100659121566 testLossDiff:-9.088960545756697E-4
Iteration: 15 trainLoss:0.432586432423437 testLoss:0.35477341137520313 trainLossDiff:-0.0013678280835736634 testLossDiff:-0.001332962865564724
Iteration: 16 trainLoss:0.4313981135827651 testLoss:0.3540789840210993 trainLossDiff:-0.001188318840671887 testLossDiff:-6.944273541038548E-4
Iteration: 17 trainLoss:0.4303320100240886 testLoss:0.3536679279961126 trainLossDiff:-0.0010661035586764789 testLossDiff:-4.1105602498670013E-4
Iteration: 18 trainLoss:0.42933253864967014 testLoss:0.35317858904186533 trainLossDiff:-9.994713744184702E-4 testLossDiff:-4.893389542472426E-4
Iteration: 19 trainLoss:0.4283875738328126 testLoss:0.35242153460507364 trainLossDiff:-9.449648168575187E-4 testLossDiff:-7.570544367916932E-4
Iteration: 20 trainLoss:0.42751300036223194 testLoss:0.3515829518662511 trainLossDiff:-8.745734705806751E-4 testLossDiff:-8.385827388225353E-4
Iteration: 21 trainLoss:0.42673436189034203 testLoss:0.3512542346923889 trainLossDiff:-7.786384718899142E-4 testLossDiff:-3.287171738621808E-4
Iteration: 22 trainLoss:0.4260288368167533 testLoss:0.35123686436164375 trainLossDiff:-7.055250735887308E-4 testLossDiff:-1.7370330745170026E-5
Iteration: 23 trainLoss:0.4253573656210404 testLoss:0.35094710915733307 trainLossDiff:-6.714711957129249E-4 testLossDiff:-2.8975520431068214E-4
Iteration: 24 trainLoss:0.42475712354503825 testLoss:0.35109132623044953 trainLossDiff:-6.002420760021221E-4 testLossDiff:1.4421707311645937E-4
Iteration: 25 trainLoss:0.42414647648365295 testLoss:0.3504959468064485 trainLossDiff:-6.106470613853054E-4 testLossDiff:-5.95379424001008E-4
Iteration: 26 trainLoss:0.423597446688705 testLoss:0.35009558797208945 trainLossDiff:-5.490297949479195E-4 testLossDiff:-4.003588343590714E-4
Iteration: 27 trainLoss:0.4231188377765174 testLoss:0.35034045920928475 trainLossDiff:-4.786089121876502E-4 testLossDiff:2.448712371952988E-4
Iteration: 28 trainLoss:0.42263287215143547 testLoss:0.34999642890227267 trainLossDiff:-4.8596562508190777E-4 testLossDiff:-3.440303070120776E-4
Iteration: 29 trainLoss:0.4222558704151338 testLoss:0.3507556302127331 trainLossDiff:-3.770017363016742E-4 testLossDiff:7.592013104604223E-4
Iteration: 30 trainLoss:0.42178654465917875 testLoss:0.3498258560530931 trainLossDiff:-4.693257559550412E-4 testLossDiff:-9.297741596400177E-4
Learned weights: -37.18443430164352 48.35529427425683 2.354453716786672
