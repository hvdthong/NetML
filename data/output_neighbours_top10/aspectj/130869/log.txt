Iteration: 1 trainLoss:0.5202605074612516 testLoss:0.4978151843651555
Iteration: 2 trainLoss:0.5169670659933078 testLoss:0.49226633303225453 trainLossDiff:-0.0032934414679438584 testLossDiff:-0.00554885133290095
Iteration: 3 trainLoss:0.5153961275133694 testLoss:0.48848151735956574 trainLossDiff:-0.0015709384799383885 testLossDiff:-0.0037848156726887905
Iteration: 4 trainLoss:0.5142375603958615 testLoss:0.4842789515388475 trainLossDiff:-0.001158567117507836 testLossDiff:-0.004202565820718263
Iteration: 5 trainLoss:0.5132734808542324 testLoss:0.48128175776530335 trainLossDiff:-9.64079541629137E-4 testLossDiff:-0.0029971937735441267
Iteration: 6 trainLoss:0.5124442693205675 testLoss:0.47861346248970893 trainLossDiff:-8.292115336648864E-4 testLossDiff:-0.0026682952755944234
Iteration: 7 trainLoss:0.5117167340675973 testLoss:0.4759832028804657 trainLossDiff:-7.275352529702017E-4 testLossDiff:-0.002630259609243235
Iteration: 8 trainLoss:0.5110795657682246 testLoss:0.4736732400635517 trainLossDiff:-6.371682993727701E-4 testLossDiff:-0.0023099628169139796
Iteration: 9 trainLoss:0.5105113945479822 testLoss:0.4713938854282291 trainLossDiff:-5.681712202423306E-4 testLossDiff:-0.002279354635322639
Iteration: 10 trainLoss:0.5100094934517182 testLoss:0.4694143625141055 trainLossDiff:-5.019010962640236E-4 testLossDiff:-0.001979522914123566
Iteration: 11 trainLoss:0.5095582850037208 testLoss:0.4675680620597955 trainLossDiff:-4.512084479973977E-4 testLossDiff:-0.0018463004543100014
Iteration: 12 trainLoss:0.5091230628939423 testLoss:0.4667376488632121 trainLossDiff:-4.352221097785325E-4 testLossDiff:-8.304131965833905E-4
Iteration: 13 trainLoss:0.5087586096647655 testLoss:0.4652220200638807 trainLossDiff:-3.6445322917677547E-4 testLossDiff:-0.0015156287993314255
Iteration: 14 trainLoss:0.5084131940135612 testLoss:0.4651441030016288 trainLossDiff:-3.4541565120427276E-4 testLossDiff:-7.791706225190875E-5
Iteration: 15 trainLoss:0.5081310427407076 testLoss:0.4624203077205407 trainLossDiff:-2.821512728535813E-4 testLossDiff:-0.0027237952810880706
Iteration: 16 trainLoss:0.5078364581489634 testLoss:0.461817181661229 trainLossDiff:-2.9458459174425133E-4 testLossDiff:-6.031260593117316E-4
Iteration: 17 trainLoss:0.5075744149560082 testLoss:0.46116878191439237 trainLossDiff:-2.6204319295519696E-4 testLossDiff:-6.483997468366143E-4
Iteration: 18 trainLoss:0.507326838738531 testLoss:0.46097750629108486 trainLossDiff:-2.475762174771745E-4 testLossDiff:-1.9127562330750747E-4
Iteration: 19 trainLoss:0.5071197068048822 testLoss:0.4602003391610755 trainLossDiff:-2.0713193364885196E-4 testLossDiff:-7.771671300093597E-4
Iteration: 20 trainLoss:0.5069211928865184 testLoss:0.4597701791371317 trainLossDiff:-1.9851391836378518E-4 testLossDiff:-4.3016002394380415E-4
Iteration: 21 trainLoss:0.5067546154245236 testLoss:0.4581537803171016 trainLossDiff:-1.6657746199477685E-4 testLossDiff:-0.0016163988200301183
Iteration: 22 trainLoss:0.5066128592085417 testLoss:0.45704298767011714 trainLossDiff:-1.4175621598189192E-4 testLossDiff:-0.0011107926469844376
Iteration: 23 trainLoss:0.5064234622070365 testLoss:0.4577807959662715 trainLossDiff:-1.8939700150522043E-4 testLossDiff:7.378082961543853E-4
Iteration: 24 trainLoss:0.5062926720659031 testLoss:0.4566912989303276 trainLossDiff:-1.307901411333745E-4 testLossDiff:-0.0010894970359439093
Iteration: 25 trainLoss:0.5061514609321244 testLoss:0.45698300365464406 trainLossDiff:-1.4121113377874028E-4 testLossDiff:2.917047243164439E-4
Iteration: 26 trainLoss:0.506032257291022 testLoss:0.45617564511285524 trainLossDiff:-1.1920364110240556E-4 testLossDiff:-8.073585417888163E-4
Iteration: 27 trainLoss:0.5059144252672627 testLoss:0.45646805855552003 trainLossDiff:-1.1783202375925672E-4 testLossDiff:2.924134426647851E-4
Iteration: 28 trainLoss:0.5058091391712594 testLoss:0.4561796650725211 trainLossDiff:-1.0528609600335415E-4 testLossDiff:-2.8839348299891654E-4
Iteration: 29 trainLoss:0.5057312304236268 testLoss:0.4546174408439401 trainLossDiff:-7.790874763258238E-5 testLossDiff:-0.0015622242285809884
Iteration: 30 trainLoss:0.5056245652772168 testLoss:0.45522834903810677 trainLossDiff:-1.0666514641000102E-4 testLossDiff:6.109081941666483E-4
Learned weights: 6.508345762210894 26.834672410581124 1.3153349104329781
