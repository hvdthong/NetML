Iteration: 1 trainLoss:0.4489592818545614 testLoss:0.5170884015283994
Iteration: 2 trainLoss:0.4359552015751922 testLoss:0.512724896586723 trainLossDiff:-0.013004080279369223 testLossDiff:-0.004363504941676366
Iteration: 3 trainLoss:0.4249353688855715 testLoss:0.5108274675736095 trainLossDiff:-0.011019832689620701 testLossDiff:-0.0018974290131135163
Iteration: 4 trainLoss:0.4154360860040963 testLoss:0.510903244044691 trainLossDiff:-0.009499282881475168 testLossDiff:7.5776471081479E-5
Iteration: 5 trainLoss:0.40712373760229864 testLoss:0.5115521402035998 trainLossDiff:-0.008312348401797676 testLossDiff:6.488961589088404E-4
Iteration: 6 trainLoss:0.3998354537481374 testLoss:0.513476854778689 trainLossDiff:-0.007288283854161248 testLossDiff:0.001924714575089137
Iteration: 7 trainLoss:0.3933619046836751 testLoss:0.5153300223550101 trainLossDiff:-0.006473549064462292 testLossDiff:0.0018531675763211464
Iteration: 8 trainLoss:0.38759610262792277 testLoss:0.517238842382546 trainLossDiff:-0.005765802055752334 testLossDiff:0.0019088200275358957
Iteration: 9 trainLoss:0.3824893564210341 testLoss:0.5216815319303024 trainLossDiff:-0.005106746206888668 testLossDiff:0.0044426895477563955
Iteration: 10 trainLoss:0.3778211509840774 testLoss:0.522762468065333 trainLossDiff:-0.004668205436956674 testLossDiff:0.0010809361350305746
Iteration: 11 trainLoss:0.37369164080358 testLoss:0.5282170394235769 trainLossDiff:-0.004129510180497398 testLossDiff:0.005454571358243898
Iteration: 12 trainLoss:0.3698782776722341 testLoss:0.5306947765827342 trainLossDiff:-0.003813363131345948 testLossDiff:0.002477737159157334
Iteration: 13 trainLoss:0.3664330706875015 testLoss:0.5339666977988199 trainLossDiff:-0.0034452069847325517 testLossDiff:0.0032719212160856603
Iteration: 14 trainLoss:0.3632812737960022 testLoss:0.537199002389886 trainLossDiff:-0.0031517968914993033 testLossDiff:0.0032323045910661596
Iteration: 15 trainLoss:0.36040781643261255 testLoss:0.5410104391590005 trainLossDiff:-0.0028734573633896754 testLossDiff:0.00381143676911444
Iteration: 16 trainLoss:0.3577287542205588 testLoss:0.5423930717058919 trainLossDiff:-0.0026790622120537733 testLossDiff:0.0013826325468914158
Iteration: 17 trainLoss:0.3553130801730132 testLoss:0.54639540637279 trainLossDiff:-0.0024156740475455574 testLossDiff:0.004002334666898144
Iteration: 18 trainLoss:0.353072504303291 testLoss:0.5494186191498279 trainLossDiff:-0.0022405758697222056 testLossDiff:0.003023212777037876
Iteration: 19 trainLoss:0.35101488886288307 testLoss:0.5532892880449887 trainLossDiff:-0.002057615440407945 testLossDiff:0.003870668895160745
Iteration: 20 trainLoss:0.3491145942619204 testLoss:0.5568320631210424 trainLossDiff:-0.001900294600962693 testLossDiff:0.003542775076053717
Iteration: 21 trainLoss:0.34733612969100286 testLoss:0.559502851979031 trainLossDiff:-0.001778464570917515 testLossDiff:0.0026707888579886596
Iteration: 22 trainLoss:0.3456493638426567 testLoss:0.5590024068928252 trainLossDiff:-0.00168676584834615 testLossDiff:-5.004450862058363E-4
Iteration: 23 trainLoss:0.3441691090370473 testLoss:0.5653507522851907 trainLossDiff:-0.0014802548056094267 testLossDiff:0.0063483453923655064
Iteration: 24 trainLoss:0.3427001308711498 testLoss:0.5638994533682102 trainLossDiff:-0.001468978165897472 testLossDiff:-0.0014512989169804813
Iteration: 25 trainLoss:0.341382974812961 testLoss:0.5675335452305936 trainLossDiff:-0.0013171560581888286 testLossDiff:0.003634091862383393
Iteration: 26 trainLoss:0.340195767010778 testLoss:0.5731103108721405 trainLossDiff:-0.0011872078021829546 testLossDiff:0.005576765641546855
Iteration: 27 trainLoss:0.3389946629959393 testLoss:0.5725123613415004 trainLossDiff:-0.0012011040148387497 testLossDiff:-5.979495306400739E-4
Iteration: 28 trainLoss:0.3379305449911065 testLoss:0.575971938856518 trainLossDiff:-0.0010641180048328036 testLossDiff:0.0034595775150175756
Iteration: 29 trainLoss:0.3369378131432251 testLoss:0.5792166617533158 trainLossDiff:-9.927318478814007E-4 testLossDiff:0.0032447228967977804
Iteration: 30 trainLoss:0.3359506331564725 testLoss:0.5784860350692467 trainLossDiff:-9.871799867525732E-4 testLossDiff:-7.306266840690911E-4
Learned weights: -42.19746879626747 63.828082429775286 1.3118717963370918
