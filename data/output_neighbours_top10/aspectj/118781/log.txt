Iteration: 1 trainLoss:0.44778932536421423 testLoss:0.6641231386523163
Iteration: 2 trainLoss:0.439327877062613 testLoss:0.662999503786077 trainLossDiff:-0.008461448301601227 testLossDiff:-0.0011236348662393425
Iteration: 3 trainLoss:0.4323302534042448 testLoss:0.6621344047148556 trainLossDiff:-0.006997623658368202 testLossDiff:-8.650990712213424E-4
Iteration: 4 trainLoss:0.4265065359264844 testLoss:0.661774352617162 trainLossDiff:-0.005823717477760393 testLossDiff:-3.6005209769363056E-4
Iteration: 5 trainLoss:0.42154442057601077 testLoss:0.6615178851382486 trainLossDiff:-0.004962115350473639 testLossDiff:-2.564674789133914E-4
Iteration: 6 trainLoss:0.41727338568549505 testLoss:0.6612735695501558 trainLossDiff:-0.004271034890515724 testLossDiff:-2.4431558809279164E-4
Iteration: 7 trainLoss:0.41364737417782904 testLoss:0.6616631954737245 trainLossDiff:-0.003626011507666005 testLossDiff:3.8962592356872605E-4
Iteration: 8 trainLoss:0.410440755322109 testLoss:0.6617039657077705 trainLossDiff:-0.003206618855720045 testLossDiff:4.0770234045917064E-5
Iteration: 9 trainLoss:0.4076860921711922 testLoss:0.6622397434265745 trainLossDiff:-0.0027546631509167696 testLossDiff:5.357777188040869E-4
Iteration: 10 trainLoss:0.405192782654221 testLoss:0.6622377529885128 trainLossDiff:-0.0024933095169712427 testLossDiff:-1.990438061705291E-6
Iteration: 11 trainLoss:0.40300139744185276 testLoss:0.6624524233204634 trainLossDiff:-0.0021913852123682243 testLossDiff:2.1467033195055052E-4
Iteration: 12 trainLoss:0.40111272084513916 testLoss:0.6630335891087731 trainLossDiff:-0.001888676596713601 testLossDiff:5.811657883096899E-4
Iteration: 13 trainLoss:0.3993560158140644 testLoss:0.6629958004801584 trainLossDiff:-0.001756705031074779 testLossDiff:-3.7788628614698894E-5
Iteration: 14 trainLoss:0.39779159083030374 testLoss:0.6629719782247748 trainLossDiff:-0.0015644249837606372 testLossDiff:-2.3822255383554314E-5
Iteration: 15 trainLoss:0.3964673552172168 testLoss:0.6638126891856846 trainLossDiff:-0.0013242356130869215 testLossDiff:8.407109609097629E-4
Iteration: 16 trainLoss:0.39517259232219587 testLoss:0.6636494690926688 trainLossDiff:-0.001294762895020951 testLossDiff:-1.6322009301583673E-4
Iteration: 17 trainLoss:0.3940109951407432 testLoss:0.6634523126909708 trainLossDiff:-0.001161597181452645 testLossDiff:-1.971564016979288E-4
Iteration: 18 trainLoss:0.3930082268819919 testLoss:0.663905704457703 trainLossDiff:-0.001002768258751341 testLossDiff:4.5339176673220294E-4
Iteration: 19 trainLoss:0.3920657847495342 testLoss:0.6639058988573552 trainLossDiff:-9.424421324576993E-4 testLossDiff:1.9439965215362065E-7
Iteration: 20 trainLoss:0.3912687766486319 testLoss:0.664600558284117 trainLossDiff:-7.970081009022745E-4 testLossDiff:6.946594267618345E-4
Iteration: 21 trainLoss:0.39044286508263676 testLoss:0.6641494518634028 trainLossDiff:-8.259115659951521E-4 testLossDiff:-4.5110642071422014E-4
Iteration: 22 trainLoss:0.38981180715863234 testLoss:0.6651172289293016 trainLossDiff:-6.31057924004419E-4 testLossDiff:9.677770658987894E-4
Iteration: 23 trainLoss:0.3891471297911879 testLoss:0.6651196327913658 trainLossDiff:-6.646773674444661E-4 testLossDiff:2.403862064181972E-6
Iteration: 24 trainLoss:0.3885129469187051 testLoss:0.6647144587941762 trainLossDiff:-6.341828724827914E-4 testLossDiff:-4.0517399718953406E-4
Iteration: 25 trainLoss:0.38799121346031046 testLoss:0.6652242469924183 trainLossDiff:-5.217334583946243E-4 testLossDiff:5.097881982421004E-4
Iteration: 26 trainLoss:0.38756411530350204 testLoss:0.6660168856439534 trainLossDiff:-4.2709815680841423E-4 testLossDiff:7.926386515351158E-4
Iteration: 27 trainLoss:0.38701006060130816 testLoss:0.6653203934674707 trainLossDiff:-5.540547021938846E-4 testLossDiff:-6.964921764827103E-4
Iteration: 28 trainLoss:0.38660858964715444 testLoss:0.6657446817178945 trainLossDiff:-4.0147095415371536E-4 testLossDiff:4.242882504237322E-4
Iteration: 29 trainLoss:0.3861793933094068 testLoss:0.6655931393421668 trainLossDiff:-4.291963377476282E-4 testLossDiff:-1.515423757276757E-4
Iteration: 30 trainLoss:0.3858355959441413 testLoss:0.6660240052905868 trainLossDiff:-3.4379736526551907E-4 testLossDiff:4.308659484200117E-4
Learned weights: -34.466303682620484 44.21164267463681 2.3996283767562443
