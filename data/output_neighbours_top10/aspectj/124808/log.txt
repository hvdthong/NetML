Iteration: 1 trainLoss:0.5644482582525993 testLoss:0.4779737456408458
Iteration: 2 trainLoss:0.5626789921301787 testLoss:0.480434695428417 trainLossDiff:-0.0017692661224205652 testLossDiff:0.002460949787571165
Iteration: 3 trainLoss:0.5614117430998593 testLoss:0.48119216185861413 trainLossDiff:-0.001267249030319384 testLossDiff:7.574664301971401E-4
Iteration: 4 trainLoss:0.5603875865485096 testLoss:0.48161432485236294 trainLossDiff:-0.0010241565513496864 testLossDiff:4.2216299374880917E-4
Iteration: 5 trainLoss:0.559468239270156 testLoss:0.4823864956280335 trainLossDiff:-9.193472783536327E-4 testLossDiff:7.721707756705443E-4
Iteration: 6 trainLoss:0.5587241178638669 testLoss:0.48202178939485374 trainLossDiff:-7.441214062891E-4 testLossDiff:-3.647062331797457E-4
Iteration: 7 trainLoss:0.5580227350429017 testLoss:0.4824639712549467 trainLossDiff:-7.013828209652129E-4 testLossDiff:4.4218186009298277E-4
Iteration: 8 trainLoss:0.55747818574605 testLoss:0.4822449784447747 trainLossDiff:-5.445492968516596E-4 testLossDiff:-2.18992810172014E-4
Iteration: 9 trainLoss:0.5569263049015938 testLoss:0.48284553168598754 trainLossDiff:-5.518808444562318E-4 testLossDiff:6.005532412128312E-4
Iteration: 10 trainLoss:0.5564799452360669 testLoss:0.48266245625315796 trainLossDiff:-4.463596655268631E-4 testLossDiff:-1.830754328295825E-4
Iteration: 11 trainLoss:0.5560868124752143 testLoss:0.48264311272378013 trainLossDiff:-3.931327608526214E-4 testLossDiff:-1.9343529377824353E-5
Iteration: 12 trainLoss:0.5556919912914486 testLoss:0.48334674984866416 trainLossDiff:-3.94821183765659E-4 testLossDiff:7.036371248840267E-4
Iteration: 13 trainLoss:0.5553475977715054 testLoss:0.48380320420300565 trainLossDiff:-3.44393519943198E-4 testLossDiff:4.564543543414956E-4
Iteration: 14 trainLoss:0.5550623010523907 testLoss:0.4831977668068266 trainLossDiff:-2.8529671911470267E-4 testLossDiff:-6.05437396179076E-4
Iteration: 15 trainLoss:0.5547881836562031 testLoss:0.48338916772789553 trainLossDiff:-2.741173961876564E-4 testLossDiff:1.9140092106895157E-4
Iteration: 16 trainLoss:0.5545611018147069 testLoss:0.4836119597836484 trainLossDiff:-2.270818414962239E-4 testLossDiff:2.2279205575287397E-4
Iteration: 17 trainLoss:0.5543268338779819 testLoss:0.48387926646818546 trainLossDiff:-2.3426793672498558E-4 testLossDiff:2.6730668453706086E-4
Iteration: 18 trainLoss:0.5541393119534446 testLoss:0.4836857331358107 trainLossDiff:-1.8752192453730387E-4 testLossDiff:-1.9353333237476233E-4
Iteration: 19 trainLoss:0.5539594624939289 testLoss:0.48380754542358617 trainLossDiff:-1.7984945951565745E-4 testLossDiff:1.2181228777546904E-4
Iteration: 20 trainLoss:0.5537747644538722 testLoss:0.4840205510208194 trainLossDiff:-1.8469804005671886E-4 testLossDiff:2.130055972332512E-4
Iteration: 21 trainLoss:0.5535573191698273 testLoss:0.48494635814485704 trainLossDiff:-2.174452840448815E-4 testLossDiff:9.258071240376142E-4
Iteration: 22 trainLoss:0.5534523698060813 testLoss:0.48480026299937085 trainLossDiff:-1.0494936374605413E-4 testLossDiff:-1.460951454861914E-4
Iteration: 23 trainLoss:0.5532791937966601 testLoss:0.48561668963393684 trainLossDiff:-1.7317600942112765E-4 testLossDiff:8.164266345659921E-4
Iteration: 24 trainLoss:0.5531548147997062 testLoss:0.485789205030117 trainLossDiff:-1.243789969539444E-4 testLossDiff:1.7251539618018397E-4
Iteration: 25 trainLoss:0.553038909747716 testLoss:0.48605396554390545 trainLossDiff:-1.1590505199021717E-4 testLossDiff:2.6476051378843124E-4
Iteration: 26 trainLoss:0.5529329252852722 testLoss:0.48591351107389963 trainLossDiff:-1.0598446244380888E-4 testLossDiff:-1.4045447000582412E-4
Iteration: 27 trainLoss:0.5528276712690507 testLoss:0.48698859441944325 trainLossDiff:-1.0525401622141217E-4 testLossDiff:0.001075083345543626
Iteration: 28 trainLoss:0.5528007645830246 testLoss:0.4856590525009969 trainLossDiff:-2.690668602611801E-5 testLossDiff:-0.0013295419184463642
Iteration: 29 trainLoss:0.5526916571516709 testLoss:0.4859322802617888 trainLossDiff:-1.0910743135372769E-4 testLossDiff:2.7322776079191646E-4
Iteration: 30 trainLoss:0.5526206858168526 testLoss:0.4859452708694546 trainLossDiff:-7.097133481825946E-5 testLossDiff:1.2990607665797071E-5
Learned weights: -0.35677944237160375 24.861620866404923 1.6498548763243321
