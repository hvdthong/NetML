Iteration: 1 trainLoss:0.5699831508987043 testLoss:0.52916969078197
Iteration: 2 trainLoss:0.5687144503692547 testLoss:0.5318505538489635 trainLossDiff:-0.0012687005294496068 testLossDiff:0.002680863066993555
Iteration: 3 trainLoss:0.5681186499879189 testLoss:0.533515949950388 trainLossDiff:-5.95800381335776E-4 testLossDiff:0.0016653961014244656
Iteration: 4 trainLoss:0.5676856542685673 testLoss:0.5335699836201732 trainLossDiff:-4.329957193516254E-4 testLossDiff:5.403366978518065E-5
Iteration: 5 trainLoss:0.5673372241170639 testLoss:0.5337425616432906 trainLossDiff:-3.484301515034316E-4 testLossDiff:1.725780231174312E-4
Iteration: 6 trainLoss:0.5670461695581214 testLoss:0.5335049663624899 trainLossDiff:-2.910545589425162E-4 testLossDiff:-2.3759528080069536E-4
Iteration: 7 trainLoss:0.5668027406509396 testLoss:0.5329865164574642 trainLossDiff:-2.4342890718176413E-4 testLossDiff:-5.184499050256974E-4
Iteration: 8 trainLoss:0.5665897900990302 testLoss:0.5329371787900818 trainLossDiff:-2.129505519093966E-4 testLossDiff:-4.933766738235423E-5
Iteration: 9 trainLoss:0.5663909529162447 testLoss:0.5338500166059746 trainLossDiff:-1.988371827854607E-4 testLossDiff:9.128378158927974E-4
Iteration: 10 trainLoss:0.5662397013060504 testLoss:0.5329603337568891 trainLossDiff:-1.512516101943584E-4 testLossDiff:-8.896828490855269E-4
Iteration: 11 trainLoss:0.5660924657099371 testLoss:0.533371560197301 trainLossDiff:-1.4723559611329318E-4 testLossDiff:4.112264404119159E-4
Iteration: 12 trainLoss:0.5659673232537402 testLoss:0.5339027437743693 trainLossDiff:-1.2514245619688058E-4 testLossDiff:5.311835770682727E-4
Iteration: 13 trainLoss:0.5658601290191987 testLoss:0.5343378908063895 trainLossDiff:-1.0719423454152999E-4 testLossDiff:4.351470320201889E-4
Iteration: 14 trainLoss:0.5657658646994451 testLoss:0.532872984069173 trainLossDiff:-9.426431975356753E-5 testLossDiff:-0.0014649067372164426
Iteration: 15 trainLoss:0.5656683625963267 testLoss:0.5337375025487998 trainLossDiff:-9.750210311842977E-5 testLossDiff:8.645184796267635E-4
Iteration: 16 trainLoss:0.565595453777163 testLoss:0.5332112406910091 trainLossDiff:-7.290881916366398E-5 testLossDiff:-5.262618577906997E-4
Iteration: 17 trainLoss:0.5655317193949794 testLoss:0.5327443475484813 trainLossDiff:-6.373438218365557E-5 testLossDiff:-4.6689314252779113E-4
Iteration: 18 trainLoss:0.5654690048158548 testLoss:0.5327332433197632 trainLossDiff:-6.271457912454537E-5 testLossDiff:-1.110422871808403E-5
Iteration: 19 trainLoss:0.5653999636597868 testLoss:0.5343122893287031 trainLossDiff:-6.904115606798378E-5 testLossDiff:0.0015790460089398772
Iteration: 20 trainLoss:0.5653533581506297 testLoss:0.5349380818191102 trainLossDiff:-4.6605509157138236E-5 testLossDiff:6.257924904070622E-4
Iteration: 21 trainLoss:0.5653069422999447 testLoss:0.5329450023404791 trainLossDiff:-4.641585068498877E-5 testLossDiff:-0.0019930794786310324
Iteration: 22 trainLoss:0.5652553316987667 testLoss:0.5336107245202201 trainLossDiff:-5.1610601177976E-5 testLossDiff:6.657221797409241E-4
Iteration: 23 trainLoss:0.5652296004439051 testLoss:0.5329484432964167 trainLossDiff:-2.5731254861605102E-5 testLossDiff:-6.62281223803407E-4
Iteration: 24 trainLoss:0.5651829400873338 testLoss:0.5343683863585569 trainLossDiff:-4.6660356571304185E-5 testLossDiff:0.0014199430621402165
Iteration: 25 trainLoss:0.5651769432525448 testLoss:0.5324212984481933 trainLossDiff:-5.996834789079308E-6 testLossDiff:-0.0019470879103635763
Iteration: 26 trainLoss:0.5651250835726459 testLoss:0.5333932348748043 trainLossDiff:-5.185967989884688E-5 testLossDiff:9.719364266109753E-4
Iteration: 27 trainLoss:0.5650983318292939 testLoss:0.5331124748219318 trainLossDiff:-2.6751743351982604E-5 testLossDiff:-2.807600528724752E-4
Iteration: 28 trainLoss:0.5650681182950943 testLoss:0.533661727739564 trainLossDiff:-3.0213534199630132E-5 testLossDiff:5.492529176321925E-4
Iteration: 29 trainLoss:0.5650519931440658 testLoss:0.5329182185213595 trainLossDiff:-1.6125151028445472E-5 testLossDiff:-7.435092182045411E-4
Iteration: 30 trainLoss:0.5650299882218089 testLoss:0.5328728725970816 trainLossDiff:-2.200492225690187E-5 testLossDiff:-4.534592427785089E-5
Learned weights: 4.222592138818653 15.641494169102664 1.7231371927748833
