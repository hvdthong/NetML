Iteration: 1 trainLoss:0.5180819056695254 testLoss:0.38168656987024935
Iteration: 2 trainLoss:0.5032841384885074 testLoss:0.36416819208045603 trainLossDiff:-0.014797767181017996 testLossDiff:-0.017518377789793316
Iteration: 3 trainLoss:0.4929801620251105 testLoss:0.3530566027055023 trainLossDiff:-0.010303976463396869 testLossDiff:-0.011111589374953712
Iteration: 4 trainLoss:0.4854965396101449 testLoss:0.342695290940037 trainLossDiff:-0.0074836224149656405 testLossDiff:-0.010361311765465342
Iteration: 5 trainLoss:0.4797442142886912 testLoss:0.3351154118621893 trainLossDiff:-0.0057523253214537 testLossDiff:-0.007579879077847684
Iteration: 6 trainLoss:0.4751369883064863 testLoss:0.3291612296016844 trainLossDiff:-0.004607225982204866 testLossDiff:-0.00595418226050487
Iteration: 7 trainLoss:0.47138911398299277 testLoss:0.32329040436481443 trainLossDiff:-0.0037478743234935497 testLossDiff:-0.005870825236869992
Iteration: 8 trainLoss:0.4682230437462219 testLoss:0.31852536302750933 trainLossDiff:-0.003166070236770846 testLossDiff:-0.004765041337305098
Iteration: 9 trainLoss:0.4655159262381998 testLoss:0.31454625524154756 trainLossDiff:-0.0027071175080221055 testLossDiff:-0.003979107785961777
Iteration: 10 trainLoss:0.4631519291010452 testLoss:0.3109157461939814 trainLossDiff:-0.0023639971371546276 testLossDiff:-0.003630509047566177
Iteration: 11 trainLoss:0.46105631479351133 testLoss:0.3081591528185144 trainLossDiff:-0.002095614307533855 testLossDiff:-0.0027565933754669647
Iteration: 12 trainLoss:0.45923738048605445 testLoss:0.30485742171652247 trainLossDiff:-0.0018189343074568876 testLossDiff:-0.003301731101991945
Iteration: 13 trainLoss:0.45754708577015096 testLoss:0.30266579495290424 trainLossDiff:-0.0016902947159034842 testLossDiff:-0.0021916267636182263
Iteration: 14 trainLoss:0.45606950790698664 testLoss:0.30015925736325005 trainLossDiff:-0.0014775778631643255 testLossDiff:-0.0025065375896541897
Iteration: 15 trainLoss:0.45470233708504354 testLoss:0.29827321589972405 trainLossDiff:-0.0013671708219430978 testLossDiff:-0.0018860414635260003
Iteration: 16 trainLoss:0.45348594761475347 testLoss:0.29599944950803936 trainLossDiff:-0.001216389470290069 testLossDiff:-0.002273766391684695
Iteration: 17 trainLoss:0.4523170228095803 testLoss:0.2945920023758427 trainLossDiff:-0.001168924805173166 testLossDiff:-0.0014074471321966486
Iteration: 18 trainLoss:0.45127558640282195 testLoss:0.2930481325589665 trainLossDiff:-0.001041436406758356 testLossDiff:-0.0015438698168762088
Iteration: 19 trainLoss:0.45036248394147926 testLoss:0.2911831358221377 trainLossDiff:-9.131024613426852E-4 testLossDiff:-0.0018649967368288278
Iteration: 20 trainLoss:0.4494689580269261 testLoss:0.29004895414925386 trainLossDiff:-8.935259145531615E-4 testLossDiff:-0.001134181672883816
Iteration: 21 trainLoss:0.44863788933486604 testLoss:0.28903021039520954 trainLossDiff:-8.310686920600663E-4 testLossDiff:-0.0010187437540443156
Iteration: 22 trainLoss:0.44789113167369254 testLoss:0.28800432148470345 trainLossDiff:-7.467576611734916E-4 testLossDiff:-0.0010258889105060898
Iteration: 23 trainLoss:0.4472412587628872 testLoss:0.2865284233285278 trainLossDiff:-6.498729108053714E-4 testLossDiff:-0.001475898156175659
Iteration: 24 trainLoss:0.4465718337602549 testLoss:0.28563209697437997 trainLossDiff:-6.694250026322845E-4 testLossDiff:-8.96326354147825E-4
Iteration: 25 trainLoss:0.44597909391213225 testLoss:0.28463254802766036 trainLossDiff:-5.927398481226365E-4 testLossDiff:-9.995489467196084E-4
Iteration: 26 trainLoss:0.44551668297350955 testLoss:0.2835748695444803 trainLossDiff:-4.6241093862270377E-4 testLossDiff:-0.0010576784831800579
Iteration: 27 trainLoss:0.44488218513517674 testLoss:0.28315770507761046 trainLossDiff:-6.344978383328037E-4 testLossDiff:-4.17164466869846E-4
Iteration: 28 trainLoss:0.444434255327427 testLoss:0.28222410999633446 trainLossDiff:-4.4792980774976954E-4 testLossDiff:-9.335950812759952E-4
Iteration: 29 trainLoss:0.4439695954347539 testLoss:0.2815363842591703 trainLossDiff:-4.646598926730805E-4 testLossDiff:-6.877257371641354E-4
Iteration: 30 trainLoss:0.44353757474815464 testLoss:0.28100166926942016 trainLossDiff:-4.3202068659925486E-4 testLossDiff:-5.347149897501624E-4
Learned weights: -38.41602106909506 48.383706542162315 2.4242817679324533
