Iteration: 1 trainLoss:0.563402014268167 testLoss:0.4548070528081287
Iteration: 2 trainLoss:0.5629723242149327 testLoss:0.4545293693766419 trainLossDiff:-4.2969005323434395E-4 testLossDiff:-2.776834314868193E-4
Iteration: 3 trainLoss:0.5625960781678143 testLoss:0.4543164386039054 trainLossDiff:-3.7624604711838927E-4 testLossDiff:-2.1293077273648597E-4
Iteration: 4 trainLoss:0.5622628917911754 testLoss:0.4540426633101676 trainLossDiff:-3.331863766389276E-4 testLossDiff:-2.7377529373778797E-4
Iteration: 5 trainLoss:0.5619729078999176 testLoss:0.45364979852675813 trainLossDiff:-2.8998389125778345E-4 testLossDiff:-3.928647834094967E-4
Iteration: 6 trainLoss:0.5617003848071123 testLoss:0.4532221981954595 trainLossDiff:-2.725230928053435E-4 testLossDiff:-4.276003312986276E-4
Iteration: 7 trainLoss:0.5614605188895496 testLoss:0.4527347467189742 trainLossDiff:-2.3986591756264275E-4 testLossDiff:-4.874514764853233E-4
Iteration: 8 trainLoss:0.5612422433471099 testLoss:0.45219825314954853 trainLossDiff:-2.1827554243969427E-4 testLossDiff:-5.364935694256445E-4
Iteration: 9 trainLoss:0.561041340134188 testLoss:0.4515964208734351 trainLossDiff:-2.0090321292187685E-4 testLossDiff:-6.018322761134343E-4
Iteration: 10 trainLoss:0.5608591765796584 testLoss:0.45137338140279903 trainLossDiff:-1.8216355452960187E-4 testLossDiff:-2.230394706360661E-4
Iteration: 11 trainLoss:0.5607018710660728 testLoss:0.4510859255566257 trainLossDiff:-1.5730551358561495E-4 testLossDiff:-2.8745584617334563E-4
Iteration: 12 trainLoss:0.5605414307965797 testLoss:0.45068967277148897 trainLossDiff:-1.6044026949313395E-4 testLossDiff:-3.9625278513671924E-4
Iteration: 13 trainLoss:0.5604135450876452 testLoss:0.45047458475333846 trainLossDiff:-1.2788570893451645E-4 testLossDiff:-2.1508801815051104E-4
Iteration: 14 trainLoss:0.560281870611288 testLoss:0.4500762695297936 trainLossDiff:-1.3167447635720197E-4 testLossDiff:-3.9831522354483173E-4
Iteration: 15 trainLoss:0.5601713021458947 testLoss:0.4497902415864098 trainLossDiff:-1.1056846539325704E-4 testLossDiff:-2.860279433838375E-4
Iteration: 16 trainLoss:0.5600620830095391 testLoss:0.4495903456602937 trainLossDiff:-1.0921913635564273E-4 testLossDiff:-1.998959261160782E-4
Iteration: 17 trainLoss:0.5599748216554084 testLoss:0.44954399586999316 trainLossDiff:-8.726135413072988E-5 testLossDiff:-4.634979030054831E-5
Iteration: 18 trainLoss:0.559880522585362 testLoss:0.44904438554983944 trainLossDiff:-9.429907004632199E-5 testLossDiff:-4.996103201537205E-4
Iteration: 19 trainLoss:0.559798285362389 testLoss:0.44870701668237933 trainLossDiff:-8.223722297306946E-5 testLossDiff:-3.373688674601083E-4
Iteration: 20 trainLoss:0.5597268063140597 testLoss:0.44825880765982046 trainLossDiff:-7.147904832927043E-5 testLossDiff:-4.482090225588764E-4
Iteration: 21 trainLoss:0.5596540136124174 testLoss:0.44830739569494377 trainLossDiff:-7.279270164228802E-5 testLossDiff:4.8588035123309226E-5
Iteration: 22 trainLoss:0.5595851876938477 testLoss:0.44821223192273474 trainLossDiff:-6.882591856971487E-5 testLossDiff:-9.516377220902816E-5
Iteration: 23 trainLoss:0.5595281265535966 testLoss:0.44813599702356577 trainLossDiff:-5.706114025105791E-5 testLossDiff:-7.623489916896986E-5
Iteration: 24 trainLoss:0.5594861772963288 testLoss:0.448038024996438 trainLossDiff:-4.194925726785925E-5 testLossDiff:-9.797202712774622E-5
Iteration: 25 trainLoss:0.5594234309323577 testLoss:0.44761765348939564 trainLossDiff:-6.274636397107791E-5 testLossDiff:-4.20371507042383E-4
Iteration: 26 trainLoss:0.5593754104215277 testLoss:0.4473420440869979 trainLossDiff:-4.8020510829971386E-5 testLossDiff:-2.7560940239773624E-4
Iteration: 27 trainLoss:0.5593297225974414 testLoss:0.44739177880295056 trainLossDiff:-4.5687824086315665E-5 testLossDiff:4.9734715952653996E-5
Iteration: 28 trainLoss:0.5592880870923697 testLoss:0.4473126863643237 trainLossDiff:-4.1635505071746515E-5 testLossDiff:-7.909243862685988E-5
Iteration: 29 trainLoss:0.5592485049113408 testLoss:0.44709785739921154 trainLossDiff:-3.9582181028841035E-5 testLossDiff:-2.148289651121571E-4
Iteration: 30 trainLoss:0.5592283559322091 testLoss:0.4470344561551224 trainLossDiff:-2.014897913171776E-5 testLossDiff:-6.340124408915626E-5
Learned weights: 0.2855129589624091 14.969655416851221 2.033954355467792
