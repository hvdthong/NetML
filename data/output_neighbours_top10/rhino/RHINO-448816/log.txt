Iteration: 1 trainLoss:0.6397253173210091 testLoss:0.6757325734147315
Iteration: 2 trainLoss:0.6291119588734739 testLoss:0.6644653914296086 trainLossDiff:-0.010613358447535193 testLossDiff:-0.011267181985122887
Iteration: 3 trainLoss:0.6212910761159791 testLoss:0.6526869758848651 trainLossDiff:-0.007820882757494818 testLossDiff:-0.011778415544743459
Iteration: 4 trainLoss:0.6150106684745072 testLoss:0.6428811008567086 trainLossDiff:-0.0062804076414718635 testLossDiff:-0.009805875028156552
Iteration: 5 trainLoss:0.6098954505238187 testLoss:0.6349260450896642 trainLossDiff:-0.005115217950688589 testLossDiff:-0.007955055767044361
Iteration: 6 trainLoss:0.6057514419643324 testLoss:0.6286314767556378 trainLossDiff:-0.0041440085594862675 testLossDiff:-0.006294568334026418
Iteration: 7 trainLoss:0.6023238688246635 testLoss:0.6231278297236719 trainLossDiff:-0.0034275731396689046 testLossDiff:-0.00550364703196593
Iteration: 8 trainLoss:0.5995335177247192 testLoss:0.6189262258256089 trainLossDiff:-0.0027903510999442993 testLossDiff:-0.004201603898063011
Iteration: 9 trainLoss:0.5971812428171717 testLoss:0.6151179083241147 trainLossDiff:-0.0023522749075475247 testLossDiff:-0.0038083175014941295
Iteration: 10 trainLoss:0.5952184483509038 testLoss:0.6118600141369279 trainLossDiff:-0.001962794466267903 testLossDiff:-0.003257894187186805
Iteration: 11 trainLoss:0.5935798177871395 testLoss:0.6093401888517769 trainLossDiff:-0.0016386305637642318 testLossDiff:-0.002519825285151045
Iteration: 12 trainLoss:0.592222835103942 testLoss:0.6071626129120977 trainLossDiff:-0.0013569826831975051 testLossDiff:-0.002177575939679155
Iteration: 13 trainLoss:0.5910858804902379 testLoss:0.6054417820033231 trainLossDiff:-0.0011369546137041109 testLossDiff:-0.0017208309087746176
Iteration: 14 trainLoss:0.5901355806842182 testLoss:0.6040950323071244 trainLossDiff:-9.502998060196832E-4 testLossDiff:-0.0013467496961987457
Iteration: 15 trainLoss:0.5893555879031369 testLoss:0.6026552141706764 trainLossDiff:-7.799927810813179E-4 testLossDiff:-0.0014398181364480012
Iteration: 16 trainLoss:0.5886313724198439 testLoss:0.6017582055504782 trainLossDiff:-7.242154832930447E-4 testLossDiff:-8.970086201981475E-4
Iteration: 17 trainLoss:0.5880371706323951 testLoss:0.6008177980239293 trainLossDiff:-5.942017874487338E-4 testLossDiff:-9.40407526548892E-4
Iteration: 18 trainLoss:0.5875615688721105 testLoss:0.6001652515713215 trainLossDiff:-4.756017602846052E-4 testLossDiff:-6.525464526078162E-4
Iteration: 19 trainLoss:0.5871998882974192 testLoss:0.5994597291228385 trainLossDiff:-3.616805746913254E-4 testLossDiff:-7.05522448482987E-4
Iteration: 20 trainLoss:0.586885263458789 testLoss:0.598937997415227 trainLossDiff:-3.146248386302064E-4 testLossDiff:-5.217317076114947E-4
Iteration: 21 trainLoss:0.5866000093077457 testLoss:0.5986290595461724 trainLossDiff:-2.8525415104330154E-4 testLossDiff:-3.089378690546152E-4
Iteration: 22 trainLoss:0.5863435027205408 testLoss:0.5981141729345865 trainLossDiff:-2.565065872048855E-4 testLossDiff:-5.148866115859407E-4
Iteration: 23 trainLoss:0.5861189165153948 testLoss:0.5976353586213483 trainLossDiff:-2.2458620514598238E-4 testLossDiff:-4.788143132381517E-4
Iteration: 24 trainLoss:0.5859637247136318 testLoss:0.5971277494250423 trainLossDiff:-1.551918017630438E-4 testLossDiff:-5.076091963059914E-4
Iteration: 25 trainLoss:0.5857645072728483 testLoss:0.5972641495326776 trainLossDiff:-1.9921744078343906E-4 testLossDiff:1.3640010763527055E-4
Iteration: 26 trainLoss:0.585655553523694 testLoss:0.596994466597852 trainLossDiff:-1.0895374915431688E-4 testLossDiff:-2.696829348255436E-4
Iteration: 27 trainLoss:0.5855503345495757 testLoss:0.5966721235365745 trainLossDiff:-1.0521897411830405E-4 testLossDiff:-3.223430612775413E-4
Iteration: 28 trainLoss:0.5854172838166851 testLoss:0.5966710863115943 trainLossDiff:-1.3305073289060498E-4 testLossDiff:-1.0372249802381717E-6
Iteration: 29 trainLoss:0.5853504200516907 testLoss:0.5965344439094293 trainLossDiff:-6.686376499442925E-5 testLossDiff:-1.3664240216493262E-4
Iteration: 30 trainLoss:0.585305452791762 testLoss:0.5963232164785924 trainLossDiff:-4.4967259928641035E-5 testLossDiff:-2.112274308369022E-4
Learned weights: 7.029526335516071 0.8602676926977725 1.3776185716277622
