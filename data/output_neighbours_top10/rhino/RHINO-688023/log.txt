Iteration: 1 trainLoss:0.5452387166601078 testLoss:0.6916645013945879
Iteration: 2 trainLoss:0.5445694789917469 testLoss:0.6926360469766111 trainLossDiff:-6.692376683609114E-4 testLossDiff:9.7154558202317E-4
Iteration: 3 trainLoss:0.5444494001302352 testLoss:0.6927186369999608 trainLossDiff:-1.2007886151166325E-4 testLossDiff:8.259002334976007E-5
Iteration: 4 trainLoss:0.5443867932302553 testLoss:0.6926558461080552 trainLossDiff:-6.260689997994451E-5 testLossDiff:-6.279089190563969E-5
Iteration: 5 trainLoss:0.5443302246535597 testLoss:0.6925969832854965 trainLossDiff:-5.656857669555926E-5 testLossDiff:-5.8862822558736205E-5
Iteration: 6 trainLoss:0.5442900747201501 testLoss:0.6925129873433746 trainLossDiff:-4.01499334096167E-5 testLossDiff:-8.399594212182837E-5
Iteration: 7 trainLoss:0.5442369584785657 testLoss:0.6924887840369903 trainLossDiff:-5.311624158443884E-5 testLossDiff:-2.4203306384307233E-5
Iteration: 8 trainLoss:0.5441891367224801 testLoss:0.6924684726418664 trainLossDiff:-4.7821756085530964E-5 testLossDiff:-2.0311395123928655E-5
Iteration: 9 trainLoss:0.5441384185300283 testLoss:0.6924718193094737 trainLossDiff:-5.0718192451837396E-5 testLossDiff:3.3466676072624324E-6
Iteration: 10 trainLoss:0.5441213114848337 testLoss:0.6923841456677868 trainLossDiff:-1.7107045194642012E-5 testLossDiff:-8.767364168682512E-5
Iteration: 11 trainLoss:0.5440841778851062 testLoss:0.6923711712263563 trainLossDiff:-3.713359972745689E-5 testLossDiff:-1.2974441430557704E-5
Iteration: 12 trainLoss:0.5440739530924426 testLoss:0.6922907982131661 trainLossDiff:-1.0224792663660054E-5 testLossDiff:-8.037301319019363E-5
Iteration: 13 trainLoss:0.5440404184398129 testLoss:0.6922903284851236 trainLossDiff:-3.3534652629674255E-5 testLossDiff:-4.697280424625916E-7
Iteration: 14 trainLoss:0.5440188268980205 testLoss:0.6922632948451946 trainLossDiff:-2.1591541792376212E-5 testLossDiff:-2.7033639929063824E-5
Iteration: 15 trainLoss:0.5439985116185252 testLoss:0.6922441899798217 trainLossDiff:-2.0315279495308758E-5 testLossDiff:-1.9104865372820967E-5
Iteration: 16 trainLoss:0.543976696702869 testLoss:0.6922363436586405 trainLossDiff:-2.1814915656226397E-5 testLossDiff:-7.846321181226301E-6
Iteration: 17 trainLoss:0.5439790043825714 testLoss:0.6921636483362233 trainLossDiff:2.3076797024401685E-6 testLossDiff:-7.269532241716004E-5
Iteration: 18 trainLoss:0.5439447552026708 testLoss:0.6922133278069266 trainLossDiff:-3.424917990058063E-5 testLossDiff:4.9679470703223316E-5
Iteration: 19 trainLoss:0.5439272333809045 testLoss:0.6922119305508786 trainLossDiff:-1.7521821766286472E-5 testLossDiff:-1.3972560479746932E-6
Iteration: 20 trainLoss:0.5439275420212479 testLoss:0.6921596102030882 trainLossDiff:3.0864034339384006E-7 testLossDiff:-5.2320347790346666E-5
Iteration: 21 trainLoss:0.5438989728516492 testLoss:0.6922033482159438 trainLossDiff:-2.856916959870226E-5 testLossDiff:4.373801285550982E-5
Iteration: 22 trainLoss:0.5438896126753799 testLoss:0.6921901977483482 trainLossDiff:-9.360176269290754E-6 testLossDiff:-1.3150467595535176E-5
Iteration: 23 trainLoss:0.5438859897410272 testLoss:0.6921613842590411 trainLossDiff:-3.622934352742746E-6 testLossDiff:-2.8813489307166762E-5
Iteration: 24 trainLoss:0.543881519580509 testLoss:0.6921408525659665 trainLossDiff:-4.470160518188493E-6 testLossDiff:-2.053169307458802E-5
Iteration: 25 trainLoss:0.5438597464682668 testLoss:0.6921819585226519 trainLossDiff:-2.1773112242162718E-5 testLossDiff:4.1105956685383305E-5
Iteration: 26 trainLoss:0.5438526453670469 testLoss:0.692178310355495 trainLossDiff:-7.101101219930683E-6 testLossDiff:-3.648167156811155E-6
Iteration: 27 trainLoss:0.5438564594710324 testLoss:0.692141907179637 trainLossDiff:3.8141039855332792E-6 testLossDiff:-3.6403175858068515E-5
Iteration: 28 trainLoss:0.543856457889676 testLoss:0.6921211844760301 trainLossDiff:-1.5813564901989707E-9 testLossDiff:-2.072270360686801E-5
Iteration: 29 trainLoss:0.5438449266152235 testLoss:0.692137292010161 trainLossDiff:-1.1531274452414308E-5 testLossDiff:1.610753413094912E-5
Iteration: 30 trainLoss:0.5438558901962123 testLoss:0.6920842135562566 trainLossDiff:1.0963580988732069E-5 testLossDiff:-5.307845390445376E-5
Learned weights: -0.26577577655830953 0.9477319341322027 2.6797389987927067
