Iteration: 1 trainLoss:0.6599947133136552 testLoss:0.45637349650197867
Iteration: 2 trainLoss:0.6593306818139401 testLoss:0.4439719162545317 trainLossDiff:-6.640314997151675E-4 testLossDiff:-0.012401580247446975
Iteration: 3 trainLoss:0.659073993089974 testLoss:0.44281146168877944 trainLossDiff:-2.566887239660032E-4 testLossDiff:-0.0011604545657522558
Iteration: 4 trainLoss:0.6588641150596881 testLoss:0.44309334019098967 trainLossDiff:-2.098780302859371E-4 testLossDiff:2.8187850221023103E-4
Iteration: 5 trainLoss:0.6586553888744794 testLoss:0.44216532572271816 trainLossDiff:-2.0872618520872965E-4 testLossDiff:-9.280144682715097E-4
Iteration: 6 trainLoss:0.6584686433063656 testLoss:0.4411969251557148 trainLossDiff:-1.8674556811382192E-4 testLossDiff:-9.684005670033691E-4
Iteration: 7 trainLoss:0.6583413564432031 testLoss:0.44281221562428685 trainLossDiff:-1.2728686316243465E-4 testLossDiff:0.0016152904685720615
Iteration: 8 trainLoss:0.6581944209995146 testLoss:0.44234986725826375 trainLossDiff:-1.4693544368848954E-4 testLossDiff:-4.6234836602310203E-4
Iteration: 9 trainLoss:0.6580678368038638 testLoss:0.4422316433789455 trainLossDiff:-1.2658419565081402E-4 testLossDiff:-1.1822387931825773E-4
Iteration: 10 trainLoss:0.6579517017405128 testLoss:0.4421344470885553 trainLossDiff:-1.1613506335106383E-4 testLossDiff:-9.719629039017796E-5
Iteration: 11 trainLoss:0.6578439562742717 testLoss:0.44185449222037443 trainLossDiff:-1.077454662410382E-4 testLossDiff:-2.799548681808872E-4
Iteration: 12 trainLoss:0.657764899502456 testLoss:0.44250581794902993 trainLossDiff:-7.905677181574422E-5 testLossDiff:6.513257286555052E-4
Iteration: 13 trainLoss:0.6576631691062116 testLoss:0.4414621781793918 trainLossDiff:-1.0173039624439273E-4 testLossDiff:-0.0010436397696381161
Iteration: 14 trainLoss:0.6575941973189575 testLoss:0.4416532894134743 trainLossDiff:-6.89717872540685E-5 testLossDiff:1.911112340824972E-4
Iteration: 15 trainLoss:0.6575263933253825 testLoss:0.4416032884151734 trainLossDiff:-6.780399357497746E-5 testLossDiff:-5.0000998300936406E-5
Iteration: 16 trainLoss:0.6574774784184297 testLoss:0.44208060661482684 trainLossDiff:-4.891490695280165E-5 testLossDiff:4.773181996534648E-4
Iteration: 17 trainLoss:0.6574092451406728 testLoss:0.4413892084181844 trainLossDiff:-6.82332777569572E-5 testLossDiff:-6.913981966424343E-4
Iteration: 18 trainLoss:0.6573357386619669 testLoss:0.4398614673585074 trainLossDiff:-7.35064787058537E-5 testLossDiff:-0.0015277410596770125
Iteration: 19 trainLoss:0.6573132664380541 testLoss:0.4411942699409963 trainLossDiff:-2.2472223912828326E-5 testLossDiff:0.0013328025824889123
Iteration: 20 trainLoss:0.6572791150176854 testLoss:0.4415648445601952 trainLossDiff:-3.4151420368666585E-5 testLossDiff:3.7057461919887125E-4
Iteration: 21 trainLoss:0.657250420753503 testLoss:0.44190139005503015 trainLossDiff:-2.8694264182393958E-5 testLossDiff:3.365454948349722E-4
Iteration: 22 trainLoss:0.6572043520541858 testLoss:0.4412066887331394 trainLossDiff:-4.606869931722546E-5 testLossDiff:-6.947013218907561E-4
Iteration: 23 trainLoss:0.6571669787662373 testLoss:0.4406286928399856 trainLossDiff:-3.7373287948505585E-5 testLossDiff:-5.77995893153771E-4
Iteration: 24 trainLoss:0.6571195760999221 testLoss:0.43928389758774694 trainLossDiff:-4.7402666315199404E-5 testLossDiff:-0.0013447952522386841
Iteration: 25 trainLoss:0.6571294477569347 testLoss:0.44134282064506725 trainLossDiff:9.871657012605617E-6 testLossDiff:0.0020589230573203054
Iteration: 26 trainLoss:0.6571056052016091 testLoss:0.4411568178859886 trainLossDiff:-2.3842555325614967E-5 testLossDiff:-1.8600275907865171E-4
Iteration: 27 trainLoss:0.657074787712592 testLoss:0.44060536915050263 trainLossDiff:-3.081748901712089E-5 testLossDiff:-5.514487354859599E-4
Iteration: 28 trainLoss:0.6570595995641797 testLoss:0.44064785921496374 trainLossDiff:-1.5188148412281777E-5 testLossDiff:4.2490064461109256E-5
Iteration: 29 trainLoss:0.6570695513784184 testLoss:0.4419745165625294 trainLossDiff:9.95181423868452E-6 testLossDiff:0.0013266573475656518
Iteration: 30 trainLoss:0.657037879107893 testLoss:0.4410137169438855 trainLossDiff:-3.167227052536248E-5 testLossDiff:-9.607996186438705E-4
Learned weights: -0.8257025480074744 1.4932245392959698 1.4930501120995752
