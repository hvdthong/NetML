Iteration: 1 trainLoss:0.4710665537364075 testLoss:0.44368437709801284
Iteration: 2 trainLoss:0.4706535288690174 testLoss:0.4426283688659232 trainLossDiff:-4.1302486739008826E-4 testLossDiff:-0.0010560082320896225
Iteration: 3 trainLoss:0.4704948033721147 testLoss:0.44161531358226713 trainLossDiff:-1.5872549690271187E-4 testLossDiff:-0.0010130552836560835
Iteration: 4 trainLoss:0.47035249762625686 testLoss:0.4407187951630497 trainLossDiff:-1.4230574585782918E-4 testLossDiff:-8.965184192174513E-4
Iteration: 5 trainLoss:0.4702300491619893 testLoss:0.4399210554550077 trainLossDiff:-1.2244846426756606E-4 testLossDiff:-7.977397080419779E-4
Iteration: 6 trainLoss:0.47010875648951794 testLoss:0.4392476412952866 trainLossDiff:-1.2129267247135145E-4 testLossDiff:-6.734141597211085E-4
Iteration: 7 trainLoss:0.4700103828893081 testLoss:0.43860410948045814 trainLossDiff:-9.837360020986674E-5 testLossDiff:-6.435318148284574E-4
Iteration: 8 trainLoss:0.4699195984427389 testLoss:0.4380494778351646 trainLossDiff:-9.078444656918094E-5 testLossDiff:-5.546316452935129E-4
Iteration: 9 trainLoss:0.4698365855354877 testLoss:0.43755740550228694 trainLossDiff:-8.301290725121202E-5 testLossDiff:-4.920723328776799E-4
Iteration: 10 trainLoss:0.46976454424221514 testLoss:0.43710610116908716 trainLossDiff:-7.204129327254005E-5 testLossDiff:-4.513043331997868E-4
Iteration: 11 trainLoss:0.4696962801375256 testLoss:0.4367162093090544 trainLossDiff:-6.826410468951938E-5 testLossDiff:-3.898918600327428E-4
Iteration: 12 trainLoss:0.4696307470553306 testLoss:0.43637998858813837 trainLossDiff:-6.553308219503506E-5 testLossDiff:-3.3622072091604727E-4
Iteration: 13 trainLoss:0.4695780700830455 testLoss:0.4360515973600371 trainLossDiff:-5.267697228511503E-5 testLossDiff:-3.2839122810124355E-4
Iteration: 14 trainLoss:0.46953071834852367 testLoss:0.43575189073397136 trainLossDiff:-4.735173452180552E-5 testLossDiff:-2.997066260657655E-4
Iteration: 15 trainLoss:0.4694910301616492 testLoss:0.4354789078122641 trainLossDiff:-3.968818687444253E-5 testLossDiff:-2.7298292170724325E-4
Iteration: 16 trainLoss:0.4694407344283491 testLoss:0.4352917626028935 trainLossDiff:-5.0295733300120826E-5 testLossDiff:-1.8714520937063162E-4
Iteration: 17 trainLoss:0.4694089833943778 testLoss:0.43506844311072174 trainLossDiff:-3.175103397129453E-5 testLossDiff:-2.233194921717474E-4
Iteration: 18 trainLoss:0.46937156426715126 testLoss:0.43491929240335314 trainLossDiff:-3.741912722654561E-5 testLossDiff:-1.4915070736859493E-4
Iteration: 19 trainLoss:0.46934300255965455 testLoss:0.4347438087756558 trainLossDiff:-2.8561707496710387E-5 testLossDiff:-1.7548362769731485E-4
Iteration: 20 trainLoss:0.46930797253909606 testLoss:0.4346267112910418 trainLossDiff:-3.5030020558490804E-5 testLossDiff:-1.1709748461402603E-4
Iteration: 21 trainLoss:0.46929841550316775 testLoss:0.43441062290004745 trainLossDiff:-9.557035928309254E-6 testLossDiff:-2.1608839099435118E-4
Iteration: 22 trainLoss:0.4692615757886577 testLoss:0.4343424261911026 trainLossDiff:-3.683971451007295E-5 testLossDiff:-6.819670894486762E-5
Iteration: 23 trainLoss:0.46924974397336394 testLoss:0.43418123107480294 trainLossDiff:-1.1831815293739112E-5 testLossDiff:-1.6119511629963945E-4
Iteration: 24 trainLoss:0.46922441715597707 testLoss:0.4341201096435131 trainLossDiff:-2.532681738687259E-5 testLossDiff:-6.11214312898345E-5
Iteration: 25 trainLoss:0.469206375650712 testLoss:0.4340481456974387 trainLossDiff:-1.8041505265076196E-5 testLossDiff:-7.196394607439371E-5
Iteration: 26 trainLoss:0.469192400462083 testLoss:0.43395688276040384 trainLossDiff:-1.3975188629000712E-5 testLossDiff:-9.126293703487498E-5
Iteration: 27 trainLoss:0.46918847228416855 testLoss:0.43384091333024466 trainLossDiff:-3.928177914447328E-6 testLossDiff:-1.159694301591796E-4
Iteration: 28 trainLoss:0.4691716214482562 testLoss:0.43379618462789166 trainLossDiff:-1.6850835912352036E-5 testLossDiff:-4.472870235300297E-5
Iteration: 29 trainLoss:0.46915841985125517 testLoss:0.4337519827425928 trainLossDiff:-1.3201597001022414E-5 testLossDiff:-4.4201885298855714E-5
Iteration: 30 trainLoss:0.46915027431846246 testLoss:0.4337030660283577 trainLossDiff:-8.145532792713794E-6 testLossDiff:-4.891671423512545E-5
Learned weights: -0.3763201095275888 1.3782580778852094 2.674660441179122
