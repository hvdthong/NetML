Iteration: 1 trainLoss:0.4673595000771782 testLoss:0.59902365927003
Iteration: 2 trainLoss:0.46652000656768694 testLoss:0.6000665262100375 trainLossDiff:-8.394935094912515E-4 testLossDiff:0.0010428669400075474
Iteration: 3 trainLoss:0.466195717890009 testLoss:0.5998802115116227 trainLossDiff:-3.242886776779197E-4 testLossDiff:-1.863146984147912E-4
Iteration: 4 trainLoss:0.46593535188860047 testLoss:0.5996116629894201 trainLossDiff:-2.603660014085518E-4 testLossDiff:-2.6854852220259406E-4
Iteration: 5 trainLoss:0.46570971878464545 testLoss:0.5993710642321909 trainLossDiff:-2.2563310395501412E-4 testLossDiff:-2.4059875722926005E-4
Iteration: 6 trainLoss:0.46552238154508574 testLoss:0.599089350566562 trainLossDiff:-1.8733723955971504E-4 testLossDiff:-2.817136656289021E-4
Iteration: 7 trainLoss:0.4653413806963194 testLoss:0.598898498968184 trainLossDiff:-1.8100084876632172E-4 testLossDiff:-1.9085159837795018E-4
Iteration: 8 trainLoss:0.46516506249506107 testLoss:0.5988023594249607 trainLossDiff:-1.7631820125835196E-4 testLossDiff:-9.613954322329477E-5
Iteration: 9 trainLoss:0.46503808007406217 testLoss:0.5985944728289061 trainLossDiff:-1.2698242099890011E-4 testLossDiff:-2.0788659605464055E-4
Iteration: 10 trainLoss:0.46489337952078474 testLoss:0.5985426260865596 trainLossDiff:-1.4470055327742148E-4 testLossDiff:-5.184674234648412E-5
Iteration: 11 trainLoss:0.4647933375965113 testLoss:0.5983729589077905 trainLossDiff:-1.0004192427343073E-4 testLossDiff:-1.696671787690951E-4
Iteration: 12 trainLoss:0.4647008312971414 testLoss:0.5982232298720003 trainLossDiff:-9.250629936990995E-5 testLossDiff:-1.49729035790247E-4
Iteration: 13 trainLoss:0.46460275148628105 testLoss:0.5981669549742868 trainLossDiff:-9.8079810860352E-5 testLossDiff:-5.627489771342642E-5
Iteration: 14 trainLoss:0.4645223409194764 testLoss:0.5980809099491463 trainLossDiff:-8.041056680463399E-5 testLossDiff:-8.604502514053536E-5
Iteration: 15 trainLoss:0.4644496673063095 testLoss:0.5980001892677786 trainLossDiff:-7.267361316692922E-5 testLossDiff:-8.072068136766308E-5
Iteration: 16 trainLoss:0.46437647491836687 testLoss:0.5979755188310327 trainLossDiff:-7.319238794262217E-5 testLossDiff:-2.467043674592162E-5
Iteration: 17 trainLoss:0.46432797301336404 testLoss:0.5978817299317125 trainLossDiff:-4.850190500282903E-5 testLossDiff:-9.378889932021295E-5
Iteration: 18 trainLoss:0.46427425385835397 testLoss:0.5978346805226711 trainLossDiff:-5.3719155010067965E-5 testLossDiff:-4.7049409041433066E-5
Iteration: 19 trainLoss:0.4642319340421487 testLoss:0.5977752597050415 trainLossDiff:-4.231981620528291E-5 testLossDiff:-5.942081762955187E-5
Iteration: 20 trainLoss:0.4641778645756206 testLoss:0.5977842490958702 trainLossDiff:-5.4069466528083865E-5 testLossDiff:8.989390828717525E-6
Iteration: 21 trainLoss:0.4641424687619725 testLoss:0.5977441749347081 trainLossDiff:-3.539581364808697E-5 testLossDiff:-4.007416116214024E-5
Iteration: 22 trainLoss:0.46410812939081025 testLoss:0.5977074229169417 trainLossDiff:-3.4339371162261934E-5 testLossDiff:-3.6752017766428224E-5
Iteration: 23 trainLoss:0.46406753221110336 testLoss:0.5977297529340646 trainLossDiff:-4.0597179706891584E-5 testLossDiff:2.2330017122929036E-5
Iteration: 24 trainLoss:0.46404996439427576 testLoss:0.5976591096517743 trainLossDiff:-1.7567816827601668E-5 testLossDiff:-7.064328229033912E-5
Iteration: 25 trainLoss:0.46403620175563987 testLoss:0.5975808167862906 trainLossDiff:-1.3762638635894664E-5 testLossDiff:-7.829286548366454E-5
Iteration: 26 trainLoss:0.4639963965954814 testLoss:0.5976220101387285 trainLossDiff:-3.980516015844593E-5 testLossDiff:4.1193352437907116E-5
Iteration: 27 trainLoss:0.46397982382333364 testLoss:0.5975956988617155 trainLossDiff:-1.6572772147782633E-5 testLossDiff:-2.6311277013024714E-5
Iteration: 28 trainLoss:0.46397051648767335 testLoss:0.5975383446237443 trainLossDiff:-9.307335660291294E-6 testLossDiff:-5.7354237971152244E-5
Iteration: 29 trainLoss:0.46395705435074924 testLoss:0.5975147880817906 trainLossDiff:-1.3462136924102808E-5 testLossDiff:-2.3556541953739796E-5
Iteration: 30 trainLoss:0.4639355978191209 testLoss:0.5975357197762867 trainLossDiff:-2.1456531628327724E-5 testLossDiff:2.0931694496129083E-5
Learned weights: -0.3159807430616754 1.913944264365867 2.715971722469406
