Iteration: 1 trainLoss:0.5265169252016715 testLoss:0.44513613920907974
Iteration: 2 trainLoss:0.5255590055733894 testLoss:0.4439776930527388 trainLossDiff:-9.579196282820668E-4 testLossDiff:-0.0011584461563409199
Iteration: 3 trainLoss:0.5251884249858281 testLoss:0.44376845684850164 trainLossDiff:-3.7058058756134216E-4 testLossDiff:-2.0923620423718425E-4
Iteration: 4 trainLoss:0.5249195393244745 testLoss:0.4436952915602201 trainLossDiff:-2.68885661353524E-4 testLossDiff:-7.316528828155144E-5
Iteration: 5 trainLoss:0.5246883573900019 testLoss:0.44363567681272303 trainLossDiff:-2.3118193447269064E-4 testLossDiff:-5.961474749704987E-5
Iteration: 6 trainLoss:0.5244678945506095 testLoss:0.44352685153607113 trainLossDiff:-2.2046283939236577E-4 testLossDiff:-1.0882527665190267E-4
Iteration: 7 trainLoss:0.52428982678521 testLoss:0.44347818081977336 trainLossDiff:-1.780677653995255E-4 testLossDiff:-4.8670716297771754E-5
Iteration: 8 trainLoss:0.5241345167350261 testLoss:0.44342944911961873 trainLossDiff:-1.5531005018387667E-4 testLossDiff:-4.8731700154625024E-5
Iteration: 9 trainLoss:0.5239742468193755 testLoss:0.4433175944310794 trainLossDiff:-1.6026991565054605E-4 testLossDiff:-1.1185468853935898E-4
Iteration: 10 trainLoss:0.5238751225516729 testLoss:0.44334538605723167 trainLossDiff:-9.912426770264382E-5 testLossDiff:2.7791626152295912E-5
Iteration: 11 trainLoss:0.5237483285101892 testLoss:0.44325825890667025 trainLossDiff:-1.267940414837465E-4 testLossDiff:-8.712715056141684E-5
Iteration: 12 trainLoss:0.5236605879396451 testLoss:0.44324260593331255 trainLossDiff:-8.774057054405926E-5 testLossDiff:-1.565297335770488E-5
Iteration: 13 trainLoss:0.5235703507552771 testLoss:0.4431905829067577 trainLossDiff:-9.023718436795836E-5 testLossDiff:-5.2023026554826046E-5
Iteration: 14 trainLoss:0.5235030602222144 testLoss:0.4431799359512901 trainLossDiff:-6.729053306275823E-5 testLossDiff:-1.0646955467596975E-5
Iteration: 15 trainLoss:0.5234444759085987 testLoss:0.44316622615793144 trainLossDiff:-5.858431361571714E-5 testLossDiff:-1.370979335868494E-5
Iteration: 16 trainLoss:0.5233709650624203 testLoss:0.4430964807874717 trainLossDiff:-7.351084617834847E-5 testLossDiff:-6.97453704597284E-5
Iteration: 17 trainLoss:0.5233415972567084 testLoss:0.4431378914482226 trainLossDiff:-2.9367805711943973E-5 testLossDiff:4.1410660750862416E-5
Iteration: 18 trainLoss:0.5232876491122999 testLoss:0.4430961508539548 trainLossDiff:-5.3948144408511034E-5 testLossDiff:-4.1740594267758446E-5
Iteration: 19 trainLoss:0.5232561800326436 testLoss:0.4431111099206565 trainLossDiff:-3.1469079656232246E-5 testLossDiff:1.495906670168079E-5
Iteration: 20 trainLoss:0.5232347166460084 testLoss:0.44314213154117366 trainLossDiff:-2.146338663522318E-5 testLossDiff:3.102162051715762E-5
Iteration: 21 trainLoss:0.523187993908123 testLoss:0.44308036665321177 trainLossDiff:-4.6722737885418475E-5 testLossDiff:-6.176488796189039E-5
Iteration: 22 trainLoss:0.5231541097729419 testLoss:0.4430499536285602 trainLossDiff:-3.3884135181128094E-5 testLossDiff:-3.041302465156548E-5
Iteration: 23 trainLoss:0.5231249017516405 testLoss:0.44302184852876575 trainLossDiff:-2.920802130135236E-5 testLossDiff:-2.8105099794450972E-5
Iteration: 24 trainLoss:0.5230982732468482 testLoss:0.44300059171271616 trainLossDiff:-2.6628504792292063E-5 testLossDiff:-2.125681604958629E-5
Iteration: 25 trainLoss:0.5230863285635298 testLoss:0.44300967627585 trainLossDiff:-1.1944683318443339E-5 testLossDiff:9.084563133809898E-6
Iteration: 26 trainLoss:0.5230824792364306 testLoss:0.44303529249083307 trainLossDiff:-3.849327099181288E-6 testLossDiff:2.5616214983092966E-5
Iteration: 27 trainLoss:0.5230504246334919 testLoss:0.44298127502529716 trainLossDiff:-3.2054602938647037E-5 testLossDiff:-5.401746553590492E-5
Iteration: 28 trainLoss:0.5230513970305858 testLoss:0.4430209931888347 trainLossDiff:9.723970938457782E-7 testLossDiff:3.9718163537538764E-5
Iteration: 29 trainLoss:0.5230381905902683 testLoss:0.4430056866171607 trainLossDiff:-1.3206440317437007E-5 testLossDiff:-1.5306571673978642E-5
Iteration: 30 trainLoss:0.5230227142030508 testLoss:0.4429776846058339 trainLossDiff:-1.547638721755007E-5 testLossDiff:-2.8002011326799803E-5
Learned weights: 0.8391072796751549 1.8636682822184651 2.487752406040877
