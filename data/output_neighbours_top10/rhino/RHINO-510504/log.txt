Iteration: 1 trainLoss:0.48117374741857305 testLoss:0.47876448822810785
Iteration: 2 trainLoss:0.4805220187500068 testLoss:0.4790378571969487 trainLossDiff:-6.51728668566276E-4 testLossDiff:2.7336896884083695E-4
Iteration: 3 trainLoss:0.4801721908406863 testLoss:0.4786293038848661 trainLossDiff:-3.49827909320477E-4 testLossDiff:-4.085533120826157E-4
Iteration: 4 trainLoss:0.47988305737100656 testLoss:0.478220948382871 trainLossDiff:-2.891334696797365E-4 testLossDiff:-4.083555019950835E-4
Iteration: 5 trainLoss:0.47964006806188664 testLoss:0.4778072264178219 trainLossDiff:-2.4298930911992311E-4 testLossDiff:-4.137219650490742E-4
Iteration: 6 trainLoss:0.47941545162422655 testLoss:0.477493202435881 trainLossDiff:-2.2461643766008565E-4 testLossDiff:-3.140239819409141E-4
Iteration: 7 trainLoss:0.47921698032059235 testLoss:0.47722731920462047 trainLossDiff:-1.9847130363420673E-4 testLossDiff:-2.6588323126053304E-4
Iteration: 8 trainLoss:0.4790478970896528 testLoss:0.4769608767651199 trainLossDiff:-1.6908323093955957E-4 testLossDiff:-2.6644243950058044E-4
Iteration: 9 trainLoss:0.47889821432039176 testLoss:0.4767287575627201 trainLossDiff:-1.4968276926102808E-4 testLossDiff:-2.3211920239979422E-4
Iteration: 10 trainLoss:0.4787637128386786 testLoss:0.4765653725156643 trainLossDiff:-1.3450148171317844E-4 testLossDiff:-1.6338504705581958E-4
Iteration: 11 trainLoss:0.47864632369942595 testLoss:0.4763869665085049 trainLossDiff:-1.1738913925263272E-4 testLossDiff:-1.784060071593485E-4
Iteration: 12 trainLoss:0.47854045855483396 testLoss:0.47622656828434934 trainLossDiff:-1.0586514459198781E-4 testLossDiff:-1.6039822415558902E-4
Iteration: 13 trainLoss:0.4784438479641286 testLoss:0.47609854838353716 trainLossDiff:-9.661059070537048E-5 testLossDiff:-1.2801990081218184E-4
Iteration: 14 trainLoss:0.4783646755795658 testLoss:0.4759552635569586 trainLossDiff:-7.917238456278675E-5 testLossDiff:-1.4328482657854913E-4
Iteration: 15 trainLoss:0.4782885643800837 testLoss:0.47585308954331007 trainLossDiff:-7.611119948208733E-5 testLossDiff:-1.0217401364853718E-4
Iteration: 16 trainLoss:0.47821651542075094 testLoss:0.4757847998266773 trainLossDiff:-7.204895933277111E-5 testLossDiff:-6.82897166327523E-5
Iteration: 17 trainLoss:0.4781645271373057 testLoss:0.47568131097981264 trainLossDiff:-5.198828344527007E-5 testLossDiff:-1.0348884686467441E-4
Iteration: 18 trainLoss:0.4781141548755363 testLoss:0.4756021340137235 trainLossDiff:-5.037226176934917E-5 testLossDiff:-7.917696608916724E-5
Iteration: 19 trainLoss:0.47806589767296825 testLoss:0.4755436170036871 trainLossDiff:-4.8257202568069424E-5 testLossDiff:-5.851701003639631E-5
Iteration: 20 trainLoss:0.4780234677329759 testLoss:0.4755017390343544 trainLossDiff:-4.242993999237221E-5 testLossDiff:-4.1877969332693166E-5
Iteration: 21 trainLoss:0.4779918819057986 testLoss:0.4754190474066806 trainLossDiff:-3.1585827177271764E-5 testLossDiff:-8.269162767376992E-5
Iteration: 22 trainLoss:0.47796082324716077 testLoss:0.4753550514049375 trainLossDiff:-3.105865863783919E-5 testLossDiff:-6.399600174311626E-5
Iteration: 23 trainLoss:0.4779321973759642 testLoss:0.4753053024370464 trainLossDiff:-2.862587119656368E-5 testLossDiff:-4.974896789111671E-5
Iteration: 24 trainLoss:0.47789404929925855 testLoss:0.47531973391218607 trainLossDiff:-3.814807670565745E-5 testLossDiff:1.4431475139686789E-5
Iteration: 25 trainLoss:0.47788283300222917 testLoss:0.4752244849132884 trainLossDiff:-1.121629702938165E-5 testLossDiff:-9.524899889767902E-5
Iteration: 26 trainLoss:0.4778531362236489 testLoss:0.475244974598968 trainLossDiff:-2.9696778580279304E-5 testLossDiff:2.0489685679581093E-5
Iteration: 27 trainLoss:0.47783966669664385 testLoss:0.4751887142054827 trainLossDiff:-1.3469527005038895E-5 testLossDiff:-5.626039348527456E-5
Iteration: 28 trainLoss:0.47782110624195784 testLoss:0.47517591365260703 trainLossDiff:-1.8560454686011862E-5 testLossDiff:-1.2800552875669169E-5
Iteration: 29 trainLoss:0.47783039478252276 testLoss:0.4750240874916122 trainLossDiff:9.288540564922343E-6 testLossDiff:-1.5182616099485013E-4
Iteration: 30 trainLoss:0.47779297162808565 testLoss:0.4751183142105573 trainLossDiff:-3.742315443711064E-5 testLossDiff:9.422671894510071E-5
Learned weights: 0.3654841542894133 1.937743501650885 2.5166076951776404
