Iteration: 1 trainLoss:0.5409920177401158 testLoss:0.44236582084734205
Iteration: 2 trainLoss:0.5401214884137295 testLoss:0.44110052819758033 trainLossDiff:-8.705293263863156E-4 testLossDiff:-0.0012652926497617178
Iteration: 3 trainLoss:0.5398232903983278 testLoss:0.440683376637908 trainLossDiff:-2.981980154017627E-4 testLossDiff:-4.17151559672313E-4
Iteration: 4 trainLoss:0.5396394133437998 testLoss:0.440435796266052 trainLossDiff:-1.8387705452793668E-4 testLossDiff:-2.4758037185601545E-4
Iteration: 5 trainLoss:0.5394504274684119 testLoss:0.4401752879918336 trainLossDiff:-1.889858753879592E-4 testLossDiff:-2.605082742184184E-4
Iteration: 6 trainLoss:0.5392807652468931 testLoss:0.4399408035493108 trainLossDiff:-1.6966222151881816E-4 testLossDiff:-2.3448444252277545E-4
Iteration: 7 trainLoss:0.5391243562504292 testLoss:0.4397232117865889 trainLossDiff:-1.5640899646385265E-4 testLossDiff:-2.1759176272190262E-4
Iteration: 8 trainLoss:0.5390141932849807 testLoss:0.43957496864705803 trainLossDiff:-1.1016296544852366E-4 testLossDiff:-1.482431395308792E-4
Iteration: 9 trainLoss:0.5389010676588495 testLoss:0.43941887501047483 trainLossDiff:-1.1312562613119415E-4 testLossDiff:-1.5609363658319886E-4
Iteration: 10 trainLoss:0.5387987488737003 testLoss:0.4392777460252248 trainLossDiff:-1.0231878514921355E-4 testLossDiff:-1.4112898525003859E-4
Iteration: 11 trainLoss:0.5386981594874019 testLoss:0.43913741203990486 trainLossDiff:-1.0058938629842196E-4 testLossDiff:-1.4033398531992924E-4
Iteration: 12 trainLoss:0.5386261316481822 testLoss:0.43904073077879485 trainLossDiff:-7.202783921966827E-5 testLossDiff:-9.668126111000985E-5
Iteration: 13 trainLoss:0.5385739193873035 testLoss:0.43897347777712004 trainLossDiff:-5.2212260878703454E-5 testLossDiff:-6.725300167481629E-5
Iteration: 14 trainLoss:0.5385166646852539 testLoss:0.4388958632820699 trainLossDiff:-5.72547020495362E-5 testLossDiff:-7.761449505011564E-5
Iteration: 15 trainLoss:0.5384495086798391 testLoss:0.43880098187337313 trainLossDiff:-6.71560054148479E-5 testLossDiff:-9.488140869678974E-5
Iteration: 16 trainLoss:0.5384015489155407 testLoss:0.4387352503020854 trainLossDiff:-4.795976429838866E-5 testLossDiff:-6.573157128775264E-5
Iteration: 17 trainLoss:0.5383559127120952 testLoss:0.4386729175526083 trainLossDiff:-4.563620344555375E-5 testLossDiff:-6.233274947708978E-5
Iteration: 18 trainLoss:0.5383343039427023 testLoss:0.4386481624713857 trainLossDiff:-2.1608769392833516E-5 testLossDiff:-2.475508122257164E-5
Iteration: 19 trainLoss:0.538304906161611 testLoss:0.43860922086738635 trainLossDiff:-2.9397781091344832E-5 testLossDiff:-3.894160399936508E-5
Iteration: 20 trainLoss:0.5382660120216339 testLoss:0.4385538387309487 trainLossDiff:-3.88941399770415E-5 testLossDiff:-5.538213643763168E-5
Iteration: 21 trainLoss:0.538226967416235 testLoss:0.4384973268366991 trainLossDiff:-3.904460539894128E-5 testLossDiff:-5.6511894249600125E-5
Iteration: 22 trainLoss:0.5382086154981423 testLoss:0.43847420074842797 trainLossDiff:-1.8351918092740505E-5 testLossDiff:-2.312608827115259E-5
Iteration: 23 trainLoss:0.538183455669111 testLoss:0.43843992055109193 trainLossDiff:-2.5159829031284886E-5 testLossDiff:-3.4280197336034046E-5
Iteration: 24 trainLoss:0.538198825947872 testLoss:0.438470475420549 trainLossDiff:1.537027876108432E-5 testLossDiff:3.055486945707786E-5
Iteration: 25 trainLoss:0.5381831169963693 testLoss:0.4384491942627775 trainLossDiff:-1.570895150271312E-5 testLossDiff:-2.128115777150219E-5
Iteration: 26 trainLoss:0.5381427255508607 testLoss:0.43838750390447184 trainLossDiff:-4.039144550860296E-5 testLossDiff:-6.169035830566605E-5
Iteration: 27 trainLoss:0.5381198341864629 testLoss:0.43835485932010654 trainLossDiff:-2.2891364397814584E-5 testLossDiff:-3.2644584365304485E-5
Iteration: 28 trainLoss:0.5381131743505461 testLoss:0.4383474182620229 trainLossDiff:-6.659835916855705E-6 testLossDiff:-7.441058083645924E-6
Iteration: 29 trainLoss:0.5381279522228376 testLoss:0.4383745948749592 trainLossDiff:1.4777872291538152E-5 testLossDiff:2.7176612936330447E-5
Iteration: 30 trainLoss:0.5381199961842013 testLoss:0.4383630387206161 trainLossDiff:-7.956038636347529E-6 testLossDiff:-1.155615434311752E-5
Learned weights: 0.2342545183238399 1.7596811172723024 2.4729691474713498
