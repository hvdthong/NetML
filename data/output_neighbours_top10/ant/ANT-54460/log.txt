Iteration: 1 trainLoss:0.5181675117811475 testLoss:0.36125471694822947
Iteration: 2 trainLoss:0.5153838232329562 testLoss:0.36360809395971905 trainLossDiff:-0.002783688548191332 testLossDiff:0.002353377011489577
Iteration: 3 trainLoss:0.514582983299668 testLoss:0.3642698033467368 trainLossDiff:-8.008399332881666E-4 testLossDiff:6.617093870177615E-4
Iteration: 4 trainLoss:0.5139509411465367 testLoss:0.3643475344404817 trainLossDiff:-6.320421531312848E-4 testLossDiff:7.773109374487053E-5
Iteration: 5 trainLoss:0.5134163689020205 testLoss:0.3644029716378972 trainLossDiff:-5.345722445162515E-4 testLossDiff:5.543719741551989E-5
Iteration: 6 trainLoss:0.5129650384682816 testLoss:0.3642846169244436 trainLossDiff:-4.513304337389057E-4 testLossDiff:-1.183547134536167E-4
Iteration: 7 trainLoss:0.5125367508273453 testLoss:0.36430957435662725 trainLossDiff:-4.282876409362757E-4 testLossDiff:2.495743218366986E-5
Iteration: 8 trainLoss:0.512132730204602 testLoss:0.36417734792946127 trainLossDiff:-4.040206227432508E-4 testLossDiff:-1.3222642716598232E-4
Iteration: 9 trainLoss:0.511781174555203 testLoss:0.36415228593276977 trainLossDiff:-3.5155564939903794E-4 testLossDiff:-2.50619966915E-5
Iteration: 10 trainLoss:0.5114772803279443 testLoss:0.3641015930384166 trainLossDiff:-3.038942272587386E-4 testLossDiff:-5.069289435316593E-5
Iteration: 11 trainLoss:0.5111332287111012 testLoss:0.3640413521104369 trainLossDiff:-3.44051616843033E-4 testLossDiff:-6.024092797968228E-5
Iteration: 12 trainLoss:0.5108632164954214 testLoss:0.3641035460664978 trainLossDiff:-2.700122156797935E-4 testLossDiff:6.219395606088529E-5
Iteration: 13 trainLoss:0.5106117905109347 testLoss:0.3640322287382667 trainLossDiff:-2.514259844866862E-4 testLossDiff:-7.131732823112413E-5
Iteration: 14 trainLoss:0.5103670026393317 testLoss:0.36397391947045316 trainLossDiff:-2.4478787160309157E-4 testLossDiff:-5.830926781352774E-5
Iteration: 15 trainLoss:0.5101413688460885 testLoss:0.36393158054903363 trainLossDiff:-2.256337932431407E-4 testLossDiff:-4.233892141952689E-5
Iteration: 16 trainLoss:0.5099368113727515 testLoss:0.3639092297116461 trainLossDiff:-2.0455747333703034E-4 testLossDiff:-2.2350837387552502E-5
Iteration: 17 trainLoss:0.5097112364156492 testLoss:0.3639839115015204 trainLossDiff:-2.2557495710229247E-4 testLossDiff:7.468178987429797E-5
Iteration: 18 trainLoss:0.5095593062748169 testLoss:0.3639623861536812 trainLossDiff:-1.519301408322571E-4 testLossDiff:-2.1525347839168596E-5
Iteration: 19 trainLoss:0.5093623851416612 testLoss:0.36387350991388956 trainLossDiff:-1.9692113315572524E-4 testLossDiff:-8.88762397916465E-5
Iteration: 20 trainLoss:0.5091930022252351 testLoss:0.36387156848776675 trainLossDiff:-1.6938291642609737E-4 testLossDiff:-1.941426122809009E-6
Iteration: 21 trainLoss:0.5090372165657941 testLoss:0.36384328660026805 trainLossDiff:-1.5578565944096567E-4 testLossDiff:-2.8281887498704528E-5
Iteration: 22 trainLoss:0.5089044467421303 testLoss:0.36388921828003024 trainLossDiff:-1.3276982366383638E-4 testLossDiff:4.5931679762190036E-5
Iteration: 23 trainLoss:0.5087811203103554 testLoss:0.3638212815915569 trainLossDiff:-1.233264317749283E-4 testLossDiff:-6.793668847332457E-5
Iteration: 24 trainLoss:0.5086606562018846 testLoss:0.3638040550442298 trainLossDiff:-1.2046410847077471E-4 testLossDiff:-1.7226547327109376E-5
Iteration: 25 trainLoss:0.5085295334647162 testLoss:0.3638290899277383 trainLossDiff:-1.3112273716842093E-4 testLossDiff:2.5034883508523453E-5
Iteration: 26 trainLoss:0.508384246740825 testLoss:0.3637921477501687 trainLossDiff:-1.4528672389113595E-4 testLossDiff:-3.6942177569609935E-5
Iteration: 27 trainLoss:0.5082931339531014 testLoss:0.36378470930244255 trainLossDiff:-9.111278772366838E-5 testLossDiff:-7.438447726160202E-6
Iteration: 28 trainLoss:0.5081851499807538 testLoss:0.36378754094899934 trainLossDiff:-1.0798397234756951E-4 testLossDiff:2.8316465567890248E-6
Iteration: 29 trainLoss:0.5080952859522978 testLoss:0.3637699592119336 trainLossDiff:-8.986402845601038E-5 testLossDiff:-1.758173706573052E-5
Iteration: 30 trainLoss:0.5080080916792465 testLoss:0.3637629624667484 trainLossDiff:-8.719427305126093E-5 testLossDiff:-6.9967451852281926E-6
Learned weights: 10.939556928269809 19.155882413030135 0.38392315201091454
