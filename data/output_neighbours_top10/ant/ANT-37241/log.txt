Iteration: 1 trainLoss:0.4931328474969456 testLoss:0.4902684074378683
Iteration: 2 trainLoss:0.4889312647674422 testLoss:0.476854750248885 trainLossDiff:-0.004201582729503384 testLossDiff:-0.013413657188983297
Iteration: 3 trainLoss:0.48727528707055584 testLoss:0.47299682368579904 trainLossDiff:-0.001655977696886357 testLossDiff:-0.0038579265630859783
Iteration: 4 trainLoss:0.4861872680700539 testLoss:0.4708891357853456 trainLossDiff:-0.0010880190005019275 testLossDiff:-0.0021076879004534588
Iteration: 5 trainLoss:0.48535687749297307 testLoss:0.4698825462730708 trainLossDiff:-8.303905770808417E-4 testLossDiff:-0.0010065895122747803
Iteration: 6 trainLoss:0.48468060485662795 testLoss:0.469257870145555 trainLossDiff:-6.76272636345121E-4 testLossDiff:-6.246761275158219E-4
Iteration: 7 trainLoss:0.484101911432697 testLoss:0.46851346356402623 trainLossDiff:-5.786934239309649E-4 testLossDiff:-7.444065815287448E-4
Iteration: 8 trainLoss:0.4836047504156038 testLoss:0.4680356008210427 trainLossDiff:-4.971610170931839E-4 testLossDiff:-4.7786274298355913E-4
Iteration: 9 trainLoss:0.4831998838624647 testLoss:0.46821801638958993 trainLossDiff:-4.048665531390938E-4 testLossDiff:1.8241556854725616E-4
Iteration: 10 trainLoss:0.48281363416098727 testLoss:0.46759968736801594 trainLossDiff:-3.8624970147743687E-4 testLossDiff:-6.183290215739934E-4
Iteration: 11 trainLoss:0.482486553185052 testLoss:0.46744571331483975 trainLossDiff:-3.2708097593525665E-4 testLossDiff:-1.5397405317618684E-4
Iteration: 12 trainLoss:0.48220302560156403 testLoss:0.46722055828969794 trainLossDiff:-2.835275834879858E-4 testLossDiff:-2.2515502514180996E-4
Iteration: 13 trainLoss:0.48194750754226945 testLoss:0.46708102152792585 trainLossDiff:-2.555180592945794E-4 testLossDiff:-1.3953676177208552E-4
Iteration: 14 trainLoss:0.481713465821038 testLoss:0.46697802938362704 trainLossDiff:-2.3404172123142608E-4 testLossDiff:-1.0299214429881909E-4
Iteration: 15 trainLoss:0.481527629305427 testLoss:0.467290057393751 trainLossDiff:-1.8583651561104864E-4 testLossDiff:3.1202801012397696E-4
Iteration: 16 trainLoss:0.48130927775337345 testLoss:0.46653600701757975 trainLossDiff:-2.1835155205351953E-4 testLossDiff:-7.540503761712669E-4
Iteration: 17 trainLoss:0.48113285414102164 testLoss:0.46630852751007723 trainLossDiff:-1.7642361235181703E-4 testLossDiff:-2.274795075025149E-4
Iteration: 18 trainLoss:0.4810068223213458 testLoss:0.46704986549895633 trainLossDiff:-1.2603181967585364E-4 testLossDiff:7.413379888790983E-4
Iteration: 19 trainLoss:0.48084652320405064 testLoss:0.4665987129538744 trainLossDiff:-1.6029911729514845E-4 testLossDiff:-4.5115254508193425E-4
Iteration: 20 trainLoss:0.4807322708316843 testLoss:0.4668471595346007 trainLossDiff:-1.1425237236634134E-4 testLossDiff:2.4844658072631365E-4
Iteration: 21 trainLoss:0.4805996004381679 testLoss:0.4666006593380373 trainLossDiff:-1.3267039351638754E-4 testLossDiff:-2.4650019656341504E-4
Iteration: 22 trainLoss:0.4804668608063954 testLoss:0.46590607745930757 trainLossDiff:-1.3273963177251602E-4 testLossDiff:-6.945818787297275E-4
Iteration: 23 trainLoss:0.4803794182724548 testLoss:0.46634550949092535 trainLossDiff:-8.744253394060708E-5 testLossDiff:4.394320316177813E-4
Iteration: 24 trainLoss:0.4802760807325717 testLoss:0.46609846580652536 trainLossDiff:-1.0333753988306382E-4 testLossDiff:-2.470436843999835E-4
Iteration: 25 trainLoss:0.48018334125939016 testLoss:0.4657771629690711 trainLossDiff:-9.273947318155784E-5 testLossDiff:-3.213028374542404E-4
Iteration: 26 trainLoss:0.4801333684341142 testLoss:0.4667726020221198 trainLossDiff:-4.9972825275967914E-5 testLossDiff:9.954390530486634E-4
Iteration: 27 trainLoss:0.4800441165475831 testLoss:0.46646891170130755 trainLossDiff:-8.925188653108318E-5 testLossDiff:-3.0369032081223324E-4
Iteration: 28 trainLoss:0.4799830895455528 testLoss:0.46667587572733876 trainLossDiff:-6.102700203031164E-5 testLossDiff:2.069640260312089E-4
Iteration: 29 trainLoss:0.4798947991482918 testLoss:0.4661570697242867 trainLossDiff:-8.829039726099275E-5 testLossDiff:-5.188060030520414E-4
Iteration: 30 trainLoss:0.47986646737803396 testLoss:0.4667802938840219 trainLossDiff:-2.8331770257850053E-5 testLossDiff:6.232241597352028E-4
Learned weights: 8.775524959242295 21.274931251781318 0.23683986780412003
