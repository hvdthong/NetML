Iteration: 1 trainLoss:0.509023112558717 testLoss:0.42909133235515506
Iteration: 2 trainLoss:0.5073118004212355 testLoss:0.43551942600884513 trainLossDiff:-0.0017113121374815465 testLossDiff:0.00642809365369007
Iteration: 3 trainLoss:0.5069242871070078 testLoss:0.43744986642325406 trainLossDiff:-3.875133142277054E-4 testLossDiff:0.0019304404144089293
Iteration: 4 trainLoss:0.5066601230491313 testLoss:0.43771523904521115 trainLossDiff:-2.6416405787643704E-4 testLossDiff:2.653726219570829E-4
Iteration: 5 trainLoss:0.506438993372585 testLoss:0.4373556513578427 trainLossDiff:-2.2112967654630555E-4 testLossDiff:-3.595876873684345E-4
Iteration: 6 trainLoss:0.5062478354996959 testLoss:0.4373280327454373 trainLossDiff:-1.911578728891472E-4 testLossDiff:-2.761861240541119E-5
Iteration: 7 trainLoss:0.5060276200799129 testLoss:0.43664637354062014 trainLossDiff:-2.2021541978300974E-4 testLossDiff:-6.816592048171644E-4
Iteration: 8 trainLoss:0.5058404747119551 testLoss:0.4366247063202908 trainLossDiff:-1.8714536795771952E-4 testLossDiff:-2.166722032931334E-5
Iteration: 9 trainLoss:0.5056675160707218 testLoss:0.4363250658205437 trainLossDiff:-1.7295864123334503E-4 testLossDiff:-2.996404997471225E-4
Iteration: 10 trainLoss:0.5055056147214659 testLoss:0.4361440808239376 trainLossDiff:-1.619013492558663E-4 testLossDiff:-1.809849966061261E-4
Iteration: 11 trainLoss:0.505330907344434 testLoss:0.43578816431329165 trainLossDiff:-1.7470737703195738E-4 testLossDiff:-3.559165106459261E-4
Iteration: 12 trainLoss:0.5051732419571359 testLoss:0.43540449602077164 trainLossDiff:-1.5766538729811153E-4 testLossDiff:-3.836682925200119E-4
Iteration: 13 trainLoss:0.5050139161170333 testLoss:0.4350991012941898 trainLossDiff:-1.5932584010258655E-4 testLossDiff:-3.053947265818091E-4
Iteration: 14 trainLoss:0.5048643057374026 testLoss:0.4351953921834486 trainLossDiff:-1.4961037963068247E-4 testLossDiff:9.62908892587766E-5
Iteration: 15 trainLoss:0.5047281135594109 testLoss:0.43494283456958155 trainLossDiff:-1.361921779916564E-4 testLossDiff:-2.525576138670549E-4
Iteration: 16 trainLoss:0.5045696690552977 testLoss:0.43440562528392634 trainLossDiff:-1.5844450411328648E-4 testLossDiff:-5.372092856552046E-4
Iteration: 17 trainLoss:0.5044561953016832 testLoss:0.4345674892790648 trainLossDiff:-1.134737536144792E-4 testLossDiff:1.6186399513845595E-4
Iteration: 18 trainLoss:0.5043268004948142 testLoss:0.4343094488849066 trainLossDiff:-1.2939480686902094E-4 testLossDiff:-2.58040394158221E-4
Iteration: 19 trainLoss:0.5041901068700826 testLoss:0.43385655727611416 trainLossDiff:-1.3669362473156532E-4 testLossDiff:-4.528916087924162E-4
Iteration: 20 trainLoss:0.5040799371620577 testLoss:0.4338759203756805 trainLossDiff:-1.1016970802490977E-4 testLossDiff:1.936309956634963E-5
Iteration: 21 trainLoss:0.503966138306041 testLoss:0.4337629186774475 trainLossDiff:-1.1379885601670026E-4 testLossDiff:-1.1300169823302841E-4
Iteration: 22 trainLoss:0.5038597273517968 testLoss:0.43366644239880353 trainLossDiff:-1.0641095424412939E-4 testLossDiff:-9.647627864395325E-5
Iteration: 23 trainLoss:0.5037575918873647 testLoss:0.43336322250674403 trainLossDiff:-1.0213546443216259E-4 testLossDiff:-3.0321989205950306E-4
Iteration: 24 trainLoss:0.5036532464705696 testLoss:0.43330842509955103 trainLossDiff:-1.043454167950486E-4 testLossDiff:-5.479740719299686E-5
Iteration: 25 trainLoss:0.5035436941266946 testLoss:0.4329493628564711 trainLossDiff:-1.095523438749968E-4 testLossDiff:-3.5906224307991064E-4
Iteration: 26 trainLoss:0.5034545793991835 testLoss:0.43303471497397894 trainLossDiff:-8.911472751116367E-5 testLossDiff:8.535211750781979E-5
Iteration: 27 trainLoss:0.5033568664617063 testLoss:0.43269878647210275 trainLossDiff:-9.771293747717902E-5 testLossDiff:-3.359285018761926E-4
Iteration: 28 trainLoss:0.5032678906540766 testLoss:0.4324439150484313 trainLossDiff:-8.89758076296765E-5 testLossDiff:-2.548714236714211E-4
Iteration: 29 trainLoss:0.5031860741162759 testLoss:0.4323634895942938 trainLossDiff:-8.181653780070519E-5 testLossDiff:-8.042545413750046E-5
Iteration: 30 trainLoss:0.5030985014341078 testLoss:0.4321598989087289 trainLossDiff:-8.757268216808001E-5 testLossDiff:-2.035906855649139E-4
Learned weights: 11.214914821766124 14.165619027706295 1.84850245508371
