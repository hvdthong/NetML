Iteration: 1 trainLoss:0.49126919106376143 testLoss:0.4125423358900947
Iteration: 2 trainLoss:0.4885877642186462 testLoss:0.4139466532208639 trainLossDiff:-0.0026814268451152423 testLossDiff:0.001404317330769178
Iteration: 3 trainLoss:0.4876013538722134 testLoss:0.4134341919174281 trainLossDiff:-9.864103464327645E-4 testLossDiff:-5.124613034357961E-4
Iteration: 4 trainLoss:0.48695188208991175 testLoss:0.4125628604813908 trainLossDiff:-6.494717823016805E-4 testLossDiff:-8.713314360372926E-4
Iteration: 5 trainLoss:0.48647226735778326 testLoss:0.411476977245761 trainLossDiff:-4.7961473212848604E-4 testLossDiff:-0.0010858832356298032
Iteration: 6 trainLoss:0.48606803020773726 testLoss:0.4105497297355257 trainLossDiff:-4.0423715004600513E-4 testLossDiff:-9.272475102352629E-4
Iteration: 7 trainLoss:0.48573932115491114 testLoss:0.4097176971119298 trainLossDiff:-3.2870905282611496E-4 testLossDiff:-8.320326235959352E-4
Iteration: 8 trainLoss:0.4854630298091718 testLoss:0.40886703271880276 trainLossDiff:-2.7629134573936565E-4 testLossDiff:-8.506643931270319E-4
Iteration: 9 trainLoss:0.48522473690515544 testLoss:0.40828216329230055 trainLossDiff:-2.3829290401633507E-4 testLossDiff:-5.848694265022103E-4
Iteration: 10 trainLoss:0.4850237103001144 testLoss:0.4076373512212744 trainLossDiff:-2.0102660504106584E-4 testLossDiff:-6.44812071026124E-4
Iteration: 11 trainLoss:0.48484143559453224 testLoss:0.40711762952880315 trainLossDiff:-1.8227470558213055E-4 testLossDiff:-5.197216924712755E-4
Iteration: 12 trainLoss:0.48468386904557004 testLoss:0.40671116437370447 trainLossDiff:-1.575665489622069E-4 testLossDiff:-4.0646515509867864E-4
Iteration: 13 trainLoss:0.4845441671795561 testLoss:0.4063589199296609 trainLossDiff:-1.3970186601391932E-4 testLossDiff:-3.5224444404358124E-4
Iteration: 14 trainLoss:0.4844249477725156 testLoss:0.40593499750011136 trainLossDiff:-1.1921940704051615E-4 testLossDiff:-4.239224295495281E-4
Iteration: 15 trainLoss:0.48431581724906736 testLoss:0.40560792554756375 trainLossDiff:-1.0913052344824203E-4 testLossDiff:-3.2707195254760846E-4
Iteration: 16 trainLoss:0.4842175723510883 testLoss:0.40538557083592175 trainLossDiff:-9.824489797904956E-5 testLossDiff:-2.2235471164200327E-4
Iteration: 17 trainLoss:0.48413250222971754 testLoss:0.40513716519234955 trainLossDiff:-8.50701213707672E-5 testLossDiff:-2.4840564357220263E-4
Iteration: 18 trainLoss:0.48405444694036287 testLoss:0.4048257949628606 trainLossDiff:-7.805528935467265E-5 testLossDiff:-3.1137022948896087E-4
Iteration: 19 trainLoss:0.48398324057939 testLoss:0.40454946435236905 trainLossDiff:-7.120636097285304E-5 testLossDiff:-2.763306104915375E-4
Iteration: 20 trainLoss:0.4839201421711183 testLoss:0.4043478314717404 trainLossDiff:-6.309840827173341E-5 testLossDiff:-2.0163288062863272E-4
Iteration: 21 trainLoss:0.4838585688945125 testLoss:0.4041593412283844 trainLossDiff:-6.157327660577527E-5 testLossDiff:-1.8849024335604314E-4
Iteration: 22 trainLoss:0.48379413948775285 testLoss:0.4041342492169314 trainLossDiff:-6.442940675965847E-5 testLossDiff:-2.5092011452954033E-5
Iteration: 23 trainLoss:0.48374754986049995 testLoss:0.4039182124537309 trainLossDiff:-4.6589627252902055E-5 testLossDiff:-2.1603676320053333E-4
Iteration: 24 trainLoss:0.48370249814200494 testLoss:0.4037875178515453 trainLossDiff:-4.505171849500389E-5 testLossDiff:-1.3069460218556594E-4
Iteration: 25 trainLoss:0.4836574733081495 testLoss:0.40357476584667934 trainLossDiff:-4.5024833855433766E-5 testLossDiff:-2.1275200486597923E-4
Iteration: 26 trainLoss:0.48362611450739923 testLoss:0.40352817941291064 trainLossDiff:-3.1358800750280746E-5 testLossDiff:-4.658643376870275E-5
Iteration: 27 trainLoss:0.4835785683394235 testLoss:0.4033412466583802 trainLossDiff:-4.754616797575384E-5 testLossDiff:-1.8693275453041114E-4
Iteration: 28 trainLoss:0.48355266579444706 testLoss:0.40338669318223536 trainLossDiff:-2.5902544976419417E-5 testLossDiff:4.544652385513048E-5
Iteration: 29 trainLoss:0.4835192349661795 testLoss:0.4031829125617626 trainLossDiff:-3.3430828267566604E-5 testLossDiff:-2.03780620472771E-4
Iteration: 30 trainLoss:0.48349608096269203 testLoss:0.4032366130273474 trainLossDiff:-2.3154003487457775E-5 testLossDiff:5.370046558483832E-5
Learned weights: 11.502039784222939 15.629320347116613 0.6637074366937248
