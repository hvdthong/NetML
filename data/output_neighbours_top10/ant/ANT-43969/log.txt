Iteration: 1 trainLoss:0.5162963975960555 testLoss:0.5177220427756383
Iteration: 2 trainLoss:0.5127574834508755 testLoss:0.5072581591132195 trainLossDiff:-0.0035389141451800388 testLossDiff:-0.010463883662418794
Iteration: 3 trainLoss:0.5114652358474596 testLoss:0.5035131597630089 trainLossDiff:-0.0012922476034158414 testLossDiff:-0.003744999350210554
Iteration: 4 trainLoss:0.5105914942332893 testLoss:0.5016378830098895 trainLossDiff:-8.737416141703092E-4 testLossDiff:-0.0018752767531193815
Iteration: 5 trainLoss:0.5098917471707117 testLoss:0.5005717697602026 trainLossDiff:-6.997470625775826E-4 testLossDiff:-0.001066113249686973
Iteration: 6 trainLoss:0.5092735963774764 testLoss:0.5000090730443725 trainLossDiff:-6.181507932353503E-4 testLossDiff:-5.626967158300911E-4
Iteration: 7 trainLoss:0.5087537841904001 testLoss:0.49925214647686833 trainLossDiff:-5.198121870763073E-4 testLossDiff:-7.569265675041459E-4
Iteration: 8 trainLoss:0.5082744035283417 testLoss:0.49871653823896966 trainLossDiff:-4.793806620583263E-4 testLossDiff:-5.35608237898666E-4
Iteration: 9 trainLoss:0.5078590526097287 testLoss:0.4981824754687566 trainLossDiff:-4.15350918613E-4 testLossDiff:-5.340627702130618E-4
Iteration: 10 trainLoss:0.5074666485353058 testLoss:0.49764732354757446 trainLossDiff:-3.9240407442298064E-4 testLossDiff:-5.35151921182142E-4
Iteration: 11 trainLoss:0.5071419577946312 testLoss:0.4972505873590517 trainLossDiff:-3.2469074067453807E-4 testLossDiff:-3.967361885227616E-4
Iteration: 12 trainLoss:0.5067971452301067 testLoss:0.49693113155943375 trainLossDiff:-3.448125645245659E-4 testLossDiff:-3.1945579961795145E-4
Iteration: 13 trainLoss:0.5065064954952812 testLoss:0.49654681205136464 trainLossDiff:-2.9064973482550993E-4 testLossDiff:-3.8431950806910864E-4
Iteration: 14 trainLoss:0.5062349594300355 testLoss:0.4962297795212903 trainLossDiff:-2.715360652456589E-4 testLossDiff:-3.1703253007431265E-4
Iteration: 15 trainLoss:0.505978939989534 testLoss:0.4958362211785081 trainLossDiff:-2.5601944050146486E-4 testLossDiff:-3.935583427822076E-4
Iteration: 16 trainLoss:0.5057486264371553 testLoss:0.49554963369426724 trainLossDiff:-2.3031355237868034E-4 testLossDiff:-2.8658748424087443E-4
Iteration: 17 trainLoss:0.5055325542671827 testLoss:0.49532397647999515 trainLossDiff:-2.1607216997265866E-4 testLossDiff:-2.256572142720903E-4
Iteration: 18 trainLoss:0.5053436080464746 testLoss:0.4951841679025232 trainLossDiff:-1.889462207080861E-4 testLossDiff:-1.3980857747197817E-4
Iteration: 19 trainLoss:0.5051473952485259 testLoss:0.49488197331229555 trainLossDiff:-1.9621279794868052E-4 testLossDiff:-3.021945902276224E-4
Iteration: 20 trainLoss:0.5049654404471672 testLoss:0.49457096112237875 trainLossDiff:-1.8195480135874131E-4 testLossDiff:-3.110121899168039E-4
Iteration: 21 trainLoss:0.5047972843802898 testLoss:0.49447780488749865 trainLossDiff:-1.681560668773674E-4 testLossDiff:-9.31562348800985E-5
Iteration: 22 trainLoss:0.5046411749483201 testLoss:0.4942852478053598 trainLossDiff:-1.5610943196975313E-4 testLossDiff:-1.9255708213883338E-4
Iteration: 23 trainLoss:0.5044904261001439 testLoss:0.49400799269968054 trainLossDiff:-1.5074884817611878E-4 testLossDiff:-2.772551056792749E-4
Iteration: 24 trainLoss:0.5043555758032745 testLoss:0.4939852764815339 trainLossDiff:-1.3485029686943761E-4 testLossDiff:-2.2716218146645595E-5
Iteration: 25 trainLoss:0.5042268168031636 testLoss:0.49387892591212085 trainLossDiff:-1.287590001108896E-4 testLossDiff:-1.0635056941304954E-4
Iteration: 26 trainLoss:0.5041011663719804 testLoss:0.4934054816904124 trainLossDiff:-1.2565043118317742E-4 testLossDiff:-4.7344422170847444E-4
Iteration: 27 trainLoss:0.5039946170505425 testLoss:0.4936183461324143 trainLossDiff:-1.0654932143794316E-4 testLossDiff:2.1286444200191434E-4
Iteration: 28 trainLoss:0.5038758176401031 testLoss:0.4933611956462205 trainLossDiff:-1.1879941043935194E-4 testLossDiff:-2.571504861937912E-4
Iteration: 29 trainLoss:0.5037707083612042 testLoss:0.49312901993250513 trainLossDiff:-1.0510927889895161E-4 testLossDiff:-2.3217571371536572E-4
Iteration: 30 trainLoss:0.5036744913828927 testLoss:0.4931521270801385 trainLossDiff:-9.62169783115252E-5 testLossDiff:2.3107147633372183E-5
Learned weights: 9.7831424366768 21.989525231119117 -0.21860197415299967
