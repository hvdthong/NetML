Iteration: 1 trainLoss:0.4989308165861817 testLoss:0.4720086375468563
Iteration: 2 trainLoss:0.4957686023154273 testLoss:0.4642605517725058 trainLossDiff:-0.0031622142707544154 testLossDiff:-0.007748085774350488
Iteration: 3 trainLoss:0.49483934876401114 testLoss:0.46236123717024286 trainLossDiff:-9.292535514161537E-4 testLossDiff:-0.001899314602262947
Iteration: 4 trainLoss:0.4941947591599128 testLoss:0.4618222167603738 trainLossDiff:-6.445896040983556E-4 testLossDiff:-5.390204098690288E-4
Iteration: 5 trainLoss:0.4936613985204685 testLoss:0.46128213078547353 trainLossDiff:-5.333606394443136E-4 testLossDiff:-5.400859749002951E-4
Iteration: 6 trainLoss:0.49317942862985503 testLoss:0.46116671696593553 trainLossDiff:-4.8196989061344286E-4 testLossDiff:-1.1541381953800167E-4
Iteration: 7 trainLoss:0.49276181291679444 testLoss:0.46092779860746885 trainLossDiff:-4.1761571306059286E-4 testLossDiff:-2.3891835846667764E-4
Iteration: 8 trainLoss:0.49239106997735665 testLoss:0.46074562433565275 trainLossDiff:-3.707429394377848E-4 testLossDiff:-1.8217427181610457E-4
Iteration: 9 trainLoss:0.4920557537357174 testLoss:0.4605683342501521 trainLossDiff:-3.3531624163923857E-4 testLossDiff:-1.7729008550065872E-4
Iteration: 10 trainLoss:0.4917489303623934 testLoss:0.46023845084145404 trainLossDiff:-3.0682337332399445E-4 testLossDiff:-3.2988340869805066E-4
Iteration: 11 trainLoss:0.49147041892620186 testLoss:0.46003556585957894 trainLossDiff:-2.7851143619156415E-4 testLossDiff:-2.0288498187509552E-4
Iteration: 12 trainLoss:0.4912077835831661 testLoss:0.46015272792042705 trainLossDiff:-2.626353430357775E-4 testLossDiff:1.1716206084810832E-4
Iteration: 13 trainLoss:0.4909729699070935 testLoss:0.4599986849934534 trainLossDiff:-2.3481367607258719E-4 testLossDiff:-1.5404292697362987E-4
Iteration: 14 trainLoss:0.49075677456804756 testLoss:0.4597471426229147 trainLossDiff:-2.1619533904593258E-4 testLossDiff:-2.515423705387043E-4
Iteration: 15 trainLoss:0.49057249485124876 testLoss:0.4594278748355121 trainLossDiff:-1.842797167987964E-4 testLossDiff:-3.1926778740259953E-4
Iteration: 16 trainLoss:0.4903747122590634 testLoss:0.45972369302377425 trainLossDiff:-1.97782592185336E-4 testLossDiff:2.9581818826213135E-4
Iteration: 17 trainLoss:0.4902013046967177 testLoss:0.4595730990379543 trainLossDiff:-1.7340756234573984E-4 testLossDiff:-1.5059398581995787E-4
Iteration: 18 trainLoss:0.4900491705354009 testLoss:0.45911995296055974 trainLossDiff:-1.5213416131676372E-4 testLossDiff:-4.531460773945506E-4
Iteration: 19 trainLoss:0.4898877858723032 testLoss:0.45916333020066735 trainLossDiff:-1.6138466309773003E-4 testLossDiff:4.337724010761157E-5
Iteration: 20 trainLoss:0.4897535647817624 testLoss:0.45900046160803243 trainLossDiff:-1.3422109054078701E-4 testLossDiff:-1.6286859263492381E-4
Iteration: 21 trainLoss:0.48961211500354207 testLoss:0.45908359894460504 trainLossDiff:-1.4144977822033722E-4 testLossDiff:8.313733657261402E-5
Iteration: 22 trainLoss:0.4894947689643338 testLoss:0.4593763627938484 trainLossDiff:-1.1734603920826592E-4 testLossDiff:2.927638492433715E-4
Iteration: 23 trainLoss:0.4893811672808312 testLoss:0.45886960863798165 trainLossDiff:-1.1360168350260658E-4 testLossDiff:-5.067541558667621E-4
Iteration: 24 trainLoss:0.4892618275872163 testLoss:0.4589148908584577 trainLossDiff:-1.1933969361488383E-4 testLossDiff:4.5282220476061674E-5
Iteration: 25 trainLoss:0.4891568025529278 testLoss:0.45896466900115335 trainLossDiff:-1.050250342884973E-4 testLossDiff:4.977814269563341E-5
Iteration: 26 trainLoss:0.4890613560993362 testLoss:0.4588773285498849 trainLossDiff:-9.544645359160775E-5 testLossDiff:-8.734045126845835E-5
Iteration: 27 trainLoss:0.4889788412067938 testLoss:0.45868037795546346 trainLossDiff:-8.251489254240685E-5 testLossDiff:-1.9695059442143004E-4
Iteration: 28 trainLoss:0.48888386685177376 testLoss:0.458801476740637 trainLossDiff:-9.497435502003881E-5 testLossDiff:1.2109878517352346E-4
Iteration: 29 trainLoss:0.4888111186373517 testLoss:0.45839508491251046 trainLossDiff:-7.274821442204704E-5 testLossDiff:-4.0639182812651775E-4
Iteration: 30 trainLoss:0.48872576856905325 testLoss:0.45853679196152025 trainLossDiff:-8.535006829846203E-5 testLossDiff:1.4170704900978714E-4
Learned weights: 12.621641943455405 18.224627837126047 0.7736089044381819
