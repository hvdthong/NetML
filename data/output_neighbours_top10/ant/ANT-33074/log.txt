Iteration: 1 trainLoss:0.4839796490282958 testLoss:0.40152204909792844
Iteration: 2 trainLoss:0.48157968000460455 testLoss:0.40382234229344816 trainLossDiff:-0.002399969023691273 testLossDiff:0.0023002931955197203
Iteration: 3 trainLoss:0.4806166323090192 testLoss:0.4036353422140681 trainLossDiff:-9.630476955853617E-4 testLossDiff:-1.870000793800508E-4
Iteration: 4 trainLoss:0.479896118060548 testLoss:0.4027797249703325 trainLossDiff:-7.205142484711935E-4 testLossDiff:-8.55617243735618E-4
Iteration: 5 trainLoss:0.4793049546943637 testLoss:0.4018566726913541 trainLossDiff:-5.911633661843108E-4 testLossDiff:-9.230522789783757E-4
Iteration: 6 trainLoss:0.4788029134089342 testLoss:0.4010387036189257 trainLossDiff:-5.020412854294665E-4 testLossDiff:-8.179690724284261E-4
Iteration: 7 trainLoss:0.47837203588029964 testLoss:0.40044484451100426 trainLossDiff:-4.3087752863457673E-4 testLossDiff:-5.938591079214239E-4
Iteration: 8 trainLoss:0.4780175778454468 testLoss:0.39980820993538363 trainLossDiff:-3.5445803485284477E-4 testLossDiff:-6.366345756206315E-4
Iteration: 9 trainLoss:0.477691970938226 testLoss:0.39938609705007594 trainLossDiff:-3.256069072207768E-4 testLossDiff:-4.2211288530769053E-4
Iteration: 10 trainLoss:0.4774190860182248 testLoss:0.3990111609161329 trainLossDiff:-2.728849200012151E-4 testLossDiff:-3.749361339430157E-4
Iteration: 11 trainLoss:0.47716080119186466 testLoss:0.3985863415156573 trainLossDiff:-2.582848263601445E-4 testLossDiff:-4.2481940047561784E-4
Iteration: 12 trainLoss:0.4769279897016482 testLoss:0.3983548964796738 trainLossDiff:-2.3281149021647796E-4 testLossDiff:-2.3144503598349075E-4
Iteration: 13 trainLoss:0.4767435410125389 testLoss:0.39812670363625513 trainLossDiff:-1.8444868910927337E-4 testLossDiff:-2.2819284341868418E-4
Iteration: 14 trainLoss:0.4765561844974464 testLoss:0.397718229347406 trainLossDiff:-1.8735651509249607E-4 testLossDiff:-4.084742888491033E-4
Iteration: 15 trainLoss:0.4763974794768322 testLoss:0.39754653756017494 trainLossDiff:-1.5870502061421377E-4 testLossDiff:-1.7169178723108747E-4
Iteration: 16 trainLoss:0.47625317617181956 testLoss:0.3974482259002608 trainLossDiff:-1.4430330501263855E-4 testLossDiff:-9.831165991414093E-5
Iteration: 17 trainLoss:0.47612579351421386 testLoss:0.3970978841420098 trainLossDiff:-1.2738265760570133E-4 testLossDiff:-3.503417582509938E-4
Iteration: 18 trainLoss:0.4760118638128197 testLoss:0.39693833107386284 trainLossDiff:-1.1392970139417757E-4 testLossDiff:-1.5955306814696701E-4
Iteration: 19 trainLoss:0.4758841520910464 testLoss:0.3968467554667271 trainLossDiff:-1.277117217732826E-4 testLossDiff:-9.157560713574098E-5
Iteration: 20 trainLoss:0.4757957446240777 testLoss:0.3966760060479899 trainLossDiff:-8.84074669686985E-5 testLossDiff:-1.7074941873718164E-4
Iteration: 21 trainLoss:0.47570197501245637 testLoss:0.39651589651220903 trainLossDiff:-9.376961162133046E-5 testLossDiff:-1.601095357808835E-4
Iteration: 22 trainLoss:0.475617900778291 testLoss:0.3962536049088532 trainLossDiff:-8.407423416534332E-5 testLossDiff:-2.6229160335583535E-4
Iteration: 23 trainLoss:0.4755353814136228 testLoss:0.3962964799173325 trainLossDiff:-8.251936466824317E-5 testLossDiff:4.2875008479326127E-5
Iteration: 24 trainLoss:0.475473470505304 testLoss:0.3962680191452373 trainLossDiff:-6.191090831880741E-5 testLossDiff:-2.8460772095229014E-5
Iteration: 25 trainLoss:0.47541286662927873 testLoss:0.39613726777739633 trainLossDiff:-6.060387602524475E-5 testLossDiff:-1.3075136784096442E-4
Iteration: 26 trainLoss:0.47534869531179647 testLoss:0.39609971427024426 trainLossDiff:-6.417131748226446E-5 testLossDiff:-3.755350715206607E-5
Iteration: 27 trainLoss:0.4752942353263055 testLoss:0.39598583394185116 trainLossDiff:-5.4459985490973306E-5 testLossDiff:-1.1388032839310114E-4
Iteration: 28 trainLoss:0.47525169453472577 testLoss:0.39605264835484205 trainLossDiff:-4.254079157972601E-5 testLossDiff:6.681441299088986E-5
Iteration: 29 trainLoss:0.475207167018254 testLoss:0.396057948731683 trainLossDiff:-4.452751647177067E-5 testLossDiff:5.3003768409332075E-6
Iteration: 30 trainLoss:0.4751395011090099 testLoss:0.3957871506692377 trainLossDiff:-6.766590924411897E-5 testLossDiff:-2.707980624452877E-4
Learned weights: 9.265754249269284 17.798664489589992 1.1690938482222115
