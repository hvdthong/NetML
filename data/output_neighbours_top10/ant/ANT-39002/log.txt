Iteration: 1 trainLoss:0.4972074816924048 testLoss:0.520846237806549
Iteration: 2 trainLoss:0.4932417969703343 testLoss:0.5598848990700731 trainLossDiff:-0.003965684722070484 testLossDiff:0.039038661263524066
Iteration: 3 trainLoss:0.4920172905393546 testLoss:0.5801347220471034 trainLossDiff:-0.0012245064309797105 testLossDiff:0.020249822977030263
Iteration: 4 trainLoss:0.4911338917521354 testLoss:0.59210486351521 trainLossDiff:-8.833987872192139E-4 testLossDiff:0.011970141468106599
Iteration: 5 trainLoss:0.4903783897901922 testLoss:0.6008078263654442 trainLossDiff:-7.555019619431835E-4 testLossDiff:0.008702962850234197
Iteration: 6 trainLoss:0.48971391079276994 testLoss:0.6125106637938404 trainLossDiff:-6.644789974222798E-4 testLossDiff:0.011702837428396284
Iteration: 7 trainLoss:0.4891241461338397 testLoss:0.6159491682279132 trainLossDiff:-5.897646589302363E-4 testLossDiff:0.0034385044340727866
Iteration: 8 trainLoss:0.4885886785487628 testLoss:0.6277214707680887 trainLossDiff:-5.354675850768875E-4 testLossDiff:0.011772302540175472
Iteration: 9 trainLoss:0.4881045478061796 testLoss:0.6394865940204386 trainLossDiff:-4.8413074258318867E-4 testLossDiff:0.011765123252349907
Iteration: 10 trainLoss:0.48767418981501526 testLoss:0.6426727265052586 trainLossDiff:-4.3035799116436513E-4 testLossDiff:0.0031861324848200256
Iteration: 11 trainLoss:0.48727817363124587 testLoss:0.6548349240094135 trainLossDiff:-3.9601618376938763E-4 testLossDiff:0.012162197504154815
Iteration: 12 trainLoss:0.48691818492635025 testLoss:0.6614254911668087 trainLossDiff:-3.599887048956196E-4 testLossDiff:0.006590567157395255
Iteration: 13 trainLoss:0.48658305857445394 testLoss:0.6708195440998097 trainLossDiff:-3.351263518963088E-4 testLossDiff:0.009394052933000996
Iteration: 14 trainLoss:0.48628128226538214 testLoss:0.682087818708704 trainLossDiff:-3.0177630907179953E-4 testLossDiff:0.011268274608894346
Iteration: 15 trainLoss:0.4860033193098674 testLoss:0.6832090313421504 trainLossDiff:-2.7796295551474337E-4 testLossDiff:0.0011212126334463335
Iteration: 16 trainLoss:0.48574532761756123 testLoss:0.6917684330438454 trainLossDiff:-2.579916923061698E-4 testLossDiff:0.008559401701695002
Iteration: 17 trainLoss:0.4855125397978636 testLoss:0.6918682883233593 trainLossDiff:-2.3278781969765516E-4 testLossDiff:9.985527951394957E-5
Iteration: 18 trainLoss:0.4852922576835562 testLoss:0.7014103663454213 trainLossDiff:-2.2028211430735745E-4 testLossDiff:0.009542078022061973
Iteration: 19 trainLoss:0.48508842906641514 testLoss:0.7052414734786019 trainLossDiff:-2.0382861714107747E-4 testLossDiff:0.003831107133180578
Iteration: 20 trainLoss:0.48489825678910425 testLoss:0.7099459799216574 trainLossDiff:-1.9017227731088493E-4 testLossDiff:0.004704506443055534
Iteration: 21 trainLoss:0.4847220263075004 testLoss:0.7229488780814021 trainLossDiff:-1.7623048160386734E-4 testLossDiff:0.013002898159744647
Iteration: 22 trainLoss:0.48455997523748195 testLoss:0.7164480443243333 trainLossDiff:-1.6205107001843189E-4 testLossDiff:-0.00650083375706878
Iteration: 23 trainLoss:0.4844061673663219 testLoss:0.7257666809805078 trainLossDiff:-1.538078711600388E-4 testLossDiff:0.009318636656174495
Iteration: 24 trainLoss:0.4842629466142781 testLoss:0.7381202828715976 trainLossDiff:-1.4322075204381557E-4 testLossDiff:0.012353601891089805
Iteration: 25 trainLoss:0.4841261263827501 testLoss:0.7359501906294027 trainLossDiff:-1.3682023152800094E-4 testLossDiff:-0.0021700922421948876
Iteration: 26 trainLoss:0.4840020972957347 testLoss:0.7370961035723028 trainLossDiff:-1.2402908701542037E-4 testLossDiff:0.001145912942900118
Iteration: 27 trainLoss:0.4838795450973258 testLoss:0.7493419026399302 trainLossDiff:-1.2255219840889842E-4 testLossDiff:0.01224579906762735
Iteration: 28 trainLoss:0.4837681829942805 testLoss:0.7462508521672155 trainLossDiff:-1.1136210304529826E-4 testLossDiff:-0.0030910504727146293
Iteration: 29 trainLoss:0.4836685083801335 testLoss:0.7461889308315446 trainLossDiff:-9.967461414700507E-5 testLossDiff:-6.192133567095581E-5
Iteration: 30 trainLoss:0.48356958296978725 testLoss:0.7633849293722381 trainLossDiff:-9.892541034622893E-5 testLossDiff:0.017195998540693536
Learned weights: 14.797174258924128 21.299406049161753 -1.369977792599014
