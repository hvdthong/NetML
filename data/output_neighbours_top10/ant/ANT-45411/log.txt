Iteration: 1 trainLoss:0.48757190337951073 testLoss:0.4187410919544404
Iteration: 2 trainLoss:0.48330892039391776 testLoss:0.4185927044204745 trainLossDiff:-0.004262982985592967 testLossDiff:-1.483875339658991E-4
Iteration: 3 trainLoss:0.48173378289033697 testLoss:0.4168719928117038 trainLossDiff:-0.0015751375035807924 testLossDiff:-0.001720711608770742
Iteration: 4 trainLoss:0.48075989628463556 testLoss:0.41535263067443706 trainLossDiff:-9.738866057014128E-4 testLossDiff:-0.001519362137266722
Iteration: 5 trainLoss:0.48001691970573157 testLoss:0.41407137474353567 trainLossDiff:-7.429765789039866E-4 testLossDiff:-0.0012812559309013927
Iteration: 6 trainLoss:0.4794149291040337 testLoss:0.41252625465442044 trainLossDiff:-6.019906016978549E-4 testLossDiff:-0.0015451200891152261
Iteration: 7 trainLoss:0.4789131641512669 testLoss:0.41145842751061673 trainLossDiff:-5.017649527668255E-4 testLossDiff:-0.0010678271438037124
Iteration: 8 trainLoss:0.4784872749326639 testLoss:0.41027836152858893 trainLossDiff:-4.258892186029817E-4 testLossDiff:-0.0011800659820278003
Iteration: 9 trainLoss:0.47812064681415367 testLoss:0.4093873924806675 trainLossDiff:-3.6662811851023713E-4 testLossDiff:-8.909690479214083E-4
Iteration: 10 trainLoss:0.47779499304394835 testLoss:0.40915842414631426 trainLossDiff:-3.2565377020532527E-4 testLossDiff:-2.2896833435326336E-4
Iteration: 11 trainLoss:0.47751734312644667 testLoss:0.40808860963586413 trainLossDiff:-2.7764991750167667E-4 testLossDiff:-0.0010698145104501289
Iteration: 12 trainLoss:0.4772600792976941 testLoss:0.4080417141739597 trainLossDiff:-2.5726382875257414E-4 testLossDiff:-4.6895461904450375E-5
Iteration: 13 trainLoss:0.47703772453487353 testLoss:0.4075283778400314 trainLossDiff:-2.2235476282056466E-4 testLossDiff:-5.133363339283048E-4
Iteration: 14 trainLoss:0.4768384940645443 testLoss:0.4071383943272126 trainLossDiff:-1.992304703292147E-4 testLossDiff:-3.899835128187701E-4
Iteration: 15 trainLoss:0.47665448137779903 testLoss:0.4071079760271786 trainLossDiff:-1.8401268674528293E-4 testLossDiff:-3.0418300034029677E-5
Iteration: 16 trainLoss:0.47649258097707753 testLoss:0.40692257140546423 trainLossDiff:-1.6190040072150413E-4 testLossDiff:-1.854046217143468E-4
Iteration: 17 trainLoss:0.4763454799096862 testLoss:0.40654664483839853 trainLossDiff:-1.471010673913531E-4 testLossDiff:-3.759265670656986E-4
Iteration: 18 trainLoss:0.47621281359822676 testLoss:0.4061745540176148 trainLossDiff:-1.3266631145941732E-4 testLossDiff:-3.7209082078371036E-4
Iteration: 19 trainLoss:0.4760917238203619 testLoss:0.4062089946761943 trainLossDiff:-1.2108977786484676E-4 testLossDiff:3.444065857949319E-5
Iteration: 20 trainLoss:0.4759800024944484 testLoss:0.4061218005980355 trainLossDiff:-1.1172132591352746E-4 testLossDiff:-8.71940781588254E-5
Iteration: 21 trainLoss:0.47587288342248396 testLoss:0.4058570533869043 trainLossDiff:-1.0711907196442327E-4 testLossDiff:-2.647472111311777E-4
Iteration: 22 trainLoss:0.4757760083269028 testLoss:0.4058697907236885 trainLossDiff:-9.687509558115037E-5 testLossDiff:1.2737336784196529E-5
Iteration: 23 trainLoss:0.4756927212431485 testLoss:0.40572459636542135 trainLossDiff:-8.328708375432425E-5 testLossDiff:-1.4519435826715332E-4
Iteration: 24 trainLoss:0.47560632874900177 testLoss:0.4055009017797964 trainLossDiff:-8.639249414671424E-5 testLossDiff:-2.2369458562493394E-4
Iteration: 25 trainLoss:0.47553179881785856 testLoss:0.4057447051910843 trainLossDiff:-7.452993114320794E-5 testLossDiff:2.4380341128787952E-4
Iteration: 26 trainLoss:0.4754666642500269 testLoss:0.4059395103166259 trainLossDiff:-6.513456783163729E-5 testLossDiff:1.9480512554159723E-4
Iteration: 27 trainLoss:0.47539755128570604 testLoss:0.4055551357099999 trainLossDiff:-6.911296432088321E-5 testLossDiff:-3.843746066259923E-4
Iteration: 28 trainLoss:0.4753368638744147 testLoss:0.40502576452497957 trainLossDiff:-6.0687411291338034E-5 testLossDiff:-5.293711850203331E-4
Iteration: 29 trainLoss:0.47527401734515745 testLoss:0.4053772569233472 trainLossDiff:-6.284652925725442E-5 testLossDiff:3.5149239836762547E-4
Iteration: 30 trainLoss:0.47522442723653796 testLoss:0.40524868433959615 trainLossDiff:-4.9590108619490536E-5 testLossDiff:-1.2857258375104097E-4
Learned weights: 9.820723063104532 20.225625145922887 0.020267546289233433
