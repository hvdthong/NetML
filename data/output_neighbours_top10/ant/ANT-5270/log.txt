Iteration: 1 trainLoss:0.49480006613186894 testLoss:0.5701472650732943
Iteration: 2 trainLoss:0.49436488401417317 testLoss:0.5669166640710704 trainLossDiff:-4.3518211769577597E-4 testLossDiff:-0.003230601002223832
Iteration: 3 trainLoss:0.4941168280144711 testLoss:0.5661912093764875 trainLossDiff:-2.4805599970206815E-4 testLossDiff:-7.25454694582961E-4
Iteration: 4 trainLoss:0.49390973305919006 testLoss:0.5660400688142316 trainLossDiff:-2.0709495528103972E-4 testLossDiff:-1.5114056225584704E-4
Iteration: 5 trainLoss:0.4937226188081185 testLoss:0.5660156122624316 trainLossDiff:-1.8711425107154067E-4 testLossDiff:-2.4456551800056126E-5
Iteration: 6 trainLoss:0.49356097412910255 testLoss:0.5658457074561047 trainLossDiff:-1.616446790159709E-4 testLossDiff:-1.6990480632683713E-4
Iteration: 7 trainLoss:0.49341511260342485 testLoss:0.5657282755945926 trainLossDiff:-1.4586152567769295E-4 testLossDiff:-1.1743186151214058E-4
Iteration: 8 trainLoss:0.493285591431862 testLoss:0.5656496587249518 trainLossDiff:-1.2952117156284082E-4 testLossDiff:-7.861686964083514E-5
Iteration: 9 trainLoss:0.49317394022413996 testLoss:0.565354678118775 trainLossDiff:-1.1165120772205217E-4 testLossDiff:-2.9498060617672017E-4
Iteration: 10 trainLoss:0.4930646690848545 testLoss:0.5653724945835908 trainLossDiff:-1.0927113928543841E-4 testLossDiff:1.7816464815800792E-5
Iteration: 11 trainLoss:0.49297296950047165 testLoss:0.5654764053292582 trainLossDiff:-9.169958438287606E-5 testLossDiff:1.0391074566740155E-4
Iteration: 12 trainLoss:0.4928878567619469 testLoss:0.5651749868354629 trainLossDiff:-8.511273852473966E-5 testLossDiff:-3.014184937953912E-4
Iteration: 13 trainLoss:0.49280650828354133 testLoss:0.5651523074202072 trainLossDiff:-8.134847840557402E-5 testLossDiff:-2.2679415255688617E-5
Iteration: 14 trainLoss:0.492736043501554 testLoss:0.5653167727470751 trainLossDiff:-7.046478198735606E-5 testLossDiff:1.6446532686797966E-4
Iteration: 15 trainLoss:0.4926688528920171 testLoss:0.5648575918336917 trainLossDiff:-6.719060953686018E-5 testLossDiff:-4.5918091338348344E-4
Iteration: 16 trainLoss:0.49260811344658023 testLoss:0.5647074548774065 trainLossDiff:-6.073944543688592E-5 testLossDiff:-1.5013695628518509E-4
Iteration: 17 trainLoss:0.4925545417532413 testLoss:0.5647179205684354 trainLossDiff:-5.3571693338916315E-5 testLossDiff:1.0465691028915813E-5
Iteration: 18 trainLoss:0.49250109806696635 testLoss:0.5648521491515253 trainLossDiff:-5.344368627496765E-5 testLossDiff:1.3422858308986818E-4
Iteration: 19 trainLoss:0.49245745775961575 testLoss:0.5649747876971889 trainLossDiff:-4.364030735060087E-5 testLossDiff:1.2263854566363364E-4
Iteration: 20 trainLoss:0.49240854482494545 testLoss:0.5648586352416466 trainLossDiff:-4.891293467029767E-5 testLossDiff:-1.1615245554230658E-4
Iteration: 21 trainLoss:0.4923685268483049 testLoss:0.5646793660487099 trainLossDiff:-4.001797664054951E-5 testLossDiff:-1.7926919293664856E-4
Iteration: 22 trainLoss:0.4923293863690331 testLoss:0.5644901697855811 trainLossDiff:-3.914047927178199E-5 testLossDiff:-1.8919626312885462E-4
Iteration: 23 trainLoss:0.4922968611689233 testLoss:0.564471385496003 trainLossDiff:-3.252520010982307E-5 testLossDiff:-1.8784289578133162E-5
Iteration: 24 trainLoss:0.4922610347872148 testLoss:0.5642159865399864 trainLossDiff:-3.582638170851471E-5 testLossDiff:-2.553989560165615E-4
Iteration: 25 trainLoss:0.49223039986728123 testLoss:0.5645844099676773 trainLossDiff:-3.063491993354761E-5 testLossDiff:3.684234276909448E-4
Iteration: 26 trainLoss:0.4922023528914769 testLoss:0.5645365256179546 trainLossDiff:-2.804697580433002E-5 testLossDiff:-4.788434972269329E-5
Iteration: 27 trainLoss:0.4921748076998633 testLoss:0.5643873417629828 trainLossDiff:-2.7545191613576048E-5 testLossDiff:-1.4918385497186826E-4
Iteration: 28 trainLoss:0.492150371238672 testLoss:0.5644488137603213 trainLossDiff:-2.443646119132392E-5 testLossDiff:6.147199733852471E-5
Iteration: 29 trainLoss:0.4921272578255638 testLoss:0.5643521085154535 trainLossDiff:-2.3113413108177827E-5 testLossDiff:-9.670524486782295E-5
Iteration: 30 trainLoss:0.49210589883717737 testLoss:0.5642694087411874 trainLossDiff:-2.1358988386455113E-5 testLossDiff:-8.269977426611508E-5
Learned weights: 5.501533628954367 10.715493069550908 2.608497991504692
