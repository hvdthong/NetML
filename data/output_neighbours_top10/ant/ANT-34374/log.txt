Iteration: 1 trainLoss:0.4823637318148771 testLoss:0.4516161470615967
Iteration: 2 trainLoss:0.4818465057707406 testLoss:0.4452180497655067 trainLossDiff:-5.17226044136454E-4 testLossDiff:-0.006398097296089977
Iteration: 3 trainLoss:0.48167374450509287 testLoss:0.4434786207361354 trainLossDiff:-1.727612656477473E-4 testLossDiff:-0.0017394290293712977
Iteration: 4 trainLoss:0.4815448219622182 testLoss:0.44286135774239993 trainLossDiff:-1.2892254287466542E-4 testLossDiff:-6.172629937354901E-4
Iteration: 5 trainLoss:0.48142711322451665 testLoss:0.4422665213277288 trainLossDiff:-1.1770873770156065E-4 testLossDiff:-5.948364146711183E-4
Iteration: 6 trainLoss:0.4813221773584271 testLoss:0.44190102626389915 trainLossDiff:-1.0493586608956162E-4 testLossDiff:-3.6549506382965724E-4
Iteration: 7 trainLoss:0.4812362582180938 testLoss:0.442236760544478 trainLossDiff:-8.59191403332904E-5 testLossDiff:3.357342805788699E-4
Iteration: 8 trainLoss:0.481147094551598 testLoss:0.44195781934156947 trainLossDiff:-8.91636664958062E-5 testLossDiff:-2.7894120290855584E-4
Iteration: 9 trainLoss:0.4810678030576619 testLoss:0.441696429186234 trainLossDiff:-7.929149393609558E-5 testLossDiff:-2.613901553354947E-4
Iteration: 10 trainLoss:0.4809904056010102 testLoss:0.4411052285219215 trainLossDiff:-7.73974566516955E-5 testLossDiff:-5.912006643124523E-4
Iteration: 11 trainLoss:0.48092540496837427 testLoss:0.44114189457458675 trainLossDiff:-6.500063263592537E-5 testLossDiff:3.666605266522405E-5
Iteration: 12 trainLoss:0.4808610065113622 testLoss:0.4407494831533822 trainLossDiff:-6.439845701206037E-5 testLossDiff:-3.9241142120455264E-4
Iteration: 13 trainLoss:0.4808044535280473 testLoss:0.44088161368723594 trainLossDiff:-5.655298331491698E-5 testLossDiff:1.3213053385374707E-4
Iteration: 14 trainLoss:0.48074972204934463 testLoss:0.44060283600527894 trainLossDiff:-5.473147870266315E-5 testLossDiff:-2.787776819569987E-4
Iteration: 15 trainLoss:0.4806965387189909 testLoss:0.4403526448164864 trainLossDiff:-5.318333035375655E-5 testLossDiff:-2.5019118879254787E-4
Iteration: 16 trainLoss:0.4806507472625812 testLoss:0.44054132374881205 trainLossDiff:-4.5791456409649545E-5 testLossDiff:1.886789323256588E-4
Iteration: 17 trainLoss:0.4806054985853705 testLoss:0.4404309647879906 trainLossDiff:-4.524867721072967E-5 testLossDiff:-1.1035896082145502E-4
Iteration: 18 trainLoss:0.48056565603628676 testLoss:0.44060462329579997 trainLossDiff:-3.984254908373508E-5 testLossDiff:1.736585078093711E-4
Iteration: 19 trainLoss:0.4805211324983603 testLoss:0.44004092635953135 trainLossDiff:-4.4523537926444146E-5 testLossDiff:-5.636969362686206E-4
Iteration: 20 trainLoss:0.4804846231527719 testLoss:0.4400289600898837 trainLossDiff:-3.6509345588409126E-5 testLossDiff:-1.1966269647667449E-5
Iteration: 21 trainLoss:0.4804490204752566 testLoss:0.4400250108990065 trainLossDiff:-3.560267751528956E-5 testLossDiff:-3.949190877206021E-6
Iteration: 22 trainLoss:0.48041309168308954 testLoss:0.4395807151268493 trainLossDiff:-3.5928792167072565E-5 testLossDiff:-4.44295772157155E-4
Iteration: 23 trainLoss:0.4803816371552744 testLoss:0.43955967650684974 trainLossDiff:-3.145452781516678E-5 testLossDiff:-2.1038619999580455E-5
Iteration: 24 trainLoss:0.4803523417197031 testLoss:0.439476298326466 trainLossDiff:-2.9295435571286E-5 testLossDiff:-8.33781803837308E-5
Iteration: 25 trainLoss:0.48032219863426384 testLoss:0.4393888390054643 trainLossDiff:-3.0143085439249262E-5 testLossDiff:-8.745932100168163E-5
Iteration: 26 trainLoss:0.4803044205211555 testLoss:0.4401301533722822 trainLossDiff:-1.7778113108324334E-5 testLossDiff:7.413143668178468E-4
Iteration: 27 trainLoss:0.48027220073998866 testLoss:0.439604036533191 trainLossDiff:-3.221978116685342E-5 testLossDiff:-5.261168390911508E-4
Iteration: 28 trainLoss:0.4802465311692139 testLoss:0.4393978032014493 trainLossDiff:-2.5669570774766726E-5 testLossDiff:-2.062333317417453E-4
Iteration: 29 trainLoss:0.48022088894987175 testLoss:0.43898726479820677 trainLossDiff:-2.5642219342147943E-5 testLossDiff:-4.105384032425108E-4
Iteration: 30 trainLoss:0.4802008205983905 testLoss:0.4392093183258222 trainLossDiff:-2.0068351481272728E-5 testLossDiff:2.2205352761545116E-4
Learned weights: 6.4777999969660565 9.236921705079046 3.1281118266321726
