Iteration: 1 trainLoss:0.489003936397601 testLoss:0.43080115822022996
Iteration: 2 trainLoss:0.48674312033699857 testLoss:0.42967981719660386 trainLossDiff:-0.002260816060602411 testLossDiff:-0.001121341023626099
Iteration: 3 trainLoss:0.48594904192402144 testLoss:0.4289570661493206 trainLossDiff:-7.940784129771283E-4 testLossDiff:-7.227510472832543E-4
Iteration: 4 trainLoss:0.4854139481670841 testLoss:0.42824811617081965 trainLossDiff:-5.350937569373326E-4 testLossDiff:-7.089499785009612E-4
Iteration: 5 trainLoss:0.48499322874627254 testLoss:0.42769201961340025 trainLossDiff:-4.207194208115661E-4 testLossDiff:-5.560965574193943E-4
Iteration: 6 trainLoss:0.4846542295085362 testLoss:0.4273364435186099 trainLossDiff:-3.389992377363371E-4 testLossDiff:-3.5557609479036634E-4
Iteration: 7 trainLoss:0.48437446348704627 testLoss:0.42671052811996124 trainLossDiff:-2.7976602148993557E-4 testLossDiff:-6.259153986486465E-4
Iteration: 8 trainLoss:0.48413771491438556 testLoss:0.4264503120682821 trainLossDiff:-2.3674857266070548E-4 testLossDiff:-2.6021605167914075E-4
Iteration: 9 trainLoss:0.4839386493539838 testLoss:0.4261552994170642 trainLossDiff:-1.990655604017788E-4 testLossDiff:-2.950126512178963E-4
Iteration: 10 trainLoss:0.48377847874240476 testLoss:0.42567899272917986 trainLossDiff:-1.6017061157902468E-4 testLossDiff:-4.763066878843425E-4
Iteration: 11 trainLoss:0.48361334884334967 testLoss:0.42564958368143074 trainLossDiff:-1.6512989905509423E-4 testLossDiff:-2.9409047749118233E-5
Iteration: 12 trainLoss:0.48348621706752604 testLoss:0.42548905529293296 trainLossDiff:-1.271317758236301E-4 testLossDiff:-1.6052838849778261E-4
Iteration: 13 trainLoss:0.48337328271457025 testLoss:0.42533264209384875 trainLossDiff:-1.1293435295578469E-4 testLossDiff:-1.5641319908421547E-4
Iteration: 14 trainLoss:0.48328409303479514 testLoss:0.425139671404996 trainLossDiff:-8.91896797751146E-5 testLossDiff:-1.9297068885276714E-4
Iteration: 15 trainLoss:0.4831919948263972 testLoss:0.42506851491568504 trainLossDiff:-9.209820839795047E-5 testLossDiff:-7.115648931094176E-5
Iteration: 16 trainLoss:0.48310950037029354 testLoss:0.42502632574280036 trainLossDiff:-8.249445610364337E-5 testLossDiff:-4.218917288467683E-5
Iteration: 17 trainLoss:0.48304503973721163 testLoss:0.42495465110558694 trainLossDiff:-6.446063308190864E-5 testLossDiff:-7.167463721341472E-5
Iteration: 18 trainLoss:0.4829801140039355 testLoss:0.42476873337097737 trainLossDiff:-6.492573327615547E-5 testLossDiff:-1.8591773460957528E-4
Iteration: 19 trainLoss:0.4829197231500873 testLoss:0.4247395679490006 trainLossDiff:-6.0390853848180104E-5 testLossDiff:-2.916542197678451E-5
Iteration: 20 trainLoss:0.48286814352350593 testLoss:0.4246797319385709 trainLossDiff:-5.157962658136617E-5 testLossDiff:-5.983601042969244E-5
Iteration: 21 trainLoss:0.48282584051809313 testLoss:0.4246073401085706 trainLossDiff:-4.230300541280263E-5 testLossDiff:-7.23918300002957E-5
Iteration: 22 trainLoss:0.4827788685603377 testLoss:0.42464462281846743 trainLossDiff:-4.697195775543728E-5 testLossDiff:3.728270989683535E-5
Iteration: 23 trainLoss:0.4827481741444841 testLoss:0.4245277998257804 trainLossDiff:-3.069441585357158E-5 testLossDiff:-1.1682299268700458E-4
Iteration: 24 trainLoss:0.48270852061376956 testLoss:0.4244939511608643 trainLossDiff:-3.965353071455624E-5 testLossDiff:-3.384866491612515E-5
Iteration: 25 trainLoss:0.4826748279063018 testLoss:0.4245782070868096 trainLossDiff:-3.3692707467780636E-5 testLossDiff:8.425592594529796E-5
Iteration: 26 trainLoss:0.48264347309714467 testLoss:0.42448746690347955 trainLossDiff:-3.135480915711364E-5 testLossDiff:-9.07401833300514E-5
Iteration: 27 trainLoss:0.48262462431568187 testLoss:0.42440586985298334 trainLossDiff:-1.8848781462799113E-5 testLossDiff:-8.159705049620714E-5
Iteration: 28 trainLoss:0.48260166191197595 testLoss:0.4243600629159662 trainLossDiff:-2.296240370591729E-5 testLossDiff:-4.580693701716765E-5
Iteration: 29 trainLoss:0.4825741023328627 testLoss:0.4243822170319127 trainLossDiff:-2.7559579113267674E-5 testLossDiff:2.215411594652661E-5
Iteration: 30 trainLoss:0.48255241562124995 testLoss:0.42436217937783505 trainLossDiff:-2.1686711612733944E-5 testLossDiff:-2.0037654077653677E-5
Learned weights: 8.365633255803404 14.594365256218712 1.1843060015453504
