Iteration: 1 trainLoss:0.47437120231236485 testLoss:0.429642121371825
Iteration: 2 trainLoss:0.4713443758401497 testLoss:0.43199338328041026 trainLossDiff:-0.0030268264722151383 testLossDiff:0.002351261908585256
Iteration: 3 trainLoss:0.4701513108823054 testLoss:0.4309851084277112 trainLossDiff:-0.0011930649578443253 testLossDiff:-0.0010082748526990537
Iteration: 4 trainLoss:0.4691585259403079 testLoss:0.4303505144934673 trainLossDiff:-9.927849419975043E-4 testLossDiff:-6.345939342439211E-4
Iteration: 5 trainLoss:0.4683650039292638 testLoss:0.4287762085021446 trainLossDiff:-7.93522011044101E-4 testLossDiff:-0.0015743059913226887
Iteration: 6 trainLoss:0.4676382745787 testLoss:0.42770643709448924 trainLossDiff:-7.267293505637817E-4 testLossDiff:-0.001069771407655351
Iteration: 7 trainLoss:0.4670017062467172 testLoss:0.4265999536622922 trainLossDiff:-6.365683319827786E-4 testLossDiff:-0.0011064834321970474
Iteration: 8 trainLoss:0.46643665022542813 testLoss:0.42547935112067536 trainLossDiff:-5.650560212890898E-4 testLossDiff:-0.001120602541616833
Iteration: 9 trainLoss:0.46591092690329866 testLoss:0.4247506649589786 trainLossDiff:-5.257233221294677E-4 testLossDiff:-7.286861616967455E-4
Iteration: 10 trainLoss:0.4654471015813767 testLoss:0.4238118712407573 trainLossDiff:-4.6382532192196235E-4 testLossDiff:-9.387937182213091E-4
Iteration: 11 trainLoss:0.4650253870892571 testLoss:0.4229183683847313 trainLossDiff:-4.217144921195848E-4 testLossDiff:-8.935028560260183E-4
Iteration: 12 trainLoss:0.46464157831094344 testLoss:0.4221015252986308 trainLossDiff:-3.8380877831367677E-4 testLossDiff:-8.168430861004716E-4
Iteration: 13 trainLoss:0.4642920311745232 testLoss:0.4213234203180891 trainLossDiff:-3.4954713642021407E-4 testLossDiff:-7.781049805417051E-4
Iteration: 14 trainLoss:0.46394037670008037 testLoss:0.42092685170383937 trainLossDiff:-3.516544744428529E-4 testLossDiff:-3.965686142497482E-4
Iteration: 15 trainLoss:0.463618664810634 testLoss:0.4206397987556365 trainLossDiff:-3.217118894463522E-4 testLossDiff:-2.870529482028594E-4
Iteration: 16 trainLoss:0.463335698294594 testLoss:0.4200898057655747 trainLossDiff:-2.8296651604003964E-4 testLossDiff:-5.499929900618095E-4
Iteration: 17 trainLoss:0.4630656759770576 testLoss:0.41964942095176866 trainLossDiff:-2.7002231753636696E-4 testLossDiff:-4.4038481380603844E-4
Iteration: 18 trainLoss:0.46282168792593975 testLoss:0.41909953771390346 trainLossDiff:-2.4398805111786048E-4 testLossDiff:-5.498832378652008E-4
Iteration: 19 trainLoss:0.46258348012472994 testLoss:0.41885761756173007 trainLossDiff:-2.38207801209811E-4 testLossDiff:-2.4192015217339158E-4
Iteration: 20 trainLoss:0.4623794186931944 testLoss:0.4182792818617027 trainLossDiff:-2.0406143153556267E-4 testLossDiff:-5.783357000273548E-4
Iteration: 21 trainLoss:0.46215124664123375 testLoss:0.41842984287985924 trainLossDiff:-2.2817205196062895E-4 testLossDiff:1.5056101815652534E-4
Iteration: 22 trainLoss:0.4619739164192315 testLoss:0.41774308242139385 trainLossDiff:-1.7733022200222548E-4 testLossDiff:-6.867604584653852E-4
Iteration: 23 trainLoss:0.46178856207830055 testLoss:0.4175780706696065 trainLossDiff:-1.8535434093097658E-4 testLossDiff:-1.6501175178734728E-4
Iteration: 24 trainLoss:0.46162938717855845 testLoss:0.41718592823111234 trainLossDiff:-1.591748997420983E-4 testLossDiff:-3.9214243849416963E-4
Iteration: 25 trainLoss:0.4614718600460523 testLoss:0.41679815409352955 trainLossDiff:-1.5752713250616335E-4 testLossDiff:-3.877741375827859E-4
Iteration: 26 trainLoss:0.461310057112232 testLoss:0.4168348610071586 trainLossDiff:-1.6180293382028754E-4 testLossDiff:3.670691362905876E-5
Iteration: 27 trainLoss:0.4611643827768838 testLoss:0.4167149011234822 trainLossDiff:-1.456743353481782E-4 testLossDiff:-1.1995988367641264E-4
Iteration: 28 trainLoss:0.46103749379750625 testLoss:0.41631219816917286 trainLossDiff:-1.268889793775707E-4 testLossDiff:-4.027029543093308E-4
Iteration: 29 trainLoss:0.4609113540117162 testLoss:0.4160625495311807 trainLossDiff:-1.2613978579006924E-4 testLossDiff:-2.496486379921503E-4
Iteration: 30 trainLoss:0.46079062682986005 testLoss:0.4158940272225154 trainLossDiff:-1.2072718185612841E-4 testLossDiff:-1.685223086653198E-4
Learned weights: 12.689566637674625 22.472374460521586 -0.2614625403766252
