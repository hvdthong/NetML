Iteration: 1 trainLoss:0.5170026517104757 testLoss:0.38534804266815603
Iteration: 2 trainLoss:0.5083325285878023 testLoss:0.3870095237484364 trainLossDiff:-0.008670123122673346 testLossDiff:0.0016614810802803581
Iteration: 3 trainLoss:0.5052505594796135 testLoss:0.3877416457321602 trainLossDiff:-0.003081969108188809 testLossDiff:7.321219837237991E-4
Iteration: 4 trainLoss:0.5034502676269751 testLoss:0.3880510541920457 trainLossDiff:-0.0018002918526384137 testLossDiff:3.0940845988552956E-4
Iteration: 5 trainLoss:0.5022112993425616 testLoss:0.38783086544910117 trainLossDiff:-0.0012389682844134997 testLossDiff:-2.2018874294454926E-4
Iteration: 6 trainLoss:0.5012431154572818 testLoss:0.3874967292704963 trainLossDiff:-9.681838852797497E-4 testLossDiff:-3.3413617860489353E-4
Iteration: 7 trainLoss:0.5004320348101641 testLoss:0.38712121633282603 trainLossDiff:-8.110806471177678E-4 testLossDiff:-3.755129376702415E-4
Iteration: 8 trainLoss:0.49975033591850865 testLoss:0.38674646389912154 trainLossDiff:-6.816988916554245E-4 testLossDiff:-3.7475243370449496E-4
Iteration: 9 trainLoss:0.4991713408327386 testLoss:0.38641842253007086 trainLossDiff:-5.789950857700288E-4 testLossDiff:-3.2804136905068004E-4
Iteration: 10 trainLoss:0.4986606605630505 testLoss:0.3860219894645511 trainLossDiff:-5.106802696881463E-4 testLossDiff:-3.9643306551978563E-4
Iteration: 11 trainLoss:0.4982166402192969 testLoss:0.38573989835003875 trainLossDiff:-4.440203437535706E-4 testLossDiff:-2.820911145123284E-4
Iteration: 12 trainLoss:0.4978210410151944 testLoss:0.3855910842375429 trainLossDiff:-3.955992041024814E-4 testLossDiff:-1.488141124958431E-4
Iteration: 13 trainLoss:0.4974652470656441 testLoss:0.3852780731663697 trainLossDiff:-3.557939495503204E-4 testLossDiff:-3.1301107117320814E-4
Iteration: 14 trainLoss:0.49715641472785965 testLoss:0.3851419313707849 trainLossDiff:-3.088323377844482E-4 testLossDiff:-1.3614179558479877E-4
Iteration: 15 trainLoss:0.4968596143342627 testLoss:0.38498539791266795 trainLossDiff:-2.968003935969743E-4 testLossDiff:-1.5653345811694752E-4
Iteration: 16 trainLoss:0.4965992044073722 testLoss:0.38486590148919747 trainLossDiff:-2.6040992689047027E-4 testLossDiff:-1.1949642347047762E-4
Iteration: 17 trainLoss:0.49635779957575005 testLoss:0.38482430185776995 trainLossDiff:-2.4140483162216064E-4 testLossDiff:-4.159963142752465E-5
Iteration: 18 trainLoss:0.4961500866435794 testLoss:0.38472748740448 trainLossDiff:-2.0771293217064501E-4 testLossDiff:-9.681445328996174E-5
Iteration: 19 trainLoss:0.4959643200347059 testLoss:0.3845909868227649 trainLossDiff:-1.8576660887348329E-4 testLossDiff:-1.3650058171510437E-4
Iteration: 20 trainLoss:0.49578846610667815 testLoss:0.38447403045095063 trainLossDiff:-1.7585392802776934E-4 testLossDiff:-1.1695637181424745E-4
Iteration: 21 trainLoss:0.49560364550504066 testLoss:0.3843849315732796 trainLossDiff:-1.8482060163749203E-4 testLossDiff:-8.909887767105662E-5
Iteration: 22 trainLoss:0.4954505394670186 testLoss:0.3843437305796729 trainLossDiff:-1.5310603802204392E-4 testLossDiff:-4.120099360666041E-5
Iteration: 23 trainLoss:0.49531209402054865 testLoss:0.3843290824472133 trainLossDiff:-1.3844544646995915E-4 testLossDiff:-1.4648132459604835E-5
Iteration: 24 trainLoss:0.49518019865666235 testLoss:0.38419653646715657 trainLossDiff:-1.3189536388630296E-4 testLossDiff:-1.325459800567419E-4
Iteration: 25 trainLoss:0.495053933952217 testLoss:0.38416814335100824 trainLossDiff:-1.2626470444537796E-4 testLossDiff:-2.8393116148328623E-5
Iteration: 26 trainLoss:0.4949405535146296 testLoss:0.38413144277124894 trainLossDiff:-1.133804375873515E-4 testLossDiff:-3.670057975929675E-5
Iteration: 27 trainLoss:0.4948377848012185 testLoss:0.3841100154568074 trainLossDiff:-1.027687134111388E-4 testLossDiff:-2.1427314441546663E-5
Iteration: 28 trainLoss:0.49473593716452235 testLoss:0.3841590556341073 trainLossDiff:-1.0184763669612851E-4 testLossDiff:4.904017729989718E-5
Iteration: 29 trainLoss:0.494644931246995 testLoss:0.384062625044961 trainLossDiff:-9.100591752736475E-5 testLossDiff:-9.643058914626801E-5
Iteration: 30 trainLoss:0.49456280670034125 testLoss:0.3839537644272013 trainLossDiff:-8.212454665373903E-5 testLossDiff:-1.0886061775972067E-4
Learned weights: 14.760976257498514 27.204493388952404 -2.186922828079993
