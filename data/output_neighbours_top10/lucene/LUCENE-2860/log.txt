Iteration: 1 trainLoss:0.543873526156096 testLoss:0.40399974616855094
Iteration: 2 trainLoss:0.5369647575431912 testLoss:0.40278109406945717 trainLossDiff:-0.006908768612904792 testLossDiff:-0.0012186520990937755
Iteration: 3 trainLoss:0.5341136399761461 testLoss:0.4020911056089145 trainLossDiff:-0.002851117567045036 testLossDiff:-6.899884605426898E-4
Iteration: 4 trainLoss:0.5322974763230758 testLoss:0.3997785361304879 trainLossDiff:-0.0018161636530703573 testLossDiff:-0.0023125694784265627
Iteration: 5 trainLoss:0.5307746578898535 testLoss:0.39865972611250877 trainLossDiff:-0.0015228184332223282 testLossDiff:-0.0011188100179791438
Iteration: 6 trainLoss:0.5295875521943963 testLoss:0.3964457529793259 trainLossDiff:-0.0011871056954571024 testLossDiff:-0.0022139731331828894
Iteration: 7 trainLoss:0.528465864738476 testLoss:0.39583361091031344 trainLossDiff:-0.0011216874559203394 testLossDiff:-6.121420690124446E-4
Iteration: 8 trainLoss:0.5275866463140689 testLoss:0.3941417078976695 trainLossDiff:-8.7921842440708E-4 testLossDiff:-0.001691903012643936
Iteration: 9 trainLoss:0.5267708131832489 testLoss:0.39345308619066827 trainLossDiff:-8.158331308200095E-4 testLossDiff:-6.886217070012357E-4
Iteration: 10 trainLoss:0.5260555163400064 testLoss:0.39278687402321016 trainLossDiff:-7.152968432425633E-4 testLossDiff:-6.662121674581023E-4
Iteration: 11 trainLoss:0.5254829698552274 testLoss:0.3912156976742436 trainLossDiff:-5.725464847790018E-4 testLossDiff:-0.0015711763489665853
Iteration: 12 trainLoss:0.5249206662314044 testLoss:0.39053150513526974 trainLossDiff:-5.62303623822924E-4 testLossDiff:-6.841925389738379E-4
Iteration: 13 trainLoss:0.5244127202983523 testLoss:0.3903704133065931 trainLossDiff:-5.079459330521452E-4 testLossDiff:-1.610918286766294E-4
Iteration: 14 trainLoss:0.5239742100668603 testLoss:0.3901403361707774 trainLossDiff:-4.385102314919953E-4 testLossDiff:-2.3007713581568723E-4
Iteration: 15 trainLoss:0.5236664571290384 testLoss:0.38831259351096764 trainLossDiff:-3.077529378219257E-4 testLossDiff:-0.0018277426598097835
Iteration: 16 trainLoss:0.5232868574274345 testLoss:0.3881998300529067 trainLossDiff:-3.795997016038388E-4 testLossDiff:-1.1276345806093824E-4
Iteration: 17 trainLoss:0.522974160264881 testLoss:0.3878974975735637 trainLossDiff:-3.126971625535546E-4 testLossDiff:-3.02332479343026E-4
Iteration: 18 trainLoss:0.522644631640195 testLoss:0.3888219329667157 trainLossDiff:-3.2952862468593747E-4 testLossDiff:9.244353931520122E-4
Iteration: 19 trainLoss:0.5224460662959303 testLoss:0.3868957724861378 trainLossDiff:-1.9856534426476724E-4 testLossDiff:-0.0019261604805778654
Iteration: 20 trainLoss:0.5221742997066335 testLoss:0.38714590524280124 trainLossDiff:-2.7176658929672914E-4 testLossDiff:2.501327566634126E-4
Iteration: 21 trainLoss:0.5219634040965878 testLoss:0.3867304115145545 trainLossDiff:-2.1089561004572488E-4 testLossDiff:-4.154937282467297E-4
Iteration: 22 trainLoss:0.5217630995342831 testLoss:0.3865565726738444 trainLossDiff:-2.003045623046873E-4 testLossDiff:-1.7383884071009437E-4
Iteration: 23 trainLoss:0.5215997108351385 testLoss:0.38601527444093153 trainLossDiff:-1.6338869914467313E-4 testLossDiff:-5.41298232912879E-4
Iteration: 24 trainLoss:0.5214690987016707 testLoss:0.3853486472448413 trainLossDiff:-1.306121334677668E-4 testLossDiff:-6.666271960902304E-4
Iteration: 25 trainLoss:0.5212683792904573 testLoss:0.3860606688215874 trainLossDiff:-2.00719411213357E-4 testLossDiff:7.120215767461024E-4
Iteration: 26 trainLoss:0.5211268030291294 testLoss:0.3859260882709243 trainLossDiff:-1.4157626132793588E-4 testLossDiff:-1.3458055066312147E-4
Iteration: 27 trainLoss:0.5210253801346648 testLoss:0.38519100930800204 trainLossDiff:-1.0142289446457564E-4 testLossDiff:-7.350789629222421E-4
Iteration: 28 trainLoss:0.5209105182320976 testLoss:0.38499166952405384 trainLossDiff:-1.148619025672648E-4 testLossDiff:-1.9933978394820473E-4
Iteration: 29 trainLoss:0.5207778069602843 testLoss:0.3857053730692245 trainLossDiff:-1.3271127181324616E-4 testLossDiff:7.137035451706408E-4
Iteration: 30 trainLoss:0.5206968179197552 testLoss:0.38490559533933744 trainLossDiff:-8.098904052911138E-5 testLossDiff:-7.997777298870412E-4
Learned weights: 12.282983678792448 29.683788023688553 -0.6440219052737827
