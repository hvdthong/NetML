Iteration: 1 trainLoss:0.528267406784803 testLoss:0.4135402641438835
Iteration: 2 trainLoss:0.5230644065174896 testLoss:0.4153666118503849 trainLossDiff:-0.005203000267313351 testLossDiff:0.0018263477065014189
Iteration: 3 trainLoss:0.5208996641222114 testLoss:0.4146745700514132 trainLossDiff:-0.0021647423952781963 testLossDiff:-6.920417989716987E-4
Iteration: 4 trainLoss:0.5193276305237288 testLoss:0.4130845921674618 trainLossDiff:-0.0015720335984826805 testLossDiff:-0.0015899778839514322
Iteration: 5 trainLoss:0.5180189051733924 testLoss:0.41197753291311495 trainLossDiff:-0.001308725350336326 testLossDiff:-0.0011070592543468427
Iteration: 6 trainLoss:0.5169108619595771 testLoss:0.4106348704977278 trainLossDiff:-0.0011080432138153018 testLossDiff:-0.0013426624153871636
Iteration: 7 trainLoss:0.5159494203467021 testLoss:0.4089715438959598 trainLossDiff:-9.614416128750358E-4 testLossDiff:-0.0016633266017679893
Iteration: 8 trainLoss:0.5151167132245623 testLoss:0.4079704588017016 trainLossDiff:-8.327071221397864E-4 testLossDiff:-0.001001085094258225
Iteration: 9 trainLoss:0.5143905981546719 testLoss:0.40694026255938437 trainLossDiff:-7.261150698903984E-4 testLossDiff:-0.001030196242317205
Iteration: 10 trainLoss:0.5137468964169164 testLoss:0.40590682297294556 trainLossDiff:-6.437017377555199E-4 testLossDiff:-0.0010334395864388113
Iteration: 11 trainLoss:0.5131739735295557 testLoss:0.4054535362787638 trainLossDiff:-5.729228873606607E-4 testLossDiff:-4.532866941817648E-4
Iteration: 12 trainLoss:0.5126707446539407 testLoss:0.40488796877372524 trainLossDiff:-5.032288756150471E-4 testLossDiff:-5.655675050385556E-4
Iteration: 13 trainLoss:0.5122265384329955 testLoss:0.4038057630793897 trainLossDiff:-4.442062209452091E-4 testLossDiff:-0.0010822056943355363
Iteration: 14 trainLoss:0.5118102192934638 testLoss:0.40361718720848677 trainLossDiff:-4.1631913953166233E-4 testLossDiff:-1.885758709029295E-4
Iteration: 15 trainLoss:0.5114491720746013 testLoss:0.4031084808767881 trainLossDiff:-3.6104721886254243E-4 testLossDiff:-5.08706331698694E-4
Iteration: 16 trainLoss:0.5111180214580604 testLoss:0.40271792436218384 trainLossDiff:-3.311506165408762E-4 testLossDiff:-3.9055651460423446E-4
Iteration: 17 trainLoss:0.5108458845529935 testLoss:0.4018519330020973 trainLossDiff:-2.721369050668887E-4 testLossDiff:-8.659913600865266E-4
Iteration: 18 trainLoss:0.5105616317223605 testLoss:0.4021615136851285 trainLossDiff:-2.842528306330472E-4 testLossDiff:3.0958068303116315E-4
Iteration: 19 trainLoss:0.5103146404012091 testLoss:0.4017377044541485 trainLossDiff:-2.4699132115135747E-4 testLossDiff:-4.238092309799546E-4
Iteration: 20 trainLoss:0.5101065004210998 testLoss:0.40103698465734905 trainLossDiff:-2.081399801092676E-4 testLossDiff:-7.00719796799476E-4
Iteration: 21 trainLoss:0.5098963435345272 testLoss:0.4008746717238571 trainLossDiff:-2.101568865726655E-4 testLossDiff:-1.623129334919482E-4
Iteration: 22 trainLoss:0.5097201658531432 testLoss:0.4003507517345468 trainLossDiff:-1.7617768138400436E-4 testLossDiff:-5.239199893102842E-4
Iteration: 23 trainLoss:0.5095523884778201 testLoss:0.39997217910219274 trainLossDiff:-1.677773753230305E-4 testLossDiff:-3.7857263235407945E-4
Iteration: 24 trainLoss:0.5093825822885154 testLoss:0.4001014005350405 trainLossDiff:-1.6980618930473312E-4 testLossDiff:1.2922143284777032E-4
Iteration: 25 trainLoss:0.5092450761129663 testLoss:0.39982936637000316 trainLossDiff:-1.3750617554908473E-4 testLossDiff:-2.7203416503734923E-4
Iteration: 26 trainLoss:0.509105697531741 testLoss:0.3997114851305377 trainLossDiff:-1.3937858122536895E-4 testLossDiff:-1.1788123946543383E-4
Iteration: 27 trainLoss:0.5089870204911353 testLoss:0.399498799472668 trainLossDiff:-1.1867704060564144E-4 testLossDiff:-2.126856578697489E-4
Iteration: 28 trainLoss:0.5088897957593863 testLoss:0.3990617363324651 trainLossDiff:-9.722473174900159E-5 testLossDiff:-4.3706314020286463E-4
Iteration: 29 trainLoss:0.5087670032024083 testLoss:0.3997009590586941 trainLossDiff:-1.2279255697800195E-4 testLossDiff:6.392227262290162E-4
Iteration: 30 trainLoss:0.5086699780501832 testLoss:0.3994395833305167 trainLossDiff:-9.702515222509422E-5 testLossDiff:-2.613757281774154E-4
Learned weights: 12.190133800374149 28.059291146670958 -0.4109059765191536
