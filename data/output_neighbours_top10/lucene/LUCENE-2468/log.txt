Iteration: 1 trainLoss:0.5170542850752675 testLoss:0.593868292501873
Iteration: 2 trainLoss:0.5097621537978806 testLoss:0.5788672356023357 trainLossDiff:-0.007292131277386926 testLossDiff:-0.015001056899537346
Iteration: 3 trainLoss:0.5076223847248549 testLoss:0.5742352941355826 trainLossDiff:-0.00213976907302571 testLossDiff:-0.004631941466753053
Iteration: 4 trainLoss:0.5063524989415504 testLoss:0.572426325163997 trainLossDiff:-0.0012698857833044475 testLossDiff:-0.0018089689715855561
Iteration: 5 trainLoss:0.505372740082386 testLoss:0.5717690778031717 trainLossDiff:-9.79758859164459E-4 testLossDiff:-6.57247360825397E-4
Iteration: 6 trainLoss:0.5045372942137931 testLoss:0.5713963197051675 trainLossDiff:-8.354458685928545E-4 testLossDiff:-3.727580980041889E-4
Iteration: 7 trainLoss:0.5038137784188544 testLoss:0.5713966556011543 trainLossDiff:-7.235157949386783E-4 testLossDiff:3.358959868027256E-7
Iteration: 8 trainLoss:0.5031594276003072 testLoss:0.5711594389306685 trainLossDiff:-6.543508185472557E-4 testLossDiff:-2.3721667048581807E-4
Iteration: 9 trainLoss:0.5025863285259976 testLoss:0.5712945898023917 trainLossDiff:-5.730990743095798E-4 testLossDiff:1.3515087172322193E-4
Iteration: 10 trainLoss:0.5020675717486875 testLoss:0.5713573589414882 trainLossDiff:-5.187567773100588E-4 testLossDiff:6.276913909653015E-5
Iteration: 11 trainLoss:0.5015912893240688 testLoss:0.571385220055002 trainLossDiff:-4.762824246187236E-4 testLossDiff:2.7861113513827362E-5
Iteration: 12 trainLoss:0.5011739420866396 testLoss:0.5713358532310977 trainLossDiff:-4.173472374292553E-4 testLossDiff:-4.936682390432878E-5
Iteration: 13 trainLoss:0.5007795726907465 testLoss:0.5713804768386437 trainLossDiff:-3.943693958931016E-4 testLossDiff:4.462360754597938E-5
Iteration: 14 trainLoss:0.5004377465581277 testLoss:0.5715779146975728 trainLossDiff:-3.4182613261879435E-4 testLossDiff:1.9743785892911703E-4
Iteration: 15 trainLoss:0.500103636706452 testLoss:0.571500475749479 trainLossDiff:-3.341098516757013E-4 testLossDiff:-7.74389480937554E-5
Iteration: 16 trainLoss:0.49981094170216256 testLoss:0.5715330397314018 trainLossDiff:-2.9269500428941164E-4 testLossDiff:3.2563981922750784E-5
Iteration: 17 trainLoss:0.4995390756724561 testLoss:0.5716128397086409 trainLossDiff:-2.71866029706469E-4 testLossDiff:7.979997723905896E-5
Iteration: 18 trainLoss:0.4992849259392866 testLoss:0.5715145010219824 trainLossDiff:-2.541497331695064E-4 testLossDiff:-9.833868665842793E-5
Iteration: 19 trainLoss:0.49904838269811536 testLoss:0.5715093280896933 trainLossDiff:-2.365432411712276E-4 testLossDiff:-5.1729322890770035E-6
Iteration: 20 trainLoss:0.49883304850565213 testLoss:0.5715550474709487 trainLossDiff:-2.153341924632235E-4 testLossDiff:4.5719381255304725E-5
Iteration: 21 trainLoss:0.49863749977909455 testLoss:0.5715371609656947 trainLossDiff:-1.955487265575817E-4 testLossDiff:-1.7886505253916773E-5
Iteration: 22 trainLoss:0.49845528981421083 testLoss:0.5716939083285737 trainLossDiff:-1.822099648837172E-4 testLossDiff:1.5674736287896174E-4
Iteration: 23 trainLoss:0.4982835822369069 testLoss:0.571594587325961 trainLossDiff:-1.717075773039478E-4 testLossDiff:-9.93210026126734E-5
Iteration: 24 trainLoss:0.4981191674051225 testLoss:0.5717683984671498 trainLossDiff:-1.6441483178436522E-4 testLossDiff:1.7381114118875107E-4
Iteration: 25 trainLoss:0.4979698153017066 testLoss:0.5717911682037068 trainLossDiff:-1.4935210341593397E-4 testLossDiff:2.276973655701564E-5
Iteration: 26 trainLoss:0.4978258851701015 testLoss:0.5717169798705953 trainLossDiff:-1.439301316050745E-4 testLossDiff:-7.41883331114579E-5
Iteration: 27 trainLoss:0.49769310874603157 testLoss:0.5717104540102168 trainLossDiff:-1.3277642406994694E-4 testLossDiff:-6.52586037852565E-6
Iteration: 28 trainLoss:0.4975744144669737 testLoss:0.5718108176072285 trainLossDiff:-1.1869427905786267E-4 testLossDiff:1.0036359701171005E-4
Iteration: 29 trainLoss:0.49745888446504216 testLoss:0.5718246914862504 trainLossDiff:-1.1553000193154084E-4 testLossDiff:1.3873879021852886E-5
Iteration: 30 trainLoss:0.4973486928209406 testLoss:0.5717794098568458 trainLossDiff:-1.101916441015871E-4 testLossDiff:-4.5281629404536616E-5
Learned weights: 16.00519994227979 24.612708727949034 -0.9145484094402453
