Iteration: 1 trainLoss:0.5106096594260476 testLoss:0.44147290531123645
Iteration: 2 trainLoss:0.5037595718399003 testLoss:0.43913837974561526 trainLossDiff:-0.006850087586147358 testLossDiff:-0.0023345255656211927
Iteration: 3 trainLoss:0.5000245010090327 testLoss:0.43603319607749985 trainLossDiff:-0.0037350708308675484 testLossDiff:-0.0031051836681154077
Iteration: 4 trainLoss:0.49732678781741363 testLoss:0.4337033011458074 trainLossDiff:-0.0026977131916191 testLossDiff:-0.0023298949316924444
Iteration: 5 trainLoss:0.4951528500594004 testLoss:0.43123431022815656 trainLossDiff:-0.0021739377580132224 testLossDiff:-0.0024689909176508484
Iteration: 6 trainLoss:0.49327235879181996 testLoss:0.4278270900306774 trainLossDiff:-0.001880491267580442 testLossDiff:-0.0034072201974791327
Iteration: 7 trainLoss:0.4916896795655893 testLoss:0.4267721579544753 trainLossDiff:-0.0015826792262306766 testLossDiff:-0.0010549320762021086
Iteration: 8 trainLoss:0.4902887226100048 testLoss:0.4242385051786307 trainLossDiff:-0.0014009569555845092 testLossDiff:-0.002533652775844608
Iteration: 9 trainLoss:0.48909429639385993 testLoss:0.42291041758094267 trainLossDiff:-0.0011944262161448505 testLossDiff:-0.0013280875976880435
Iteration: 10 trainLoss:0.4880241104964247 testLoss:0.4215180554858089 trainLossDiff:-0.0010701858974352385 testLossDiff:-0.00139236209513377
Iteration: 11 trainLoss:0.48707589290743547 testLoss:0.4201646404168578 trainLossDiff:-9.482175889892197E-4 testLossDiff:-0.0013534150689510915
Iteration: 12 trainLoss:0.4862337624794888 testLoss:0.41926137419016624 trainLossDiff:-8.421304279466746E-4 testLossDiff:-9.032662266915681E-4
Iteration: 13 trainLoss:0.48547878829320623 testLoss:0.4187164021965829 trainLossDiff:-7.549741862825643E-4 testLossDiff:-5.449719935833319E-4
Iteration: 14 trainLoss:0.484799771191679 testLoss:0.4174945525239789 trainLossDiff:-6.79017101527235E-4 testLossDiff:-0.001221849672604025
Iteration: 15 trainLoss:0.48419505450258854 testLoss:0.4171554385074801 trainLossDiff:-6.047166890904565E-4 testLossDiff:-3.3911401649877604E-4
Iteration: 16 trainLoss:0.483657027447133 testLoss:0.41653606656681347 trainLossDiff:-5.380270554555255E-4 testLossDiff:-6.193719406666354E-4
Iteration: 17 trainLoss:0.4831527994158242 testLoss:0.4157572524322978 trainLossDiff:-5.042280313088399E-4 testLossDiff:-7.788141345156929E-4
Iteration: 18 trainLoss:0.4827017069680496 testLoss:0.4148256757387903 trainLossDiff:-4.5109244777458146E-4 testLossDiff:-9.315766935074632E-4
Iteration: 19 trainLoss:0.4822987136102942 testLoss:0.41554306609407465 trainLossDiff:-4.02993357755399E-4 testLossDiff:7.173903552843419E-4
Iteration: 20 trainLoss:0.4819248808717801 testLoss:0.41516231453683217 trainLossDiff:-3.738327385141016E-4 testLossDiff:-3.807515572424869E-4
Iteration: 21 trainLoss:0.48156751384478447 testLoss:0.41449372735819184 trainLossDiff:-3.573670269956253E-4 testLossDiff:-6.68587178640323E-4
Iteration: 22 trainLoss:0.481249708282526 testLoss:0.41451684537142564 trainLossDiff:-3.1780556225846635E-4 testLossDiff:2.311801323379159E-5
Iteration: 23 trainLoss:0.48095195877098695 testLoss:0.41352099097642425 trainLossDiff:-2.9774951153904716E-4 testLossDiff:-9.958543950013832E-4
Iteration: 24 trainLoss:0.48069716972949345 testLoss:0.41373503824023394 trainLossDiff:-2.5478904149350834E-4 testLossDiff:2.140472638096913E-4
Iteration: 25 trainLoss:0.48044928156266287 testLoss:0.4133945958951501 trainLossDiff:-2.478881668305788E-4 testLossDiff:-3.4044234508384674E-4
Iteration: 26 trainLoss:0.4802239039564852 testLoss:0.4127034922347168 trainLossDiff:-2.253776061776902E-4 testLossDiff:-6.911036604332899E-4
Iteration: 27 trainLoss:0.48001072968707004 testLoss:0.412658658964761 trainLossDiff:-2.131742694151395E-4 testLossDiff:-4.4833269955801835E-5
Iteration: 28 trainLoss:0.47983567664923954 testLoss:0.4139632967978027 trainLossDiff:-1.7505303783049708E-4 testLossDiff:0.0013046378330416886
Iteration: 29 trainLoss:0.4796292647991813 testLoss:0.41216046034384607 trainLossDiff:-2.0641185005826346E-4 testLossDiff:-0.0018028364539566244
Iteration: 30 trainLoss:0.4794751714389137 testLoss:0.41284049678850815 trainLossDiff:-1.5409336026755982E-4 testLossDiff:6.800364446620799E-4
Learned weights: 7.756273048300385 35.67609075049209 0.023691323032375238
